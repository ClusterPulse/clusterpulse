{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"ClusterPulse","text":"<p>Multi-cluster Kubernetes monitoring with fine-grained RBAC</p> <p>ClusterPulse provides a unified view of your Kubernetes clusters with  enterprise-grade access control. Monitor clusters, registries, and  resources while ensuring users only see what they're authorized to access.</p>"},{"location":"#quick-links","title":"Quick Links","text":"<ul> <li> <p>Getting Started</p> <p>Install ClusterPulse and connect your first cluster in 5 minutes</p> <p>Quickstart</p> </li> <li> <p>Tutorials</p> <p>Learn ClusterPulse through hands-on tutorials</p> <p>Tutorials</p> </li> <li> <p>Reference</p> <p>CRD specifications, API docs, and configuration</p> <p>References</p> </li> <li> <p>Contributing</p> <p>Help improve ClusterPulse</p> <p>Contributing</p> </li> </ul>"},{"location":"concepts/architecture/","title":"Architecture","text":"<p>ClusterPulse consists of three main components that work together to provide secure multi-cluster monitoring.</p>"},{"location":"concepts/architecture/#system-overview","title":"System Overview","text":""},{"location":"concepts/architecture/#components","title":"Components","text":""},{"location":"concepts/architecture/#cluster-controller-go","title":"Cluster Controller (Go)","text":"<p>The Cluster Controller is a Kubernetes operator that:</p> <ul> <li>Watches <code>ClusterConnection</code> CRDs</li> <li>Connects to remote clusters using provided credentials</li> <li>Collects metrics (nodes, pods, operators, resources)</li> <li>Stores data in Redis for the API to consume</li> </ul> <p>Learn more \u2192</p>"},{"location":"concepts/architecture/#policy-controller-python","title":"Policy Controller (Python)","text":"<p>The Policy Controller compiles RBAC policies:</p> <ul> <li>Watches <code>MonitorAccessPolicy</code> CRDs</li> <li>Compiles policies into efficient evaluation structures</li> <li>Indexes policies by user/group for fast lookup</li> <li>Validates time-bound policies</li> </ul> <p>Learn more \u2192</p>"},{"location":"concepts/architecture/#api-server-pythonfastapi","title":"API Server (Python/FastAPI)","text":"<p>The API Server handles all user requests:</p> <ul> <li>Authenticates users via OAuth/OIDC</li> <li>Resolves group membership in real-time</li> <li>Evaluates RBAC policies for every request</li> <li>Filters resources based on user permissions</li> <li>Serves the web UI</li> </ul> <p>Learn more \u2192</p>"},{"location":"concepts/architecture/#data-flow","title":"Data Flow","text":"<ol> <li>Cluster Controller collects metrics every 30 seconds</li> <li>Data is stored in Redis with TTL</li> <li>Policy Controller indexes policies for fast lookup</li> <li>API Server receives user request</li> <li>API authenticates user and resolves groups</li> <li>RBAC Engine evaluates policies and filters data</li> <li>Filtered response returned to user</li> </ol>"},{"location":"concepts/policy-evaluation/","title":"Policy Evaluation","text":"<p>This document describes how ClusterPulse evaluates policies to make authorization decisions.</p>"},{"location":"concepts/policy-evaluation/#evaluation-flow","title":"Evaluation Flow","text":"<pre><code>flowchart TD\n    A[Request Received] --&gt; B[Extract Principal]\n    B --&gt; C[Load Applicable Policies]\n    C --&gt; D[Sort by Priority]\n    D --&gt; E{For Each Policy}\n    E --&gt; F{Policy Valid?}\n    F --&gt;|No| E\n    F --&gt;|Yes| G{Resource Matches?}\n    G --&gt;|No| E\n    G --&gt;|Yes| H{Effect?}\n    H --&gt;|Deny| I[Return DENY]\n    H --&gt;|Allow| J[Extract Permissions &amp; Filters]\n    J --&gt; K[Return ALLOW/PARTIAL]\n    E --&gt;|No More Policies| L[Return Default DENY]</code></pre>"},{"location":"concepts/policy-evaluation/#step-1-policy-retrieval","title":"Step 1: Policy Retrieval","text":"<p>When a request arrives, the RBAC engine retrieves all policies that might apply to the principal.</p>"},{"location":"concepts/policy-evaluation/#index-lookup","title":"Index Lookup","text":"<p>Policies are retrieved from Redis using multiple indexes:</p> <pre><code># Pseudocode\npolicy_keys = set()\n\n# User-specific policies\npolicy_keys.update(redis.zrevrange(f\"policy:user:{username}:sorted\"))\n\n# Group policies (for each group)\nfor group in principal.groups:\n    policy_keys.update(redis.zrevrange(f\"policy:group:{group}:sorted\"))\n\n# Service account policies (if applicable)\nif principal.is_service_account:\n    policy_keys.update(redis.zrevrange(f\"policy:sa:{sa_name}:sorted\"))\n</code></pre>"},{"location":"concepts/policy-evaluation/#priority-sorting","title":"Priority Sorting","text":"<p>Retrieved policies are sorted by priority in descending order (highest priority first, meaning lowest numeric value):</p> Priority Order 0 First (highest priority) 100 Second 200 Third 999 Last (lowest priority)"},{"location":"concepts/policy-evaluation/#step-2-policy-validation","title":"Step 2: Policy Validation","text":"<p>Each policy is validated before evaluation:</p>"},{"location":"concepts/policy-evaluation/#enabled-check","title":"Enabled Check","text":"<pre><code>if not policy.enabled:\n    skip_policy()\n</code></pre>"},{"location":"concepts/policy-evaluation/#time-based-validity","title":"Time-Based Validity","text":"<pre><code>now = datetime.utcnow()\n\nif policy.not_before and now &lt; policy.not_before:\n    skip_policy()  # Policy not yet active\n\nif policy.not_after and now &gt; policy.not_after:\n    skip_policy()  # Policy expired\n</code></pre>"},{"location":"concepts/policy-evaluation/#step-3-resource-matching","title":"Step 3: Resource Matching","text":"<p>The engine determines if the policy applies to the requested resource.</p>"},{"location":"concepts/policy-evaluation/#cluster-matching","title":"Cluster Matching","text":"<p>For cluster resources, rules are matched using selectors:</p> <pre><code>flowchart TD\n    A[Cluster Resource] --&gt; B{Check Rules}\n    B --&gt; C{matchNames contains cluster?}\n    C --&gt;|Yes| D[Rule Matches]\n    C --&gt;|No| E{matchPattern matches?}\n    E --&gt;|Yes| D\n    E --&gt;|No| F{matchLabels match?}\n    F --&gt;|Yes| D\n    F --&gt;|No| G{More Rules?}\n    G --&gt;|Yes| B\n    G --&gt;|No| H{default access?}\n    H --&gt;|all/allow| D\n    H --&gt;|none| I[No Match]</code></pre>"},{"location":"concepts/policy-evaluation/#selector-types","title":"Selector Types","text":"Selector Description <code>matchNames</code> Exact cluster name match <code>matchPattern</code> Regex pattern match <code>matchLabels</code> Kubernetes label selector <p>Example:</p> <pre><code>rules:\n  - selector:\n      matchNames:\n        - production-cluster\n      matchLabels:\n        environment: production\n        region: us-west\n</code></pre>"},{"location":"concepts/policy-evaluation/#sub-resource-matching","title":"Sub-Resource Matching","text":"<p>For nodes, namespaces, operators, and pods, the engine evaluates resource filters after the cluster match.</p>"},{"location":"concepts/policy-evaluation/#step-4-decision-generation","title":"Step 4: Decision Generation","text":"<p>Once a matching policy is found, the engine generates a decision.</p>"},{"location":"concepts/policy-evaluation/#deny-effect","title":"Deny Effect","text":"<p>If the policy effect is <code>Deny</code>, evaluation stops immediately:</p> <pre><code>if policy.effect == \"Deny\":\n    return Decision(\n        decision=DENY,\n        reason=f\"Denied by policy {policy.name}\"\n    )\n</code></pre>"},{"location":"concepts/policy-evaluation/#allow-effect","title":"Allow Effect","text":"<p>For <code>Allow</code> policies, permissions and filters are extracted:</p> <pre><code>if policy.effect == \"Allow\":\n    permissions = extract_permissions(rule)\n    filters = extract_filters(rule)\n\n    if filters:\n        return Decision(\n            decision=PARTIAL,\n            permissions=permissions,\n            filters=filters\n        )\n    else:\n        return Decision(\n            decision=ALLOW,\n            permissions=permissions\n        )\n</code></pre>"},{"location":"concepts/policy-evaluation/#step-5-filter-application","title":"Step 5: Filter Application","text":"<p>When a <code>PARTIAL</code> decision is returned, filters are applied to resource lists.</p>"},{"location":"concepts/policy-evaluation/#filter-evaluation-order","title":"Filter Evaluation Order","text":"<pre><code>flowchart TD\n    A[Resource Item] --&gt; B{In Exclude Set?}\n    B --&gt;|Yes| C[Filter Out]\n    B --&gt;|No| D{Visibility = none?}\n    D --&gt;|Yes| C\n    D --&gt;|No| E{Visibility = all?}\n    E --&gt;|Yes| F[Include]\n    E --&gt;|No| G{In Include Set?}\n    G --&gt;|Yes| F\n    G --&gt;|No| H{Matches Include Pattern?}\n    H --&gt;|Yes| F\n    H --&gt;|No| I{Label Selector Matches?}\n    I --&gt;|Yes| F\n    I --&gt;|No| C</code></pre>"},{"location":"concepts/policy-evaluation/#filter-precedence","title":"Filter Precedence","text":"<ol> <li>Exclude literals - Highest priority, always filtered out</li> <li>Exclude patterns - Filtered if pattern matches</li> <li>Include literals - Included if in set</li> <li>Include patterns - Included if pattern matches</li> <li>Label selectors - Included if labels match</li> <li>Default - Filtered out if visibility is <code>filtered</code></li> </ol>"},{"location":"concepts/policy-evaluation/#namespace-filtering-impact","title":"Namespace Filtering Impact","text":"<p>When namespace filters are applied, metrics are recalculated:</p> <pre><code>flowchart LR\n    A[Raw Metrics] --&gt; B[Namespace Filter]\n    B --&gt; C[Filtered Namespaces]\n    C --&gt; D[Recalculate Pod Counts]\n    C --&gt; E[Recalculate Deployment Counts]\n    C --&gt; F[Recalculate Service Counts]\n    D --&gt; G[Filtered Metrics]\n    E --&gt; G\n    F --&gt; G</code></pre> <p>Affected metrics:</p> Metric Calculation <code>namespaces</code> Count of visible namespaces <code>pods</code> Sum of pods in visible namespaces <code>pods_running</code> Running pods in visible namespaces <code>deployments</code> Deployments in visible namespaces <code>services</code> Services in visible namespaces <code>statefulsets</code> StatefulSets in visible namespaces <code>daemonsets</code> DaemonSets in visible namespaces"},{"location":"concepts/policy-evaluation/#node-filtering-impact","title":"Node Filtering Impact","text":"<p>Node filters affect capacity metrics:</p> Metric Calculation <code>nodes</code> Count of visible nodes <code>nodes_ready</code> Ready nodes that are visible <code>cpu_capacity</code> Sum of CPU from visible nodes <code>memory_capacity</code> Sum of memory from visible nodes <code>cpu_usage_percent</code> Recalculated from visible nodes <code>memory_usage_percent</code> Recalculated from visible nodes"},{"location":"concepts/policy-evaluation/#multiple-policy-handling","title":"Multiple Policy Handling","text":"<p>When multiple policies apply to a principal:</p>"},{"location":"concepts/policy-evaluation/#same-priority","title":"Same Priority","text":"<p>If policies have the same priority, evaluation order is undefined. Avoid this by assigning unique priorities.</p>"},{"location":"concepts/policy-evaluation/#deny-precedence","title":"Deny Precedence","text":"<p>A <code>Deny</code> policy at any priority level stops evaluation:</p> <pre><code>Priority 100: Allow (skipped - Deny found first)\nPriority 50: Deny  &lt;-- Evaluation stops here\nPriority 10: Allow (never reached)\n</code></pre>"},{"location":"concepts/policy-evaluation/#additive-permissions","title":"Additive Permissions","text":"<p>Permissions from a matching <code>Allow</code> policy are not additive. Only the first matching policy's permissions apply:</p> <pre><code>Priority 100: Allow {view: true}           &lt;-- This applies\nPriority 200: Allow {view: true, edit: true} (not reached)\n</code></pre>"},{"location":"concepts/policy-evaluation/#caching-behavior","title":"Caching Behavior","text":""},{"location":"concepts/policy-evaluation/#decision-cache","title":"Decision Cache","text":"<p>When caching is enabled, decisions are cached with the key:</p> <pre><code>rbac:decision:{principal_cache_key}:{action}:{resource_id}\n</code></pre> <p>The <code>principal_cache_key</code> includes username and sorted groups:</p> <pre><code>cache_key = f\"{username}:{','.join(sorted(groups))}\"\n</code></pre>"},{"location":"concepts/policy-evaluation/#cache-invalidation","title":"Cache Invalidation","text":"<p>Caches are invalidated when:</p> <ol> <li>Policy created/updated/deleted - All affected users, groups, and service accounts have their caches cleared</li> <li>Manual clear - Via <code>POST /api/v1/auth/cache/clear</code></li> </ol> <p>Invalidation uses Redis SCAN to find affected keys:</p> <pre><code>patterns = [\n    f\"policy:eval:{user}:*\",\n    f\"policy:eval:*:group:{group}:*\",\n    f\"policy:eval:{service_account}:*\"\n]\n</code></pre>"},{"location":"concepts/policy-evaluation/#performance-considerations","title":"Performance Considerations","text":""},{"location":"concepts/policy-evaluation/#optimization-strategies","title":"Optimization Strategies","text":"<ol> <li>Redis Pipelining - Batch multiple Redis operations</li> <li>Pattern Pre-compilation - Wildcard patterns compiled to regex once</li> <li>Literal Indexing - Exact matches use O(1) set lookups</li> <li>Priority Sorting - Early termination on first match</li> </ol>"},{"location":"concepts/policy-evaluation/#complexity-analysis","title":"Complexity Analysis","text":"Operation Complexity Policy lookup O(g) where g = number of groups Priority sort O(p log p) where p = policies Filter evaluation O(r * f) where r = resources, f = filter rules"},{"location":"concepts/policy-evaluation/#debugging-evaluation","title":"Debugging Evaluation","text":""},{"location":"concepts/policy-evaluation/#view-applicable-policies","title":"View Applicable Policies","text":"<pre><code>curl https://clusterpulse.example.com/api/v1/auth/policies\n</code></pre>"},{"location":"concepts/policy-evaluation/#check-effective-permissions","title":"Check Effective Permissions","text":"<pre><code>curl https://clusterpulse.example.com/api/v1/auth/permissions\n</code></pre>"},{"location":"concepts/policy-evaluation/#enable-debug-logging","title":"Enable Debug Logging","text":"<p>Set environment variable on the API:</p> <pre><code>env:\n  - name: LOG_LEVEL\n    value: DEBUG\n</code></pre> <p>Debug logs show:</p> <ul> <li>Policy retrieval and sorting</li> <li>Validation results</li> <li>Match decisions</li> <li>Filter application</li> </ul>"},{"location":"concepts/policy-evaluation/#related-documentation","title":"Related Documentation","text":"<ul> <li>RBAC Model - Core concepts and data structures</li> <li>Filter by Namespace - Practical filtering examples</li> </ul>"},{"location":"concepts/rbac-model/","title":"RBAC Model","text":"<p>This document describes the role-based access control model used by ClusterPulse to authorize access to cluster resources.</p>"},{"location":"concepts/rbac-model/#overview","title":"Overview","text":"<p>ClusterPulse implements a policy-based RBAC system that evaluates access requests against compiled policies stored in Redis. The model supports:</p> <ul> <li>Multiple subject types (users, groups, service accounts)</li> <li>Fine-grained resource filtering (clusters, nodes, namespaces, operators, pods)</li> <li>Priority-based policy resolution</li> <li>Time-based policy validity</li> </ul>"},{"location":"concepts/rbac-model/#core-components","title":"Core Components","text":"<pre><code>flowchart TB\n    subgraph Request\n        P[Principal]\n        A[Action]\n        R[Resource]\n    end\n\n    subgraph Evaluation\n        PE[Policy Engine]\n        PC[Policy Cache]\n        Redis[(Redis)]\n    end\n\n    subgraph Decision\n        D{Decision}\n        Allow[Allow]\n        Deny[Deny]\n        Partial[Partial + Filters]\n    end\n\n    P --&gt; PE\n    A --&gt; PE\n    R --&gt; PE\n    PE &lt;--&gt; PC\n    PC &lt;--&gt; Redis\n    PE --&gt; D\n    D --&gt; Allow\n    D --&gt; Deny\n    D --&gt; Partial</code></pre>"},{"location":"concepts/rbac-model/#principal","title":"Principal","text":"<p>The entity making a request. Contains:</p> Field Type Description <code>username</code> string Unique identifier <code>email</code> string Optional email address <code>groups</code> list Group memberships <code>is_service_account</code> bool Whether this is a service account <code>attributes</code> dict Additional metadata <p>Principals are extracted from OAuth proxy headers or Kubernetes authentication.</p>"},{"location":"concepts/rbac-model/#resource","title":"Resource","text":"<p>The object being accessed:</p> Field Type Description <code>type</code> enum Resource type (see below) <code>name</code> string Resource name <code>namespace</code> string Kubernetes namespace (if applicable) <code>cluster</code> string Cluster name <code>labels</code> dict Resource labels"},{"location":"concepts/rbac-model/#resource-types","title":"Resource Types","text":"Type Description <code>CLUSTER</code> A monitored Kubernetes cluster <code>NODE</code> A cluster node <code>NAMESPACE</code> A Kubernetes namespace <code>OPERATOR</code> An OLM-managed operator <code>POD</code> A pod (used for namespace-scoped filtering) <code>ALERT</code> A cluster alert <code>EVENT</code> A cluster event"},{"location":"concepts/rbac-model/#action","title":"Action","text":"<p>Operations that can be performed:</p> Action Description <code>VIEW</code> Basic read access <code>VIEW_METRICS</code> Access to performance metrics <code>VIEW_SENSITIVE</code> Access to sensitive data <code>VIEW_COSTS</code> Access to cost information <code>VIEW_SECRETS</code> Access to secret values <code>VIEW_METADATA</code> Access to filtering metadata <code>VIEW_AUDIT</code> Access to audit logs <code>EDIT</code> Modify resources <code>DELETE</code> Delete resources <code>EXECUTE</code> Execute commands"},{"location":"concepts/rbac-model/#policy-structure","title":"Policy Structure","text":"<p>Policies are defined as <code>MonitorAccessPolicy</code> custom resources:</p> <pre><code>apiVersion: clusterpulse.io/v1alpha1\nkind: MonitorAccessPolicy\nmetadata:\n  name: policy-name\n  namespace: clusterpulse\nspec:\n  identity:\n    priority: 100\n    subjects:\n      users: []\n      groups: []\n      serviceAccounts: []\n\n  access:\n    effect: Allow | Deny\n    enabled: true\n\n  scope:\n    clusters:\n      default: all | none | filtered\n      rules:\n        - selector: {}\n          permissions: {}\n          resources: {}\n\n  lifecycle:\n    validity:\n      notBefore: \"2024-01-01T00:00:00Z\"\n      notAfter: \"2024-12-31T23:59:59Z\"\n\n  operations:\n    audit:\n      logAccess: true\n      requireReason: false\n</code></pre>"},{"location":"concepts/rbac-model/#identity-section","title":"Identity Section","text":"<p>Defines who the policy applies to and its evaluation priority.</p> <p>Priority: Integer from 0-999. Lower values are evaluated first. When multiple policies match, the first Allow or Deny decision wins.</p> <p>Subjects: Policies can target:</p> <ul> <li>Individual users by username or email</li> <li>Groups (resolved at request time from OpenShift)</li> <li>Service accounts by name and namespace</li> </ul>"},{"location":"concepts/rbac-model/#access-section","title":"Access Section","text":"<p>Effect: Determines the authorization outcome when the policy matches.</p> Effect Behavior <code>Allow</code> Grant access with specified permissions and filters <code>Deny</code> Block access regardless of other policies <p>Enabled: Boolean flag to enable/disable the policy without deleting it.</p>"},{"location":"concepts/rbac-model/#scope-section","title":"Scope Section","text":"<p>Defines which clusters and resources the policy covers.</p> <p>Default Cluster Access:</p> Value Behavior <code>all</code> Access all clusters unless restricted by rules <code>none</code> Deny by default; only rules grant access <code>filtered</code> Apply rule-based filtering <p>Rules: Array of cluster access rules, each containing:</p> <ul> <li><code>selector</code>: Label-based cluster matching</li> <li><code>permissions</code>: Actions allowed on matching clusters</li> <li><code>resources</code>: Resource-level filters</li> </ul>"},{"location":"concepts/rbac-model/#resource-filters","title":"Resource Filters","text":"<p>Each resource type supports filtering:</p> <pre><code>resources:\n  nodes:\n    visibility: all | none | filtered\n    filters:\n      hideMasters: true\n      labelSelector: {}\n\n  namespaces:\n    visibility: filtered\n    filters:\n      allowed:\n        - \"app-*\"\n      denied:\n        - \"kube-system\"\n\n  operators:\n    visibility: filtered\n    filters:\n      allowedNamespaces:\n        - \"operator-*\"\n      deniedNames:\n        - \"*-test\"\n\n  pods:\n    visibility: filtered\n    filters:\n      allowedNamespaces:\n        - \"app-*\"\n</code></pre>"},{"location":"concepts/rbac-model/#decision-types","title":"Decision Types","text":"<p>The RBAC engine returns one of three decisions:</p> Decision Description <code>ALLOW</code> Full access granted <code>DENY</code> Access blocked <code>PARTIAL</code> Access granted with filters applied <p>A <code>PARTIAL</code> decision includes filters that restrict which resources are visible.</p>"},{"location":"concepts/rbac-model/#filter-model","title":"Filter Model","text":"<p>Filters control resource visibility when <code>visibility: filtered</code> is set:</p> <pre><code>flowchart TD\n    R[Resource] --&gt; V{Visibility}\n    V --&gt;|all| A[Show All]\n    V --&gt;|none| N[Show None]\n    V --&gt;|filtered| F{Apply Filters}\n    F --&gt; E{In Exclude List?}\n    E --&gt;|yes| N\n    E --&gt;|no| I{In Include List?}\n    I --&gt;|yes| A\n    I --&gt;|no| P{Matches Pattern?}\n    P --&gt;|yes| A\n    P --&gt;|no| N</code></pre>"},{"location":"concepts/rbac-model/#filter-properties","title":"Filter Properties","text":"Property Type Description <code>visibility</code> enum <code>all</code>, <code>none</code>, or <code>filtered</code> <code>include</code> set Literal values to include <code>exclude</code> set Literal values to exclude (takes precedence) <code>patterns</code> list Wildcard patterns to match <code>labels</code> dict Label selectors"},{"location":"concepts/rbac-model/#pattern-syntax","title":"Pattern Syntax","text":"Pattern Matches <code>*</code> Any characters <code>?</code> Single character <code>app-*</code> <code>app-frontend</code>, <code>app-backend</code>, etc. <code>team-?-prod</code> <code>team-a-prod</code>, <code>team-b-prod</code>, etc."},{"location":"concepts/rbac-model/#storage-model","title":"Storage Model","text":"<p>Policies are compiled and stored in Redis for fast evaluation:</p> <pre><code>flowchart LR\n    subgraph Kubernetes\n        CRD[MonitorAccessPolicy CRD]\n    end\n\n    subgraph Controller\n        PC[Policy Controller]\n        Compiler[Compiler]\n    end\n\n    subgraph Redis\n        Policy[policy:ns:name]\n        UserIdx[policy:user:username]\n        GroupIdx[policy:group:groupname]\n        SAIdx[policy:sa:account]\n    end\n\n    CRD --&gt; PC\n    PC --&gt; Compiler\n    Compiler --&gt; Policy\n    Compiler --&gt; UserIdx\n    Compiler --&gt; GroupIdx\n    Compiler --&gt; SAIdx</code></pre>"},{"location":"concepts/rbac-model/#redis-key-patterns","title":"Redis Key Patterns","text":"Pattern Purpose <code>policy:{namespace}:{name}</code> Compiled policy data <code>policy:user:{user}</code> Policies indexed by user <code>policy:group:{group}</code> Policies indexed by group <code>policy:sa:{serviceaccount}</code> Policies indexed by service account <code>policies:all</code> Set of all policy keys <code>policies:enabled</code> Set of enabled policy keys <code>policies:by:priority</code> Sorted set by priority"},{"location":"concepts/rbac-model/#caching","title":"Caching","text":"<p>The RBAC engine supports optional decision caching:</p> <ul> <li>Cache key: <code>{principal}:{action}:{resource}</code></li> <li>Configurable TTL (default: disabled for real-time evaluation)</li> <li>Automatically invalidated when policies change</li> </ul> <p>Cache invalidation occurs when:</p> <ol> <li>A policy is created, updated, or deleted</li> <li>Policy affects users, groups, or service accounts that have cached decisions</li> <li>Manual cache clear via API</li> </ol>"},{"location":"concepts/rbac-model/#related-documentation","title":"Related Documentation","text":"<ul> <li>Policy Evaluation - Detailed evaluation algorithm</li> <li>RBAC Basics Tutorial - Hands-on introduction</li> <li>Create Read-Only Policy - Practical example</li> </ul>"},{"location":"contributing/","title":"Index","text":"<ul> <li>Contribute to the API</li> <li>Contribute to the Cluster Controller</li> <li>Contribute to the Policy Controller</li> </ul>"},{"location":"contributing/api/","title":"Contributing to ClusterPulse API","text":""},{"location":"contributing/api/#getting-started","title":"Getting Started","text":""},{"location":"contributing/api/#local-setup","title":"Local Setup","text":"<pre><code># Install dependencies\npip install -r requirements.txt\npip install -e .  # Install in dev mode\n\n# Set up environment\ncp .env.example .env\n# Edit .env - set ENVIRONMENT=development, DEBUG=True\n\n# Start Redis\ndocker run -d -p 6379:6379 redis:latest\n\n# Run the API\npython -m uvicorn clusterpulse.main:app --reload --host 0.0.0.0 --port 8080\n</code></pre> <p>API docs available at <code>http://localhost:8080/api/v1/docs</code></p>"},{"location":"contributing/api/#development-dependencies","title":"Development Dependencies","text":"<pre><code>pip install pytest pytest-cov pytest-asyncio black ruff mypy\n</code></pre>"},{"location":"contributing/api/#project-structure","title":"Project Structure","text":"<p>Here's what goes where and why it's organized this way.</p>"},{"location":"contributing/api/#directory-layout","title":"Directory Layout","text":"<pre><code>clusterpulse/\n\u251c\u2500\u2500 config/              Configuration settings\n\u251c\u2500\u2500 core/                Core utilities (logging, etc.)\n\u251c\u2500\u2500 db/                  Database and cache connections\n\u251c\u2500\u2500 models/              Pydantic models for data validation\n\u251c\u2500\u2500 repositories/        Data access layer (talks to Redis)\n\u251c\u2500\u2500 services/            Business logic (RBAC, metrics)\n\u2514\u2500\u2500 api/                 HTTP layer\n    \u251c\u2500\u2500 dependencies/    FastAPI dependencies\n    \u251c\u2500\u2500 middleware/      Request/response middleware\n    \u251c\u2500\u2500 responses/       Response builders for consistent API responses\n    \u2514\u2500\u2500 v1/              API version 1\n        \u251c\u2500\u2500 endpoints/   Route handlers\n        \u2514\u2500\u2500 router.py    Router assembly\n</code></pre>"},{"location":"contributing/api/#what-each-directory-does","title":"What Each Directory Does","text":""},{"location":"contributing/api/#config","title":"<code>config/</code>","text":"<p>Application configuration. Just settings, environment variables, that sort of thing.</p> <p>Files: - <code>settings.py</code> - All configuration (Redis host, OAuth settings, etc.)</p> <p>When to edit: - Adding a new feature flag - Adding a new environment variable - Changing default values</p> <pre><code># Example: Adding a new setting\nclass Settings(BaseSettings):\n    new_feature_enabled: bool = Field(False, env=\"NEW_FEATURE_ENABLED\")\n</code></pre>"},{"location":"contributing/api/#core","title":"<code>core/</code>","text":"<p>Utilities used throughout the app. Keep it minimal - only truly shared utilities go here.</p> <p>Files: - <code>logging.py</code> - Logging setup and helpers</p> <p>When to add here: - Shared utility functions - Common helpers - Framework setup code</p> <p>Don't put here: - Business logic (goes in <code>services/</code>) - Data access (goes in <code>repositories/</code>) - HTTP handlers (goes in <code>api/</code>)</p>"},{"location":"contributing/api/#db","title":"<code>db/</code>","text":"<p>Database and cache connections. Currently just Redis, but could expand.</p> <p>Files: - <code>redis.py</code> - Redis connection pool and client</p> <p>When to edit: - Changing Redis connection logic - Adding connection health checks - Adding a new database (Postgres, etc.)</p> <pre><code># Example: Using the Redis client\nfrom clusterpulse.db.redis import get_redis_client\n\nredis = get_redis_client()\ndata = redis.get(\"some:key\")\n</code></pre>"},{"location":"contributing/api/#models","title":"<code>models/</code>","text":"<p>Pydantic models for request/response validation and data structures.</p> <p>Files: - <code>auth.py</code> - User, AuthStatus - <code>cluster.py</code> - Cluster, Node, Metrics, etc.</p> <p>When to add here: - New API request/response models - Data structures shared across layers</p> <pre><code># Example: Adding a new model\nclass Workload(BaseModel):\n    name: str\n    namespace: str\n    replicas: int\n</code></pre>"},{"location":"contributing/api/#repositories","title":"<code>repositories/</code>","text":"<p>Data access layer. These talk to Redis (or any datastore) and return Python objects.</p> <p>Files: - <code>cluster.py</code> - Legacy ClusterRepository - <code>redis_base.py</code> - Base repository classes with optimized patterns   - <code>RedisRepository</code> - Base class with common Redis operations   - <code>ClusterDataRepository</code> - Cluster-specific data access   - <code>RegistryDataRepository</code> - Registry-specific data access</p> <p>When to add here: - New data access patterns - New CRUD operations - Complex Redis queries</p> <p>Pattern: <pre><code>from clusterpulse.repositories.redis_base import ClusterDataRepository\n\n# Use the repository\nrepo = ClusterDataRepository(redis_client)\n\n# Get all cluster data in one batch operation\nbundle = repo.get_cluster_bundle(cluster_name)\nspec = bundle['spec']\nstatus = bundle['status']\nmetrics = bundle['metrics']\ninfo = bundle['info']\n\n# Get specific resources\nnodes = repo.get_cluster_nodes(cluster_name)\noperators = repo.get_cluster_operators(cluster_name)\n</code></pre></p>"},{"location":"contributing/api/#services","title":"<code>services/</code>","text":"<p>Business logic goes here. This is where you implement features, algorithms, calculations, etc.</p> <p>Files: - <code>rbac.py</code> - RBACEngine for authorization - <code>metrics.py</code> - FilteredMetricsCalculator for calculating filtered metrics</p> <p>When to add here: - Authorization logic - Complex calculations - Business rules - Data transformation</p> <p>Pattern: <pre><code>class MyService:\n    def __init__(self, redis_client, other_deps):\n        self.redis = redis_client\n        self.other = other_deps\n\n    def do_complex_thing(self, params):\n        # Business logic here\n        pass\n</code></pre></p>"},{"location":"contributing/api/#apiv1endpoints","title":"<code>api/v1/endpoints/</code>","text":"<p>HTTP route handlers. Keep these thin - they should mostly just coordinate between services.</p> <p>Files: - <code>auth.py</code> - Authentication endpoints - <code>clusters.py</code> - Cluster management endpoints - <code>health.py</code> - Health check endpoints - <code>public.py</code> - Public API endpoints - <code>registries.py</code> - Registry endpoints</p> <p>When to add here: - New API endpoints - New HTTP handlers</p> <p>Pattern: <pre><code>from clusterpulse.api.dependencies.rbac import RBACContext, get_rbac_context\nfrom clusterpulse.repositories.redis_base import ClusterDataRepository\nfrom clusterpulse.api.responses.cluster import ClusterResponseBuilder\n\nrepo = ClusterDataRepository(redis_client)\n\n@router.get(\"/{id}\")\nasync def get_something(\n    id: str,\n    rbac: RBACContext = Depends(get_rbac_context)\n):\n    # 1. Check authorization (1 line)\n    rbac.check_cluster_access(id)\n\n    # 2. Get data from repository (1 line)\n    bundle = repo.get_cluster_bundle(id)\n\n    # 3. Build and return response (3-5 lines)\n    return (ClusterResponseBuilder(id)\n        .with_spec(bundle['spec'])\n        .with_status(bundle['status'])\n        .build())\n</code></pre></p> <p>Keep endpoints thin: - Don't put business logic here - Don't do complex calculations - Don't directly access Redis - Delegate to repositories and services</p>"},{"location":"contributing/api/#apidependencies","title":"<code>api/dependencies/</code>","text":"<p>FastAPI dependency injection functions.</p> <p>Files: - <code>auth.py</code> - User extraction, group resolution - <code>rbac.py</code> - RBAC context and utilities</p> <p>When to add here: - Reusable dependencies - Common parameter validation - Shared authorization checks</p> <p>Key Components: - <code>RBACContext</code> - Provides all RBAC operations for endpoints - <code>get_rbac_context()</code> - FastAPI dependency that injects RBAC context - <code>get_rbac_engine()</code> - Singleton RBAC engine</p> <pre><code># Using RBACContext in endpoints\n@router.get(\"/resource\")\nasync def get_resource(rbac: RBACContext = Depends(get_rbac_context)):\n    # Check access\n    rbac.check_cluster_access(cluster_name)\n\n    # Filter resources\n    filtered = rbac.filter_resources(items, ResourceType.NODE, cluster_name)\n\n    # Get accessible clusters\n    clusters = rbac.get_accessible_clusters()\n</code></pre>"},{"location":"contributing/api/#apimiddleware","title":"<code>api/middleware/</code>","text":"<p>Request/response middleware.</p> <p>Files: - <code>auth.py</code> - AuthMiddleware - <code>logging.py</code> - LoggingMiddleware</p> <p>When to add here: - Request preprocessing - Response post-processing - Cross-cutting concerns</p>"},{"location":"contributing/api/#apiresponses","title":"<code>api/responses/</code>","text":"<p>Response builder classes for consistent API responses.</p> <p>Files: - <code>cluster.py</code> - Cluster response builders - <code>registry.py</code> - Registry response builders</p> <p>When to add here: - New response builders for new resource types - Shared response formatting logic</p> <p>Pattern: <pre><code>from clusterpulse.api.responses.cluster import ClusterResponseBuilder\n\n# Build a cluster detail response\nreturn (ClusterResponseBuilder(cluster_name)\n    .with_spec(spec)\n    .with_status(status)\n    .with_info(info)\n    .with_metrics(metrics, decision)\n    .with_operator_count(count)\n    .build())\n</code></pre></p> <p>Benefits: - Consistent response format across endpoints - Easy to add new fields - Handles fallbacks and normalization - Type-safe and IDE-friendly</p>"},{"location":"contributing/api/#data-flow-example","title":"Data Flow Example","text":"<p>Here's how a request flows through the layers:</p> <pre><code># 1. HTTP Request comes in\nGET /api/v1/clusters/prod-cluster/metrics\n\n# 2. Middleware processes it\n# - LoggingMiddleware logs the request\n# - AuthMiddleware checks OAuth headers\n\n# 3. Endpoint handler (api/v1/endpoints/clusters.py)\n@router.get(\"/{cluster_name}/metrics\")\nasync def get_cluster_metrics(\n    cluster_name: str, \n    rbac: RBACContext = Depends(get_rbac_context)\n):\n    # Check access (1 line - RBAC context handles everything)\n    decision = rbac.check_cluster_access(cluster_name, Action.VIEW_METRICS)\n\n    # 4. Service layer (services/metrics.py)\n    metrics = metrics_calculator.get_filtered_cluster_metrics(\n        cluster_name, rbac.principal\n    )\n\n    return metrics\n\n# Inside metrics_calculator (service layer):\ndef get_filtered_cluster_metrics(self, cluster_name, principal):\n    # 5. Repository layer (repositories/redis_base.py)\n    base_metrics = self.repo.get_cluster_metrics(cluster_name)\n\n    # Business logic - filtering\n    filtered = self.rbac.filter_resources(...)\n\n    return self._calculate_metrics(filtered)\n\n# Inside repository:\ndef get_cluster_metrics(self, cluster_name):\n    # 6. Database layer (db/redis.py)\n    return self.get_json(f\"cluster:{cluster_name}:metrics\")\n</code></pre>"},{"location":"contributing/api/#understanding-rbac","title":"Understanding RBAC","text":"<p>RBAC is the most important part of the system. Every data access goes through RBAC filtering.</p>"},{"location":"contributing/api/#core-concepts","title":"Core Concepts","text":"<p>Principal: Who is making the request <pre><code>Principal(username=\"john.doe\", email=\"john@example.com\", groups=[\"developers\"])\n</code></pre></p> <p>Resource: What they're trying to access <pre><code>Resource(type=ResourceType.CLUSTER, name=\"prod-cluster\", cluster=\"prod-cluster\")\n</code></pre></p> <p>Request: Combines principal + action + resource <pre><code>Request(principal=principal, action=Action.VIEW, resource=resource)\n</code></pre></p> <p>Decision: Result of authorization <pre><code>decision = rbac_engine.authorize(request)\nif decision.allowed:\n    # Proceed\n</code></pre></p>"},{"location":"contributing/api/#using-rbaccontext","title":"Using RBACContext","text":"<p>The <code>RBACContext</code> class simplifies RBAC operations in endpoints:</p> <pre><code>from clusterpulse.api.dependencies.rbac import RBACContext, get_rbac_context\n\n@router.get(\"/{cluster_name}\")\nasync def get_cluster(\n    cluster_name: str,\n    rbac: RBACContext = Depends(get_rbac_context)\n):\n    # Check access - raises AuthorizationError if denied\n    decision = rbac.check_cluster_access(cluster_name)\n\n    # Check specific permissions\n    if not decision.can(Action.VIEW_METRICS):\n        # Handle case where metrics viewing is not allowed\n        pass\n\n    # Filter resources\n    nodes = get_all_nodes()\n    filtered_nodes = rbac.filter_resources(nodes, ResourceType.NODE, cluster_name)\n\n    # Get accessible clusters\n    accessible = rbac.get_accessible_clusters()\n\n    return filtered_nodes\n</code></pre> <p>RBACContext provides: - <code>check_cluster_access(cluster_name, action=Action.VIEW)</code> - Check and raise if denied - <code>filter_resources(resources, resource_type, cluster)</code> - Filter resources through RBAC - <code>get_accessible_clusters()</code> - Get all accessible cluster names - <code>has_permission(action, resource)</code> - Check specific permission - <code>principal</code> - The user's Principal object - <code>user</code> - The authenticated User object - <code>rbac</code> - The RBAC engine instance</p>"},{"location":"contributing/api/#filtering-resources","title":"Filtering Resources","text":"<p>Always filter resources through the engine:</p> <pre><code># DON'T do this:\nall_nodes = get_all_nodes()\nreturn all_nodes  # \u274c Bypasses RBAC\n\n# DO this with RBACContext:\nall_nodes = get_all_nodes()\nfiltered_nodes = rbac.filter_resources(all_nodes, ResourceType.NODE, cluster_name)\nreturn filtered_nodes  # \u2705 RBAC enforced\n\n# Or without RBACContext (when not in an endpoint):\nfrom clusterpulse.api.dependencies.rbac import get_rbac_engine\n\nrbac_engine = get_rbac_engine()\nfiltered_nodes = rbac_engine.filter_resources(\n    principal=principal,\n    resources=all_nodes,\n    resource_type=ResourceType.NODE,\n    cluster=cluster_name\n)\n</code></pre> <p>The engine applies filters from policies (namespace patterns, node selectors, etc.) and removes resources the user shouldn't see.</p>"},{"location":"contributing/api/#common-tasks","title":"Common Tasks","text":""},{"location":"contributing/api/#adding-a-new-endpoint","title":"Adding a New Endpoint","text":"<ol> <li>Create the endpoint using the new patterns:</li> </ol> <pre><code># api/v1/endpoints/clusters.py\nfrom clusterpulse.api.dependencies.rbac import RBACContext, get_rbac_context\nfrom clusterpulse.repositories.redis_base import ClusterDataRepository\nfrom clusterpulse.api.responses.cluster import ClusterResponseBuilder\n\nrepo = ClusterDataRepository(redis_client)\n\n@router.get(\"/{cluster_name}/workloads\")\nasync def get_cluster_workloads(\n    cluster_name: str,\n    rbac: RBACContext = Depends(get_rbac_context)\n) -&gt; List[Dict[str, Any]]:\n    \"\"\"Get workloads for a cluster.\"\"\"\n\n    # 1. Check cluster access (1 line)\n    rbac.check_cluster_access(cluster_name)\n\n    # 2. Get raw data from repository (1 line)\n    workloads = repo.get_cluster_resource_list(cluster_name, \"workloads\")\n\n    # 3. Filter through RBAC (1 line)\n    filtered_workloads = rbac.filter_resources(\n        workloads, \n        ResourceType.POD,  # Use POD for namespace-scoped resources\n        cluster_name\n    )\n\n    return filtered_workloads\n</code></pre> <p>Total: ~10 lines of actual logic</p> <ol> <li>Register the route (if needed):</li> </ol> <p>The route is already registered since it's in <code>api/v1/endpoints/clusters.py</code>. If you create a new router file, add it to <code>api/v1/router.py</code>.</p>"},{"location":"contributing/api/#using-response-builders","title":"Using Response Builders","text":"<p>Response builders provide consistent formatting and handle fallbacks:</p> <pre><code>from clusterpulse.api.responses.cluster import ClusterResponseBuilder\n\n@router.get(\"/{cluster_name}\")\nasync def get_cluster(\n    cluster_name: str,\n    rbac: RBACContext = Depends(get_rbac_context)\n):\n    decision = rbac.check_cluster_access(cluster_name)\n\n    # Get data in one batch\n    bundle = repo.get_cluster_bundle(cluster_name)\n\n    # Build response with builder pattern\n    builder = ClusterResponseBuilder(cluster_name)\n    builder.with_spec(bundle['spec'])\n    builder.with_status(bundle['status'])\n    builder.with_info(bundle['info'])\n\n    # Conditionally add metrics\n    if decision.can(Action.VIEW_METRICS):\n        builder.with_metrics(bundle['metrics'], decision)\n\n    return builder.build()\n</code></pre> <p>Or using method chaining:</p> <pre><code>return (ClusterResponseBuilder(cluster_name)\n    .with_spec(bundle['spec'])\n    .with_status(bundle['status'])\n    .with_info(bundle['info'])\n    .with_metrics(bundle['metrics'], decision)\n    .with_operator_count(operator_count)\n    .build())\n</code></pre> <p>Benefits: - Automatic fallbacks (missing spec/status gets defaults) - Consistent field naming (displayName normalization) - Easy to extend (add new methods) - Type-safe - Self-documenting code</p>"},{"location":"contributing/api/#creating-a-new-response-builder","title":"Creating a New Response Builder","text":"<p>If you need a builder for a new resource type:</p> <pre><code># api/responses/workload.py\n\nclass WorkloadResponseBuilder:\n    \"\"\"Builder for workload response objects.\"\"\"\n\n    def __init__(self, workload_name: str):\n        self.data = {\"name\": workload_name}\n\n    def with_spec(self, spec: Optional[Dict]) -&gt; \"WorkloadResponseBuilder\":\n        \"\"\"Add spec data.\"\"\"\n        if spec:\n            self.data[\"spec\"] = spec\n            self.data[\"replicas\"] = spec.get(\"replicas\", 1)\n        return self\n\n    def with_status(self, status: Optional[Dict]) -&gt; \"WorkloadResponseBuilder\":\n        \"\"\"Add status with fallback.\"\"\"\n        self.data[\"status\"] = status or {\"state\": \"unknown\"}\n        return self\n\n    def build(self) -&gt; Dict[str, Any]:\n        \"\"\"Build and return the final response.\"\"\"\n        return self.data\n</code></pre>"},{"location":"contributing/api/#using-repositories","title":"Using Repositories","text":"<p>Repositories provide optimized data access with batch operations:</p> <pre><code>from clusterpulse.repositories.redis_base import ClusterDataRepository\n\nrepo = ClusterDataRepository(redis_client)\n\n# Get all cluster data in one optimized batch operation\nbundle = repo.get_cluster_bundle(cluster_name)\n# Returns: {'spec': ..., 'status': ..., 'metrics': ..., 'info': ...}\n\n# Get specific resources\nnodes = repo.get_cluster_nodes(cluster_name)\noperators = repo.get_cluster_operators(cluster_name)\nnamespaces = repo.get_cluster_namespaces(cluster_name)\n\n# Get specific resource types (pods, deployments, etc.)\npods = repo.get_cluster_resource_list(cluster_name, \"pods\")\ndeployments = repo.get_cluster_resource_list(cluster_name, \"deployments\")\n\n# Get node details\nnode = repo.get_cluster_node(cluster_name, node_name)\nconditions = repo.get_node_conditions(cluster_name, node_name)\n</code></pre> <p>Repository Methods:</p> <p>ClusterDataRepository: - <code>get_cluster_bundle(cluster_name)</code> - Get spec/status/metrics/info in one batch - <code>get_cluster_spec(cluster_name)</code> - Get cluster specification - <code>get_cluster_status(cluster_name)</code> - Get cluster status - <code>get_cluster_metrics(cluster_name)</code> - Get cluster metrics - <code>get_cluster_info(cluster_name)</code> - Get cluster info (version, console URL, etc.) - <code>get_cluster_operators(cluster_name)</code> - Get operators list - <code>get_cluster_namespaces(cluster_name)</code> - Get namespace list - <code>get_cluster_nodes(cluster_name)</code> - Get all nodes - <code>get_cluster_node(cluster_name, node_name)</code> - Get specific node - <code>get_cluster_resource_list(cluster_name, resource_type)</code> - Get pods/deployments/etc. - <code>get_cluster_alerts(cluster_name)</code> - Get alerts - <code>get_cluster_events(cluster_name, limit)</code> - Get events</p> <p>RegistryDataRepository: - <code>batch_get_registry_bundles(registry_names)</code> - Get multiple registry bundles in one batch - <code>get_registry_bundle(registry_name)</code> - Get status and spec - <code>get_all_registry_names()</code> - Get all registry names - <code>get_registry_status(registry_name)</code> - Get registry status - <code>get_registry_spec(registry_name)</code> - Get registry spec</p> <p>Why use repositories: - Optimized batch operations (1 Redis call instead of N) - Consistent error handling - Type hints for return values - Centralized data access patterns - Easy to test (mock the repository)</p>"},{"location":"contributing/api/#adding-a-new-resource-type","title":"Adding a New Resource Type","text":"<p>If you need a new resource type (e.g., <code>ConfigMap</code>):</p> <ol> <li>Add to <code>ResourceType</code> enum:</li> </ol> <pre><code># services/rbac.py\nclass ResourceType(str, Enum):\n    CLUSTER = \"cluster\"\n    NODE = \"node\"\n    # ... existing types\n    CONFIGMAP = \"configmap\"  # Add this\n</code></pre> <ol> <li>Use in endpoints:</li> </ol> <pre><code>filtered_configmaps = rbac.filter_resources(\n    configmaps, \n    ResourceType.CONFIGMAP, \n    cluster_name\n)\n</code></pre>"},{"location":"contributing/api/#adding-metrics-calculations","title":"Adding Metrics Calculations","text":"<p>Metrics are calculated in <code>services/metrics.py</code>. The <code>FilteredMetricsCalculator</code> class handles this.</p> <p>Example: Add new metric:</p> <pre><code># services/metrics.py\n\ndef _calculate_filtered_metrics_via_rbac(self, cluster_name, principal, base_metrics, include_details):\n    filtered = base_metrics.copy()\n\n    # Add your new metric calculation\n    jobs_data = self.redis.get(f\"cluster:{cluster_name}:jobs\")\n    if jobs_data:\n        jobs = json.loads(jobs_data)\n        filtered_jobs = self.rbac.filter_resources(\n            principal=principal,\n            resources=jobs,\n            resource_type=ResourceType.POD,  # Use POD for namespace filtering\n            cluster=cluster_name\n        )\n\n        filtered[\"jobs\"] = len(filtered_jobs)\n        filtered[\"jobs_succeeded\"] = sum(1 for j in filtered_jobs if j.get(\"status\") == \"Succeeded\")\n\n    return filtered\n</code></pre>"},{"location":"contributing/api/#adding-new-repository-methods","title":"Adding New Repository Methods","text":"<p>To add a new data access pattern:</p> <pre><code># repositories/redis_base.py\n\nclass ClusterDataRepository(RedisRepository):\n    # ... existing methods\n\n    def get_cluster_configmaps(self, cluster_name: str) -&gt; List[Dict]:\n        \"\"\"Get configmaps for cluster.\"\"\"\n        return self.get_json_list(f\"cluster:{cluster_name}:configmaps\")\n\n    def get_cluster_secrets_count(self, cluster_name: str) -&gt; int:\n        \"\"\"Get count of secrets (not actual secret data).\"\"\"\n        data = self.get_json(f\"cluster:{cluster_name}:secrets_summary\")\n        return data.get(\"count\", 0) if data else 0\n</code></pre>"},{"location":"contributing/api/#testing","title":"Testing","text":""},{"location":"contributing/api/#write-tests-first","title":"Write Tests First","text":"<p>For new endpoints, create a test file:</p> <pre><code># tests/integration/api/test_workloads.py\n\nimport pytest\nfrom clusterpulse.services.rbac import Principal\n\n@pytest.mark.integration\nclass TestWorkloadsEndpoint:\n    def test_get_workloads_success(\n        self,\n        authenticated_client,\n        fake_redis,\n        populate_redis_with_policies,\n        basic_dev_policy\n    ):\n        \"\"\"User can see workloads they have access to.\"\"\"\n        # Setup policy\n        populate_redis_with_policies([basic_dev_policy])\n\n        # Mock group resolution\n        def mock_groups(username, email=None):\n            return [\"developers\"]\n\n        import clusterpulse.api.dependencies.auth as auth_module\n        auth_module.resolve_groups_realtime = mock_groups\n\n        # Add test data\n        workloads = [\n            {\"name\": \"app-1\", \"namespace\": \"team-a\"},\n            {\"name\": \"app-2\", \"namespace\": \"team-b\"},\n        ]\n        fake_redis.set(f\"cluster:test-cluster:workloads\", json.dumps(workloads))\n\n        # Make request\n        response = authenticated_client.get(\"/api/v1/clusters/test-cluster/workloads\")\n\n        # Verify\n        assert response.status_code == 200\n        data = response.json()\n        assert len(data) &gt; 0  # Should see some workloads based on policy\n</code></pre>"},{"location":"contributing/api/#testing-with-repositories","title":"Testing with Repositories","text":"<p>Mock repositories for cleaner tests:</p> <pre><code>from unittest.mock import Mock\nfrom clusterpulse.repositories.redis_base import ClusterDataRepository\n\ndef test_endpoint_with_mocked_repo(mocker):\n    # Mock the repository\n    mock_repo = Mock(spec=ClusterDataRepository)\n    mock_repo.get_cluster_bundle.return_value = {\n        'spec': {'displayName': 'Test Cluster'},\n        'status': {'health': 'healthy'},\n        'metrics': {'nodes': 3},\n        'info': {'version': '4.12'}\n    }\n\n    # Inject mock into endpoint\n    # ... test logic\n</code></pre>"},{"location":"contributing/api/#running-tests","title":"Running Tests","text":"<pre><code># All tests\npytest\n\n# Specific category\npytest -m unit\npytest -m integration\n\n# With coverage\npytest --cov=clusterpulse --cov-report=html\n\n# Single test\npytest tests/integration/api/test_workloads.py::TestWorkloadsEndpoint::test_get_workloads_success -v\n</code></pre>"},{"location":"contributing/api/#code-patterns","title":"Code Patterns","text":""},{"location":"contributing/api/#error-handling","title":"Error Handling","text":"<pre><code>from fastapi import HTTPException, status\nfrom clusterpulse.api.dependencies.auth import AuthorizationError\n\n# Not found\nraise HTTPException(\n    status_code=status.HTTP_404_NOT_FOUND,\n    detail=\"Resource not found\"\n)\n\n# Authorization failed (RBACContext.check_cluster_access raises this automatically)\nraise AuthorizationError(f\"Access denied to {resource_name}\")\n</code></pre>"},{"location":"contributing/api/#logging","title":"Logging","text":"<pre><code>from clusterpulse.core.logging import get_logger, log_event\n\nlogger = get_logger(__name__)\n\n# Simple log\nlogger.info(f\"User {user.username} accessed {cluster_name}\")\n\n# Structured log\nlog_event(\n    logger,\n    \"info\",\n    \"resource_accessed\",\n    user_id=user.id,\n    resource_type=\"cluster\",\n    resource_name=cluster_name,\n    action=\"view\"\n)\n</code></pre>"},{"location":"contributing/api/#redis-operations","title":"Redis Operations","text":"<p>Use repositories instead of direct Redis calls:</p> <pre><code># DON'T do this:\ndata = redis_client.get(f\"cluster:{name}:spec\")\nspec = json.loads(data) if data else None\n\n# DO this:\nfrom clusterpulse.repositories.redis_base import ClusterDataRepository\n\nrepo = ClusterDataRepository(redis_client)\nspec = repo.get_cluster_spec(name)\n</code></pre> <p>For batch operations, repositories use pipelines automatically:</p> <pre><code># This uses a single Redis pipeline internally\nbundle = repo.get_cluster_bundle(cluster_name)\n\n# This batches all registries in one pipeline\nbundles = repo.batch_get_registry_bundles(registry_names)\n</code></pre>"},{"location":"contributing/api/#code-style","title":"Code Style","text":"<p>We use <code>black</code> for formatting, <code>autoflake</code> for removing unused imports and <code>pylint</code> for linting:</p> <pre><code># Format code\nblack &lt;path&gt;\nautoflake --remove-all-unused-imports --remove-unused-variables --recursive --in-place &lt;path&gt;\nisort &lt;path&gt;\n\n# Check linting\npylint clusterpulse/\n</code></pre> <p>Import order: 1. Standard library 2. Third-party packages 3. Local application imports</p> <pre><code>import json\nfrom datetime import datetime\nfrom typing import List, Dict\n\nfrom fastapi import APIRouter, Depends\nfrom redis import Redis\n\nfrom clusterpulse.config.settings import settings\nfrom clusterpulse.api.dependencies.rbac import RBACContext, get_rbac_context\nfrom clusterpulse.repositories.redis_base import ClusterDataRepository\nfrom clusterpulse.api.responses.cluster import ClusterResponseBuilder\nfrom clusterpulse.services.rbac import RBACEngine\nfrom clusterpulse.models.cluster import Cluster\n</code></pre>"},{"location":"contributing/api/#pull-request-process","title":"Pull Request Process","text":"<ol> <li> <p>Branch naming: <code>feature/add-workloads-endpoint</code> or <code>fix/rbac-namespace-filter</code></p> </li> <li> <p>Commits: Keep them focused and descriptive</p> </li> <li>\u2705 \"Add workloads endpoint with RBAC filtering\"</li> <li> <p>\u274c \"WIP\" or \"Fix stuff\"</p> </li> <li> <p>Before submitting: <pre><code># Format and lint\nblack clusterpulse/\nautoflake...\nisort...\n\n# Run tests\npytest\n\n# Check coverage\npytest --cov=clusterpulse --cov-report=term-missing\n</code></pre></p> </li> <li> <p>PR description should include:</p> </li> <li>What changed and why</li> <li>How to test it</li> <li>Any security implications</li> <li> <p>Related issues</p> </li> <li> <p>Things reviewers look for:</p> </li> <li>RBAC filtering is applied correctly</li> <li>No data leaks (all resources filtered)</li> <li>Tests cover new functionality</li> <li>Error handling is appropriate</li> <li>Logging added for important operations</li> <li>Using repositories instead of direct Redis calls</li> <li>Using RBACContext instead of manual RBAC operations</li> <li>Using response builders for consistency</li> </ol>"},{"location":"contributing/api/#security-considerations","title":"Security Considerations","text":""},{"location":"contributing/api/#always-filter-resources","title":"Always Filter Resources","text":"<pre><code># \u274c NEVER return raw data without filtering\n@router.get(\"/nodes\")\nasync def get_nodes():\n    nodes = get_all_nodes()\n    return nodes  # Security issue!\n\n# \u2705 ALWAYS filter through RBAC using RBACContext\n@router.get(\"/nodes\")\nasync def get_nodes(rbac: RBACContext = Depends(get_rbac_context)):\n    nodes = repo.get_cluster_nodes(cluster_name)\n    filtered = rbac.filter_resources(nodes, ResourceType.NODE, cluster_name)\n    return filtered  # Safe\n</code></pre>"},{"location":"contributing/api/#check-permissions-for-sensitive-actions","title":"Check Permissions for Sensitive Actions","text":"<pre><code># Check specific permissions using RBACContext\ndecision = rbac.check_cluster_access(cluster_name, Action.VIEW_SENSITIVE)\n\nif not decision.can(Action.VIEW_SENSITIVE):\n    raise AuthorizationError(\"Cannot view sensitive data\")\n</code></pre>"},{"location":"contributing/api/#input-validation","title":"Input Validation","text":"<pre><code>from pydantic import BaseModel, validator\n\nclass WorkloadFilter(BaseModel):\n    namespace: Optional[str]\n    status: Optional[str]\n\n    @validator('status')\n    def validate_status(cls, v):\n        allowed = ['Running', 'Pending', 'Failed']\n        if v and v not in allowed:\n            raise ValueError(f'Status must be one of {allowed}')\n        return v\n</code></pre>"},{"location":"contributing/api/#common-pitfalls","title":"Common Pitfalls","text":"<ol> <li> <p>Forgetting to filter resources: Always use <code>rbac.filter_resources()</code> or <code>rbac_engine.filter_resources()</code></p> </li> <li> <p>Not mocking group resolution in tests: Tests will fail without it    <pre><code>def mock_resolve_groups(username, email=None):\n    return [\"developers\"]\n\nimport clusterpulse.api.dependencies.auth as auth_module\nauth_module.resolve_groups_realtime = mock_resolve_groups\n</code></pre></p> </li> <li> <p>Using wrong <code>ResourceType</code> for filtering: Namespace-scoped resources should use <code>ResourceType.POD</code> for filtering</p> </li> <li> <p>Direct Redis access instead of repositories: Use <code>ClusterDataRepository</code> methods for type safety and batching</p> </li> <li> <p>Manual dict building instead of response builders: Use builder classes for consistent formatting</p> </li> <li> <p>Not using RBACContext: Use <code>RBACContext</code> dependency instead of manually creating Principal/Request objects</p> </li> <li> <p>N+1 queries: Repositories handle batching automatically, but be aware when making multiple repository calls</p> </li> </ol>"},{"location":"contributing/api/#getting-help","title":"Getting Help","text":"<ul> <li>Check existing code in <code>api/v1/endpoints/clusters.py</code> for patterns</li> <li>Look at <code>api/responses/cluster.py</code> for response builder examples</li> <li>Look at <code>repositories/redis_base.py</code> for data access patterns</li> <li>Check <code>api/dependencies/rbac.py</code> for RBAC utilities</li> <li>Look at tests in <code>tests/integration/api/</code> for examples</li> <li>Read the RBAC engine code in <code>services/rbac.py</code> to understand filtering</li> </ul>"},{"location":"contributing/api/#project-specific-notes","title":"Project-Specific Notes","text":"<ul> <li>Group resolution is real-time: Every request queries OpenShift for current group membership</li> <li>Caching is disabled by default: RBAC decisions are not cached (security over speed)</li> <li>Policies are in Redis: The Policy Controller manages them, but you can inspect with <code>redis-cli</code></li> <li>Metrics are pre-calculated: The Cluster Controller writes metrics to Redis, we just filter them</li> <li>Use repositories for data access: Don't access Redis directly - use <code>ClusterDataRepository</code> or <code>RegistryDataRepository</code></li> <li>Use RBACContext in endpoints: Simplifies authorization checks and resource filtering</li> <li>Use response builders: Ensures consistent API responses and handles fallbacks</li> </ul>"},{"location":"contributing/api/#quick-reference","title":"Quick Reference","text":""},{"location":"contributing/api/#typical-endpoint-structure","title":"Typical Endpoint Structure","text":"<pre><code>from clusterpulse.api.dependencies.rbac import RBACContext, get_rbac_context\nfrom clusterpulse.repositories.redis_base import ClusterDataRepository\nfrom clusterpulse.api.responses.cluster import ClusterResponseBuilder\n\nrepo = ClusterDataRepository(redis_client)\n\n@router.get(\"/{cluster_name}/resource\")\nasync def get_resource(\n    cluster_name: str,\n    rbac: RBACContext = Depends(get_rbac_context)\n):\n    # 1. Check access\n    rbac.check_cluster_access(cluster_name)\n\n    # 2. Get data\n    data = repo.get_cluster_resource_list(cluster_name, \"resource\")\n\n    # 3. Filter\n    filtered = rbac.filter_resources(data, ResourceType.POD, cluster_name)\n\n    # 4. Return\n    return filtered\n</code></pre>"},{"location":"contributing/api/#common-imports","title":"Common Imports","text":"<pre><code># Dependencies\nfrom clusterpulse.api.dependencies.rbac import RBACContext, get_rbac_context\n\n# Repositories\nfrom clusterpulse.repositories.redis_base import ClusterDataRepository, RegistryDataRepository\n\n# Response builders\nfrom clusterpulse.api.responses.cluster import ClusterResponseBuilder, ClusterListItemBuilder\nfrom clusterpulse.api.responses.registry import RegistryStatusBuilder\n\n# RBAC types\nfrom clusterpulse.services.rbac import Action, ResourceType, Principal, Resource\n</code></pre>"},{"location":"contributing/cluster-controller/","title":"Contributing to ClusterPulse Cluster Controller","text":""},{"location":"contributing/cluster-controller/#getting-started","title":"Getting Started","text":""},{"location":"contributing/cluster-controller/#local-setup","title":"Local Setup","text":"<pre><code># Install dependencies\n# Requires Go 1.21+ and kubebuilder\ngo mod download\n\n# Install kubebuilder (for CRD generation)\ncurl -L -o kubebuilder https://go.kubebuilder.io/dl/latest/$(go env GOOS)/$(go env GOARCH)\nchmod +x kubebuilder &amp;&amp; mv kubebuilder /usr/local/bin/\n\n# Set up environment\nexport NAMESPACE=clusterpulse\nexport REDIS_HOST=localhost\nexport REDIS_PORT=6379\n\n# Start Redis\ndocker run -d -p 6379:6379 redis:latest\n\n# Generate CRDs and deep copy code\ncontroller-gen object paths=\"./...\"\ncontroller-gen crd paths=\"./...\" output:crd:artifacts:config=config/crd/bases\n\n# Run locally (connects to your current kubeconfig cluster)\ngo run cmd/manager/main.go --namespace=clusterpulse\n</code></pre>"},{"location":"contributing/cluster-controller/#development-dependencies","title":"Development Dependencies","text":"<pre><code># Install development tools\ngo install sigs.k8s.io/controller-tools/cmd/controller-gen@latest\ngo install github.com/golangci/golangci-lint/cmd/golangci-lint@latest\n</code></pre>"},{"location":"contributing/cluster-controller/#project-structure","title":"Project Structure","text":"<p>Here's what goes where and why it's organized this way.</p>"},{"location":"contributing/cluster-controller/#directory-layout","title":"Directory Layout","text":"<pre><code>cluster-controller/\n\u251c\u2500\u2500 api/v1alpha1/            Custom Resource Definitions (CRDs)\n\u251c\u2500\u2500 cmd/manager/             Main entry point\n\u251c\u2500\u2500 internal/\n\u2502   \u251c\u2500\u2500 client/              Cluster and registry clients\n\u2502   \u2502   \u251c\u2500\u2500 cluster/         Kubernetes cluster client\n\u2502   \u2502   \u251c\u2500\u2500 registry/        Docker registry client\n\u2502   \u2502   \u2514\u2500\u2500 pool/            Client connection pooling\n\u2502   \u251c\u2500\u2500 controller/          Reconciliation controllers\n\u2502   \u2502   \u251c\u2500\u2500 cluster/         ClusterConnection reconciler\n\u2502   \u2502   \u2514\u2500\u2500 registry/        RegistryConnection reconciler\n\u2502   \u251c\u2500\u2500 store/               Redis storage layer\n\u2502   \u2514\u2500\u2500 config/              Configuration management\n\u251c\u2500\u2500 pkg/\n\u2502   \u251c\u2500\u2500 types/               Shared type definitions\n\u2502   \u2502   \u251c\u2500\u2500 types.go         Core types (NodeMetrics, ClusterMetrics, etc.)\n\u2502   \u2502   \u2514\u2500\u2500 resources.go     Resource collection types (PodSummary, etc.)\n\u2502   \u2514\u2500\u2500 utils/               Common utilities\n\u2502       \u251c\u2500\u2500 parser.go        CPU and memory parsing utilities\n\u2502       \u2514\u2500\u2500 circuit_breaker.go Circuit breaker implementation\n\u2514\u2500\u2500 config/                  Kubernetes manifests and CRDs\n</code></pre>"},{"location":"contributing/cluster-controller/#what-each-directory-does","title":"What Each Directory Does","text":""},{"location":"contributing/cluster-controller/#apiv1alpha1","title":"<code>api/v1alpha1/</code>","text":"<p>Custom Resource Definitions. These define the API schema for ClusterConnection and RegistryConnection resources.</p> <p>Files: - <code>groupversion_info.go</code> - API group registration (<code>clusterpulse.io/v1alpha1</code>) - <code>clusterconnection_types.go</code> - ClusterConnection CRD schema - <code>registryconnection_types.go</code> - RegistryConnection CRD schema - <code>zz_generated.deepcopy.go</code> - Auto-generated deep copy methods (don't edit)</p> <p>When to edit: - Adding new fields to CRDs - Changing validation rules - Adding new status fields - Modifying kubebuilder markers for oc output columns</p> <p>Pattern: <pre><code>// Add a new field to ClusterConnectionSpec\ntype ClusterConnectionSpec struct {\n    // Existing fields...\n\n    // NewField does something useful\n    // +optional\n    NewField string `json:\"newField,omitempty\"`\n}\n\n// After editing, regenerate:\n// controller-gen object paths=\"./...\"\n// controller-gen crd paths=\"./...\" output:crd:artifacts:config=config/crd/bases\n</code></pre></p> <p>Kubebuilder markers you'll use: <pre><code>// +kubebuilder:validation:Required\n// +kubebuilder:validation:MinLength=1\n// +kubebuilder:validation:Minimum=30\n// +kubebuilder:default=30\n// +optional\n// +kubebuilder:printcolumn:name=\"Status\",type=\"string\",JSONPath=\".status.phase\"\n</code></pre></p>"},{"location":"contributing/cluster-controller/#cmdmanager","title":"<code>cmd/manager/</code>","text":"<p>Application entry point. Sets up the controller manager and starts all reconcilers.</p> <p>Files: - <code>main.go</code> - Initializes manager, registers controllers, starts server</p> <p>When to edit: - Adding new controllers - Changing manager configuration - Modifying health check endpoints - Adjusting leader election settings</p> <p>Pattern: <pre><code>// Register a new controller\nif err = (&amp;newcontroller.NewReconciler{\n    Client:      mgr.GetClient(),\n    Scheme:      mgr.GetScheme(),\n    RedisClient: redisClient,\n    Config:      cfg,\n}).SetupWithManager(mgr); err != nil {\n    setupLog.Error(err, \"unable to create controller\")\n    os.Exit(1)\n}\n</code></pre></p>"},{"location":"contributing/cluster-controller/#internalclientcluster","title":"<code>internal/client/cluster/</code>","text":"<p>Kubernetes cluster client implementation. Connects to remote clusters, collects metrics, gets resource information.</p> <p>Files: - <code>client.go</code> - Main cluster client, connection management - <code>resources.go</code> - Resource collection (pods, deployments, services)</p> <p>When to edit: - Adding new resource collection - Modifying metrics calculation - Implementing new health checks - Changing how node metrics are extracted</p> <p>Key methods: <pre><code>// TestConnection - Verifies cluster is accessible\nfunc (c *ClusterClient) TestConnection(ctx context.Context) error\n\n// GetNodeMetrics - Collects detailed metrics from all nodes\nfunc (c *ClusterClient) GetNodeMetrics(ctx context.Context) ([]types.NodeMetrics, error)\n\n// GetClusterMetrics - Aggregates cluster-wide metrics\nfunc (c *ClusterClient) GetClusterMetrics(ctx context.Context) (*types.ClusterMetrics, error)\n\n// GetOperators - Retrieves OLM operator information\nfunc (c *ClusterClient) GetOperators(ctx context.Context) ([]types.OperatorInfo, error)\n\n// GetResourceCollection - Collects lightweight resource data for RBAC\nfunc (c *ClusterClient) GetResourceCollection(ctx context.Context, config types.CollectionConfig) (*types.ResourceCollection, error)\n</code></pre></p> <p>Important: All methods use circuit breakers and timeouts to prevent hanging on unhealthy clusters.</p>"},{"location":"contributing/cluster-controller/#internalclientregistry","title":"<code>internal/client/registry/</code>","text":"<p>Docker Registry v2 API client for health checking and catalog access.</p> <p>Files: - <code>client.go</code> - Registry client implementation</p> <p>When to edit: - Adding new registry feature detection - Modifying health check logic - Adding authentication methods - Changing catalog retrieval</p> <p>Key pattern: <pre><code>// All registries use Docker v2 API\nclient := registry.NewDockerV2Client(\n    endpoint,\n    username,\n    password,\n    insecure,\n    skipTLSVerify,\n)\n\n// Health check\nresult, err := client.HealthCheck(ctx)\n\n// Optional catalog access\ncatalog, err := client.CheckCatalog(ctx, maxEntries)\n</code></pre></p>"},{"location":"contributing/cluster-controller/#internalclientpool","title":"<code>internal/client/pool/</code>","text":"<p>Connection pool for cluster clients. Reuses connections and cleans up idle clients.</p> <p>Files: - <code>pool.go</code> - Client pool implementation</p> <p>Why it exists: Creating new Kubernetes clients is expensive. The pool reuses existing clients and tests them before returning.</p> <p>When to edit: - Changing idle timeout - Modifying connection test logic - Adding pool metrics</p> <p>Usage: <pre><code>// Get client from pool (creates if needed, reuses if exists)\nclient, err := pool.Get(name, endpoint, token, caCert)\n\n// Remove from pool (on cluster deletion)\npool.Remove(name)\n</code></pre></p>"},{"location":"contributing/cluster-controller/#internalcontrollercluster","title":"<code>internal/controller/cluster/</code>","text":"<p>ClusterConnection reconciliation controller. This is where the main cluster monitoring logic lives.</p> <p>Files: - <code>cluster_controller.go</code> - Reconciler implementation</p> <p>When to edit: - Changing reconciliation interval logic - Adding new metrics collection - Modifying health calculation - Changing status update logic</p> <p>Reconciliation flow: <pre><code>func (r *ClusterReconciler) Reconcile(ctx context.Context, req reconcile.Request) (reconcile.Result, error) {\n    // 1. Fetch ClusterConnection resource\n    // 2. Handle deletion if needed\n    // 3. Get cluster client from pool\n    // 4. Test connection\n    // 5. Collect metrics in parallel (errgroup)\n    //    - Node metrics\n    //    - Cluster metrics\n    //    - Operators\n    //    - Resource collection (if enabled)\n    //    - ClusterOperators (OpenShift)\n    // 6. Store everything in Redis\n    // 7. Calculate health status\n    // 8. Update CRD status\n    // 9. Return with RequeueAfter for periodic reconciliation\n\n    return reconcile.Result{RequeueAfter: time.Duration(interval) * time.Second}, nil\n}\n</code></pre></p> <p>Critical points: - Always returns <code>RequeueAfter</code> to ensure periodic reconciliation - Uses <code>errgroup</code> for parallel metric collection - Stores data in Python-compatible format in Redis - Updates status using <code>Patch</code> to avoid triggering reconciliation - Only logs at Info level for significant events</p>"},{"location":"contributing/cluster-controller/#internalcontrollerregistry","title":"<code>internal/controller/registry/</code>","text":"<p>RegistryConnection reconciliation controller. Monitors Docker registries.</p> <p>Files: - <code>registry_controller.go</code> - Reconciler implementation</p> <p>Similar to cluster controller but simpler: 1. Fetch RegistryConnection resource 2. Create registry client 3. Perform health check 4. Store results in Redis 5. Update status 6. Requeue</p> <p>Key difference: Uses event filtering to avoid status-only update loops: <pre><code>pred := predicate.Funcs{\n    UpdateFunc: func(e event.UpdateEvent) bool {\n        oldReg, okOld := e.ObjectOld.(*v1alpha1.RegistryConnection)\n        newReg, okNew := e.ObjectNew.(*v1alpha1.RegistryConnection)\n\n        // Only reconcile if generation changed (spec change)\n        if oldReg.Generation != newReg.Generation {\n            return true\n        }\n\n        // Ignore status-only updates\n        return false\n    },\n}\n</code></pre></p>"},{"location":"contributing/cluster-controller/#internalstore","title":"<code>internal/store/</code>","text":"<p>Redis storage layer. Writes data in Python-compatible format for the API to consume.</p> <p>Files: - <code>client.go</code> - Main Redis client and cluster/operator storage - <code>registry_storage.go</code> - Registry-specific storage - <code>resource_storage.go</code> - Resource collection storage</p> <p>Critical: All data must be Python-compatible - Arrays must never be <code>nil</code> (use <code>[]string{}</code> instead) - Use snake_case for keys (e.g., <code>cpu_capacity</code>, not <code>cpuCapacity</code>) - Store timestamps in RFC3339 format - Use proper type conversions (JSON numbers become <code>float64</code> in Go)</p> <p>Pattern: <pre><code>// Convert Go struct to Python-compatible map\nmetricsDict := map[string]interface{}{\n    \"timestamp\":       metrics.Timestamp.Format(time.RFC3339),\n    \"nodes\":           metrics.Nodes,\n    \"nodes_ready\":     metrics.NodesReady,\n    \"cpu_capacity\":    metrics.CPUCapacity,\n    \"memory_capacity\": metrics.MemoryCapacity,\n}\n\n// Store with TTL\ndata, _ := json.Marshal(metricsDict)\npipe.Set(ctx, key, string(data), time.Duration(c.config.CacheTTL)*time.Second)\n</code></pre></p> <p>When to edit: - Adding new Redis keys - Changing data format - Adding new storage methods - Modifying TTL strategies</p> <p>Important storage methods: <pre><code>// Cluster data\nStoreClusterSpec(ctx, name, spec)\nStoreClusterStatus(ctx, name, status)\nStoreClusterMetrics(ctx, name, metrics)\nStoreNodeMetrics(ctx, name, nodeMetrics)\nStoreOperators(ctx, name, operators)\nStoreClusterOperators(ctx, name, clusterOperators)\nStoreResourceCollection(ctx, name, collection)\n\n// Registry data\nStoreRegistrySpec(ctx, name, spec)\nStoreRegistryStatus(ctx, name, status)\nStoreRegistryMetrics(ctx, name, metrics)\n</code></pre></p>"},{"location":"contributing/cluster-controller/#internalconfig","title":"<code>internal/config/</code>","text":"<p>Configuration management from environment variables.</p> <p>Files: - <code>config.go</code> - Configuration struct and loading</p> <p>When to edit: - Adding new configuration options - Changing default values - Adding validation</p> <p>Pattern: <pre><code>// Add a new config field\ntype Config struct {\n    // Existing fields...\n\n    // New configuration\n    NewFeatureEnabled bool\n    NewFeatureTimeout int\n}\n\n// Load from environment\nfunc Load() *Config {\n    cfg := &amp;Config{\n        // ...\n        NewFeatureEnabled: getEnvBool(\"NEW_FEATURE_ENABLED\", false),\n        NewFeatureTimeout: getEnvIntWithMin(\"NEW_FEATURE_TIMEOUT\", 30, 5),\n    }\n    return cfg\n}\n</code></pre></p> <p>Available config: - <code>ReconciliationInterval</code> - How often to reconcile (default 30s) - <code>ConnectTimeout</code> - Cluster connection timeout (default 10s) - <code>CacheTTL</code> - Redis cache TTL (default 600s) - <code>MetricsRetention</code> - How long to keep time series (default 3600s) - <code>ResourceCollection</code> - Resource collection limits and settings - Threshold values for health calculations</p>"},{"location":"contributing/cluster-controller/#pkgtypes","title":"<code>pkg/types/</code>","text":"<p>Shared type definitions that are used across the project. This is the key distinction from <code>internal/</code> - types in <code>pkg/</code> can be imported by external packages.</p> <p>Files: - <code>types.go</code> - Core cluster and node types - <code>resources.go</code> - Resource collection types for RBAC filtering</p> <p>When to use pkg/types/ vs internal/: - Use <code>pkg/types/</code> for types that define the domain model and might be used by external tools - Use types in <code>internal/</code> for implementation details specific to controllers or clients</p> <p>types.go - Core Types:</p> <pre><code>// Health status constants\ntype ClusterHealth string\nconst (\n    HealthHealthy   ClusterHealth = \"healthy\"\n    HealthDegraded  ClusterHealth = \"degraded\"\n    HealthUnhealthy ClusterHealth = \"unhealthy\"\n    HealthUnknown   ClusterHealth = \"unknown\"\n)\n\n// Node status constants\ntype NodeStatus string\nconst (\n    NodeReady              NodeStatus = \"Ready\"\n    NodeNotReady           NodeStatus = \"NotReady\"\n    NodeUnknown            NodeStatus = \"Unknown\"\n    NodeSchedulingDisabled NodeStatus = \"SchedulingDisabled\"\n)\n\n// NodeMetrics contains detailed metrics for a single node\ntype NodeMetrics struct {\n    Name       string\n    Timestamp  time.Time\n    Status     string\n    Roles      []string\n    Conditions []NodeCondition\n\n    // Resource capacity and usage\n    CPUCapacity        float64\n    MemoryCapacity     int64\n    CPURequested       float64\n    MemoryRequested    int64\n    CPUUsagePercent    float64\n    MemoryUsagePercent float64\n\n    // Pod counts\n    PodsRunning   int32\n    PodsPending   int32\n    PodsFailed    int32\n    PodsTotal     int32\n\n    // System info\n    KernelVersion    string\n    OSImage          string\n    ContainerRuntime string\n    KubeletVersion   string\n\n    // Network and labels\n    InternalIP  string\n    ExternalIP  string\n    Labels      map[string]string\n    Annotations map[string]string\n}\n\n// ClusterMetrics contains cluster-wide aggregated metrics\ntype ClusterMetrics struct {\n    Timestamp     time.Time\n    Nodes         int\n    NodesReady    int\n    NodesNotReady int\n    Namespaces    int\n    NamespaceList []string\n    Pods          int\n    PodsRunning   int\n    PodsPending   int\n    PodsFailed    int\n\n    // Aggregated resources\n    CPUCapacity        float64\n    CPUAllocatable     float64\n    CPURequested       float64\n    CPUUsagePercent    float64\n    MemoryCapacity     int64\n    MemoryAllocatable  int64\n    MemoryRequested    int64\n    MemoryUsagePercent float64\n\n    // Workload counts\n    Services     int\n    Deployments  int\n    StatefulSets int\n    DaemonSets   int\n}\n\n// OperatorInfo for OLM operators\ntype OperatorInfo struct {\n    Name               string\n    DisplayName        string\n    Version            string\n    Status             string\n    InstalledNamespace string\n    Provider           string\n    CreatedAt          time.Time\n    IsClusterWide      bool\n}\n\n// ClusterOperatorInfo for OpenShift ClusterOperators\ntype ClusterOperatorInfo struct {\n    Name               string\n    Version            string\n    Available          bool\n    Progressing        bool\n    Degraded           bool\n    Upgradeable        bool\n    Message            string\n    LastTransitionTime time.Time\n    Conditions         []ClusterOperatorCondition\n    Versions           []ClusterOperatorVersion\n}\n</code></pre> <p>When to add types here: - Core domain models (nodes, clusters, metrics) - Types returned by client methods - Types stored in Redis - Types that define the system's data model</p> <p>resources.go - Resource Collection Types:</p> <p>These types are specifically designed for RBAC filtering and are optimized for memory efficiency:</p> <pre><code>// ResourceCollection holds lightweight resource data for RBAC filtering\n// Designed to be memory-efficient and fast to serialize\ntype ResourceCollection struct {\n    Timestamp   time.Time\n    Pods        []PodSummary\n    Deployments []DeploymentSummary\n    Services    []ServiceSummary\n    StatefulSets []StatefulSetSummary\n    DaemonSets  []DaemonSetSummary\n\n    // Metadata for performance monitoring\n    CollectionTimeMs int64\n    Truncated       bool\n    TotalResources  int\n}\n\n// PodSummary - minimal pod info for RBAC filtering\ntype PodSummary struct {\n    Name      string\n    Namespace string\n    Status    string\n    Node      string\n    Labels    map[string]string `json:\"labels,omitempty\"` // Only if needed\n}\n\n// DeploymentSummary - minimal deployment info\ntype DeploymentSummary struct {\n    Name      string\n    Namespace string\n    Replicas  int32\n    Ready     int32\n    Labels    map[string]string `json:\"labels,omitempty\"`\n}\n\n// CollectionConfig controls resource collection behavior\ntype CollectionConfig struct {\n    Enabled          bool\n    MaxPodsPerNS     int    // Limit pods per namespace\n    MaxTotalPods     int    // Global pod limit\n    MaxDeployments   int\n    MaxServices      int\n    IncludeLabels    bool   // Whether to collect labels\n    NamespaceFilter  string // Regex to filter namespaces\n}\n</code></pre> <p>Why these types are separate: - Specifically designed for RBAC filtering use case - Memory-optimized (minimal fields) - Fast serialization for Redis storage - Configurable collection limits</p> <p>When to add types here: - New resource summary types for RBAC - Additional resource collection configs - Metadata for collection performance</p> <p>Pattern for adding a new resource summary:</p> <pre><code>// ConfigMapSummary - minimal configmap info\ntype ConfigMapSummary struct {\n    Name      string            `json:\"name\"`\n    Namespace string            `json:\"namespace\"`\n    DataCount int               `json:\"data_count\"`\n    Labels    map[string]string `json:\"labels,omitempty\"`\n}\n\n// Then add to ResourceCollection:\ntype ResourceCollection struct {\n    // ... existing fields\n    ConfigMaps []ConfigMapSummary `json:\"configmaps,omitempty\"`\n}\n\n// And add to CollectionConfig:\ntype CollectionConfig struct {\n    // ... existing fields\n    MaxConfigMaps int `json:\"max_configmaps\"`\n}\n</code></pre>"},{"location":"contributing/cluster-controller/#pkgutils","title":"<code>pkg/utils/</code>","text":"<p>Shared utility functions used throughout the project. These are pure functions with no dependencies on internal implementation details.</p> <p>Files: - <code>parser.go</code> - CPU and memory parsing utilities - <code>circuit_breaker.go</code> - Circuit breaker implementation</p> <p>When to use pkg/utils/ vs internal/: - Use <code>pkg/utils/</code> for pure utility functions that could be used by external tools - Use utilities in <code>internal/</code> for implementation-specific helpers</p> <p>parser.go - Resource Parsing:</p> <p>Parses Kubernetes resource strings (CPU and memory) into usable numeric values:</p> <pre><code>// ParseCPU converts various CPU formats to float64 cores\nfunc ParseCPU(cpu string) float64\n\n// ParseMemory converts various memory formats to int64 bytes  \nfunc ParseMemory(mem string) int64\n</code></pre> <p>CPU parsing examples: <pre><code>ParseCPU(\"2\")        // 2.0 cores\nParseCPU(\"500m\")     // 0.5 cores (millicores)\nParseCPU(\"100m\")     // 0.1 cores\nParseCPU(\"1000u\")    // 0.001 cores (microcores)\nParseCPU(\"1000n\")    // 0.000001 cores (nanocores)\nParseCPU(\"\")         // 0.0 (empty/invalid)\n</code></pre></p> <p>Memory parsing examples: <pre><code>ParseMemory(\"1024\")     // 1024 bytes\nParseMemory(\"1Ki\")      // 1024 bytes (binary)\nParseMemory(\"1Mi\")      // 1048576 bytes (1024*1024)\nParseMemory(\"1Gi\")      // 1073741824 bytes\nParseMemory(\"1K\")       // 1000 bytes (decimal)\nParseMemory(\"1M\")       // 1000000 bytes\nParseMemory(\"1G\")       // 1000000000 bytes\nParseMemory(\"500Mi\")    // 524288000 bytes\nParseMemory(\"\")         // 0 (empty/invalid)\n</code></pre></p> <p>Usage in code: <pre><code>import \"github.com/clusterpulse/cluster-controller/pkg/utils\"\n\n// Parse container resource requests\ncpuRequest := container.Resources.Requests.Cpu().String()\ncpuCores := utils.ParseCPU(cpuRequest)\n\nmemRequest := container.Resources.Requests.Memory().String()\nmemBytes := utils.ParseMemory(memRequest)\n\n// Calculate percentages\ncpuPercent := (cpuCores / nodeCPUCapacity) * 100\nmemPercent := float64(memBytes) / float64(nodeMemCapacity) * 100\n</code></pre></p> <p>When to use: - Converting Kubernetes resource quantities to numbers - Calculating resource usage percentages - Aggregating resource requests across pods - Any time you need to work with CPU or memory values numerically</p> <p>circuit_breaker.go - Circuit Breaker Pattern:</p> <p>Implements the circuit breaker pattern to prevent cascading failures when calling unreliable services:</p> <pre><code>type CircuitBreaker struct {\n    failureThreshold int           // Number of failures before opening\n    recoveryTimeout  time.Duration // How long to wait before trying again\n    state            string         // \"closed\", \"open\", or \"half-open\"\n}\n\n// NewCircuitBreaker creates a new circuit breaker\nfunc NewCircuitBreaker(threshold int, timeout time.Duration) *CircuitBreaker\n\n// Call executes a function with circuit breaker protection\nfunc (cb *CircuitBreaker) Call(ctx context.Context, fn func(context.Context) error) error\n</code></pre> <p>Circuit breaker states: - Closed - Normal operation, requests pass through - Open - Too many failures, requests immediately fail - Half-open - Testing if service recovered, single request allowed</p> <p>State transitions: <pre><code>Closed --&gt; (failures &gt;= threshold) --&gt; Open\nOpen --&gt; (after recovery timeout) --&gt; Half-open\nHalf-open --&gt; (success) --&gt; Closed\nHalf-open --&gt; (failure) --&gt; Open\n</code></pre></p> <p>Usage in cluster client: <pre><code>import \"github.com/clusterpulse/cluster-controller/pkg/utils\"\n\ntype ClusterClient struct {\n    circuitBreaker *utils.CircuitBreaker\n    // ... other fields\n}\n\nfunc NewClusterClient(...) *ClusterClient {\n    return &amp;ClusterClient{\n        circuitBreaker: utils.NewCircuitBreaker(\n            5,              // Open after 5 failures\n            60*time.Second, // Try again after 60 seconds\n        ),\n    }\n}\n\n// Wrap API calls with circuit breaker\nfunc (c *ClusterClient) GetNodes(ctx context.Context) ([]corev1.Node, error) {\n    var nodes []corev1.Node\n\n    err := c.circuitBreaker.Call(ctx, func(ctx context.Context) error {\n        nodeList, err := c.clientset.CoreV1().Nodes().List(ctx, metav1.ListOptions{})\n        if err != nil {\n            return err\n        }\n        nodes = nodeList.Items\n        return nil\n    })\n\n    return nodes, err\n}\n</code></pre></p> <p>Why use circuit breakers: - Prevent hanging on unhealthy clusters - Fast-fail when cluster is known to be down - Automatic recovery testing - Protect controller from cascading failures</p> <p>When to use: - Wrapping all external cluster API calls - Any operation that might hang or fail repeatedly - Operations that should fail fast when service is down</p> <p>Pattern for adding new utilities:</p> <pre><code>// pkg/utils/validator.go\n\npackage utils\n\nimport \"net/url\"\n\n// ValidateURL checks if a string is a valid URL\nfunc ValidateURL(urlStr string) error {\n    _, err := url.Parse(urlStr)\n    return err\n}\n\n// ValidateNamespace checks if namespace name is valid\nfunc ValidateNamespace(name string) bool {\n    // Kubernetes namespace validation logic\n    return len(name) &lt;= 63 &amp;&amp; len(name) &gt; 0\n}\n</code></pre> <p>Key principles for pkg/utils: - Pure functions with no side effects - No dependencies on internal packages - Clear, focused purpose - Good error handling - Comprehensive documentation</p>"},{"location":"contributing/cluster-controller/#understanding-reconciliation","title":"Understanding Reconciliation","text":"<p>Reconciliation is the core concept. The controller watches CRDs and reconciles them to desired state.</p>"},{"location":"contributing/cluster-controller/#the-reconciliation-loop","title":"The Reconciliation Loop","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 1. Watch for ClusterConnection changes              \u2502\n\u2502    - Created, Updated, Deleted                      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                  \u2502\n                  \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 2. Reconcile(ctx, request)                          \u2502\n\u2502    - Fetch the ClusterConnection resource           \u2502\n\u2502    - Handle if deleted                              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                  \u2502\n                  \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 3. Get cluster client from pool                     \u2502\n\u2502    - Retrieve credentials from Secret               \u2502\n\u2502    - Create or reuse client                         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                  \u2502\n                  \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 4. Test connection                                  \u2502\n\u2502    - Try to list namespaces with timeout           \u2502\n\u2502    - Fail if unreachable                           \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                  \u2502\n                  \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 5. Collect metrics (parallel)                       \u2502\n\u2502    - Node metrics + cluster metrics + operators     \u2502\n\u2502    - Resource collection (if enabled)               \u2502\n\u2502    - ClusterOperators (OpenShift)                   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                  \u2502\n                  \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 6. Store in Redis (Python-compatible format)        \u2502\n\u2502    - Metrics, status, info, operators               \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                  \u2502\n                  \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 7. Calculate health and update status               \u2502\n\u2502    - Update ClusterConnection.Status                \u2502\n\u2502    - Use Patch to avoid reconciliation trigger      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                  \u2502\n                  \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 8. Return with RequeueAfter                         \u2502\n\u2502    - Schedule next reconciliation                   \u2502\n\u2502    - Use configured interval (default 30s)          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                  \u2502\n                  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500&gt; Loop continues\n</code></pre>"},{"location":"contributing/cluster-controller/#key-principles","title":"Key Principles","text":"<p>Always requeue: Every reconciliation must return <code>RequeueAfter</code> to ensure periodic monitoring:</p> <pre><code>return reconcile.Result{RequeueAfter: time.Duration(interval) * time.Second}, nil\n</code></pre> <p>Parallel collection: Use <code>errgroup</code> for collecting multiple metrics:</p> <pre><code>g, gctx := errgroup.WithContext(ctx)\n\ng.Go(func() error {\n    nodeMetrics, err = clusterClient.GetNodeMetrics(gctx)\n    return err\n})\n\ng.Go(func() error {\n    clusterMetrics, err = clusterClient.GetClusterMetrics(gctx)\n    return err\n})\n\nif err := g.Wait(); err != nil {\n    return err\n}\n</code></pre> <p>Non-critical failures: Some operations can fail without failing reconciliation:</p> <pre><code>// Operators are optional - don't fail if not present\noperators, err := clusterClient.GetOperators(gctx)\nif err != nil {\n    log.Debug(\"Failed to get operators (may not be installed)\")\n    operators = []types.OperatorInfo{}\n}\n</code></pre> <p>Status updates: Use <code>Patch</code> instead of <code>Update</code> to avoid triggering reconciliation:</p> <pre><code>// Patch only the status subresource\nif err := r.Status().Patch(ctx, clusterConn, k8sclient.MergeFrom(originalClusterConn)); err != nil {\n    log.WithError(err).Debug(\"Failed to patch status\")\n}\n</code></pre>"},{"location":"contributing/cluster-controller/#common-tasks","title":"Common Tasks","text":""},{"location":"contributing/cluster-controller/#adding-a-new-field-to-a-crd","title":"Adding a New Field to a CRD","text":"<ol> <li>Edit the type definition:</li> </ol> <pre><code>// api/v1alpha1/clusterconnection_types.go\n\ntype ClusterConnectionSpec struct {\n    // Existing fields...\n\n    // NewFeature enables a cool new thing\n    // +optional\n    NewFeature bool `json:\"newFeature,omitempty\"`\n\n    // NewSetting configures the feature\n    // +kubebuilder:validation:Minimum=10\n    // +optional\n    NewSetting int32 `json:\"newSetting,omitempty\"`\n}\n</code></pre> <ol> <li>Regenerate code:</li> </ol> <pre><code>controller-gen object paths=\"./...\"\ncontroller-gen crd paths=\"./...\" output:crd:artifacts:config=config/crd/bases\n</code></pre> <ol> <li>Update the controller to use it:</li> </ol> <pre><code>// internal/controller/cluster/cluster_controller.go\n\nfunc (r *ClusterReconciler) reconcileCluster(ctx context.Context, clusterConn *v1alpha1.ClusterConnection) error {\n    // Use the new field\n    if clusterConn.Spec.NewFeature {\n        setting := clusterConn.Spec.NewSetting\n        if setting == 0 {\n            setting = 30 // default\n        }\n        // Do something with it\n    }\n}\n</code></pre> <ol> <li>Test it:</li> </ol> <pre><code># Apply updated CRD\noc apply -f config/crd/bases/clusterpulse.io_clusterconnections.yaml\n\n# Create a test resource\noc apply -f - &lt;&lt;EOF\napiVersion: clusterpulse.io/v1alpha1\nkind: ClusterConnection\nmetadata:\n  name: test-cluster\n  namespace: clusterpulse\nspec:\n  endpoint: https://api.test.example.com:6443\n  credentialsRef:\n    name: test-cluster-creds\n  newFeature: true\n  newSetting: 60\nEOF\n</code></pre>"},{"location":"contributing/cluster-controller/#adding-new-metrics-collection","title":"Adding New Metrics Collection","text":"<ol> <li>Define the collection method in the client:</li> </ol> <pre><code>// internal/client/cluster/client.go\n\nfunc (c *ClusterClient) GetIngresses(ctx context.Context) ([]types.IngressInfo, error) {\n    c.updateLastUsed()\n\n    var ingresses []types.IngressInfo\n\n    err := c.circuitBreaker.Call(ctx, func(ctx context.Context) error {\n        ingressList, err := c.clientset.NetworkingV1().Ingresses(\"\").List(ctx, metav1.ListOptions{})\n        if err != nil {\n            return fmt.Errorf(\"failed to list ingresses: %w\", err)\n        }\n\n        for _, ing := range ingressList.Items {\n            ingresses = append(ingresses, types.IngressInfo{\n                Name:      ing.Name,\n                Namespace: ing.Namespace,\n                Hosts:     ing.Spec.Rules[0].Host,\n            })\n        }\n\n        return nil\n    })\n\n    return ingresses, err\n}\n</code></pre> <ol> <li>Call it in the reconciler:</li> </ol> <pre><code>// internal/controller/cluster/cluster_controller.go\n\nfunc (r *ClusterReconciler) reconcileCluster(ctx context.Context, clusterConn *v1alpha1.ClusterConnection) error {\n    // ... existing code\n\n    // Add to errgroup\n    g.Go(func() error {\n        ingresses, err = clusterClient.GetIngresses(gctx)\n        if err != nil {\n            log.Debug(\"Failed to get ingresses\")\n            return nil // Non-critical\n        }\n        return nil\n    })\n\n    // After g.Wait()...\n}\n</code></pre> <ol> <li>Store in Redis:</li> </ol> <pre><code>// internal/store/client.go\n\nfunc (c *Client) StoreIngresses(ctx context.Context, clusterName string, ingresses []types.IngressInfo) error {\n    // Convert to Python-compatible format\n    ingressList := make([]map[string]interface{}, len(ingresses))\n    for i, ing := range ingresses {\n        ingressList[i] = map[string]interface{}{\n            \"name\":      ing.Name,\n            \"namespace\": ing.Namespace,\n            \"hosts\":     ing.Hosts,\n        }\n    }\n\n    data, err := json.Marshal(ingressList)\n    if err != nil {\n        return err\n    }\n\n    key := fmt.Sprintf(\"cluster:%s:ingresses\", clusterName)\n    return c.client.Set(ctx, key, string(data), time.Duration(c.config.CacheTTL)*time.Second).Err()\n}\n</code></pre> <ol> <li>Call storage:</li> </ol> <pre><code>// Back in cluster_controller.go after g.Wait()\n\nif len(ingresses) &gt; 0 {\n    if err := r.RedisClient.StoreIngresses(ctx, clusterConn.Name, ingresses); err != nil {\n        log.WithError(err).Debug(\"Failed to store ingresses\")\n    }\n}\n</code></pre>"},{"location":"contributing/cluster-controller/#adding-a-new-utility-function","title":"Adding a New Utility Function","text":"<p>When you find yourself repeating logic, consider adding it to <code>pkg/utils/</code>:</p> <ol> <li>Create the utility file (if needed):</li> </ol> <pre><code>// pkg/utils/time.go\n\npackage utils\n\nimport \"time\"\n\n// ParseDuration parses a duration string with fallback to default\nfunc ParseDuration(s string, defaultDuration time.Duration) time.Duration {\n    if s == \"\" {\n        return defaultDuration\n    }\n\n    d, err := time.ParseDuration(s)\n    if err != nil {\n        return defaultDuration\n    }\n\n    return d\n}\n\n// DurationToSeconds converts duration to seconds as int\nfunc DurationToSeconds(d time.Duration) int {\n    return int(d.Seconds())\n}\n</code></pre> <ol> <li> <p>Add tests: - TODO</p> </li> <li> <p>Use it in your code:</p> </li> </ol> <pre><code>import \"github.com/clusterpulse/cluster-controller/pkg/utils\"\n\ntimeout := utils.ParseDuration(config.Timeout, 30*time.Second)\n</code></pre>"},{"location":"contributing/cluster-controller/#adding-a-new-type-to-pkgtypes","title":"Adding a New Type to pkg/types/","text":"<p>When you need a new domain model type:</p> <ol> <li>Add to appropriate file:</li> </ol> <pre><code>// pkg/types/types.go (for core types)\n// OR\n// pkg/types/resources.go (for resource collection types)\n\n// IngressInfo represents an ingress resource\ntype IngressInfo struct {\n    Name      string    `json:\"name\"`\n    Namespace string    `json:\"namespace\"`\n    Hosts     []string  `json:\"hosts\"`\n    TLSHosts  []string  `json:\"tls_hosts,omitempty\"`\n    CreatedAt time.Time `json:\"created_at\"`\n}\n</code></pre> <ol> <li>Use it in clients:</li> </ol> <pre><code>// internal/client/cluster/client.go\n\nfunc (c *ClusterClient) GetIngresses(ctx context.Context) ([]types.IngressInfo, error) {\n    // Implementation uses types.IngressInfo\n}\n</code></pre> <ol> <li>Store in Redis:</li> </ol> <pre><code>// internal/store/client.go\n\nfunc (c *Client) StoreIngresses(ctx context.Context, clusterName string, ingresses []types.IngressInfo) error {\n    // Convert to Python-compatible format and store\n}\n</code></pre>"},{"location":"contributing/cluster-controller/#adding-a-new-controller","title":"Adding a New Controller","text":"<p>If you need to watch a new CRD type:</p> <ol> <li>Define the CRD in <code>api/v1alpha1/</code>:</li> </ol> <pre><code>// api/v1alpha1/newresource_types.go\ntype NewResourceSpec struct {\n    // Fields\n}\n\ntype NewResourceStatus struct {\n    // Status fields\n}\n\ntype NewResource struct {\n    metav1.TypeMeta   `json:\",inline\"`\n    metav1.ObjectMeta `json:\"metadata,omitempty\"`\n\n    Spec   NewResourceSpec   `json:\"spec,omitempty\"`\n    Status NewResourceStatus `json:\"status,omitempty\"`\n}\n</code></pre> <ol> <li>Create the controller in <code>internal/controller/newresource/</code>:</li> </ol> <pre><code>type NewResourceReconciler struct {\n    client.Client\n    Scheme      *runtime.Scheme\n    RedisClient *redis.Client\n    Config      *config.Config\n}\n\nfunc (r *NewResourceReconciler) Reconcile(ctx context.Context, req reconcile.Request) (reconcile.Result, error) {\n    // Reconciliation logic\n    return reconcile.Result{RequeueAfter: 60 * time.Second}, nil\n}\n\nfunc (r *NewResourceReconciler) SetupWithManager(mgr ctrl.Manager) error {\n    return ctrl.NewControllerManagedBy(mgr).\n        For(&amp;v1alpha1.NewResource{}).\n        Complete(r)\n}\n</code></pre> <ol> <li>Register in main.go:</li> </ol> <pre><code>// cmd/manager/main.go\n\nif err = (&amp;newresourcecontroller.NewResourceReconciler{\n    Client:      mgr.GetClient(),\n    Scheme:      mgr.GetScheme(),\n    RedisClient: redisClient,\n    Config:      cfg,\n}).SetupWithManager(mgr); err != nil {\n    setupLog.Error(err, \"unable to create controller\", \"controller\", \"NewResource\")\n    os.Exit(1)\n}\n</code></pre>"},{"location":"contributing/cluster-controller/#changing-reconciliation-interval-logic","title":"Changing Reconciliation Interval Logic","text":"<p>The interval can be set per-cluster via the CRD spec:</p> <pre><code>func (r *ClusterReconciler) getReconcileInterval(clusterConn *v1alpha1.ClusterConnection) int {\n    interval := r.Config.ReconciliationInterval // Default from config\n\n    if clusterConn.Spec.Monitoring.Interval &gt; 0 {\n        specInterval := int(clusterConn.Spec.Monitoring.Interval)\n        if specInterval &gt;= 30 {\n            interval = specInterval\n        } else {\n            // Enforce minimum\n            interval = 30\n        }\n    }\n\n    return interval\n}\n</code></pre> <p>To add adaptive intervals based on health:</p> <pre><code>func (r *ClusterReconciler) getReconcileInterval(clusterConn *v1alpha1.ClusterConnection) int {\n    interval := r.Config.ReconciliationInterval\n\n    // Override from spec if set\n    if clusterConn.Spec.Monitoring.Interval &gt; 0 {\n        interval = int(clusterConn.Spec.Monitoring.Interval)\n    }\n\n    // Reduce interval for unhealthy clusters\n    if clusterConn.Status.Health == string(types.HealthUnhealthy) {\n        interval = interval / 2\n        if interval &lt; 30 {\n            interval = 30\n        }\n    }\n\n    return interval\n}\n</code></pre>"},{"location":"contributing/cluster-controller/#adding-resource-collection-limits","title":"Adding Resource Collection Limits","text":"<p>Resource collection uses configured limits to prevent memory issues on large clusters:</p> <pre><code>// internal/config/config.go\n\nResourceCollection: types.CollectionConfig{\n    Enabled:        getEnvBool(\"RESOURCE_COLLECTION_ENABLED\", true),\n    MaxPodsPerNS:   getEnvIntWithMin(\"MAX_PODS_PER_NAMESPACE\", 100, 10),\n    MaxTotalPods:   getEnvIntWithMin(\"MAX_TOTAL_PODS\", 1000, 50),\n    MaxDeployments: getEnvIntWithMin(\"MAX_DEPLOYMENTS\", 500, 10),\n    MaxServices:    getEnvIntWithMin(\"MAX_SERVICES\", 500, 10),\n    IncludeLabels:  getEnvBool(\"COLLECT_RESOURCE_LABELS\", false),\n}\n</code></pre> <p>To add a new resource type to collection:</p> <pre><code>// internal/client/cluster/resources.go\n\nfunc (c *ClusterClient) GetResourceCollection(ctx context.Context, config types.CollectionConfig) (*types.ResourceCollection, error) {\n    // ... existing code\n\n    // Add new resource collection\n    if config.MaxConfigMaps &gt; 0 {\n        g.Go(func() error {\n            cms, _ := c.collectConfigMaps(gctx, config)\n            mu.Lock()\n            collection.ConfigMaps = cms\n            mu.Unlock()\n            return nil\n        })\n    }\n\n    return collection, nil\n}\n\nfunc (c *ClusterClient) collectConfigMaps(ctx context.Context, config types.CollectionConfig) ([]types.ConfigMapSummary, bool) {\n    opts := metav1.ListOptions{\n        Limit: int64(config.MaxConfigMaps),\n    }\n\n    cmList, err := c.clientset.CoreV1().ConfigMaps(\"\").List(ctx, opts)\n    if err != nil {\n        logrus.WithError(err).Warn(\"Failed to list configmaps\")\n        return nil, false\n    }\n\n    var configMaps []types.ConfigMapSummary\n    for _, cm := range cmList.Items {\n        configMaps = append(configMaps, types.ConfigMapSummary{\n            Name:      cm.Name,\n            Namespace: cm.Namespace,\n            DataCount: len(cm.Data),\n        })\n    }\n\n    return configMaps, len(cmList.Items) &gt; config.MaxConfigMaps\n}\n</code></pre>"},{"location":"contributing/cluster-controller/#testing","title":"Testing","text":""},{"location":"contributing/cluster-controller/#unit-tests-todo","title":"Unit Tests - TODO","text":"<p>Test individual functions with fake clients:</p>"},{"location":"contributing/cluster-controller/#testing-utilities-todo","title":"Testing Utilities - TODO","text":"<p>Test utility functions in <code>pkg/utils/</code>:</p>"},{"location":"contributing/cluster-controller/#integration-tests-todo","title":"Integration Tests - TODO","text":"<p>Test controllers with envtest (real Kubernetes API):</p>"},{"location":"contributing/cluster-controller/#running-tests-todo","title":"Running Tests - TODO","text":"<pre><code># All tests\ngo test ./...\n</code></pre>"},{"location":"contributing/cluster-controller/#code-patterns","title":"Code Patterns","text":""},{"location":"contributing/cluster-controller/#error-handling","title":"Error Handling","text":"<p>Always wrap errors with context:</p> <pre><code>// Good\nif err != nil {\n    return fmt.Errorf(\"failed to list nodes: %w\", err)\n}\n\n// Also good\nnodes, err := clientset.CoreV1().Nodes().List(ctx, opts)\nif err != nil {\n    return nil, fmt.Errorf(\"failed to list nodes for cluster %s: %w\", c.Name, err)\n}\n</code></pre> <p>Don't fail reconciliation for non-critical operations:</p> <pre><code>// Optional operation - log but don't fail\noperators, err := client.GetOperators(ctx)\nif err != nil {\n    log.WithError(err).Debug(\"Failed to get operators (may not be installed)\")\n    operators = []types.OperatorInfo{}\n}\n</code></pre>"},{"location":"contributing/cluster-controller/#logging","title":"Logging","text":"<p>Use structured logging with logrus:</p> <pre><code>log := logrus.WithFields(logrus.Fields{\n    \"cluster\":   clusterConn.Name,\n    \"namespace\": clusterConn.Namespace,\n})\n\nlog.Debug(\"Starting reconciliation\")\nlog.Info(\"Cluster is healthy\")\nlog.Warn(\"Some nodes not ready\")\nlog.Error(\"Failed to connect to cluster\")\n</code></pre> <p>Log levels: - <code>Debug</code> - Detailed info for debugging (disabled by default) - <code>Info</code> - Important state changes (cluster became healthy, operator issues) - <code>Warn</code> - Degraded state or recoverable errors - <code>Error</code> - Failed operations that need attention</p> <p>Only log at Info for significant events: <pre><code>// Good - state change\nif originalHealth != newHealth {\n    log.Info(\"Cluster health changed\")\n}\n\n// Bad - every reconciliation\nlog.Info(\"Reconciliation completed\")\n\n// Good - slow operation\nif duration &gt; 5*time.Second {\n    log.Infof(\"Reconciliation took %v\", duration)\n}\n</code></pre></p>"},{"location":"contributing/cluster-controller/#context-and-timeouts","title":"Context and Timeouts","text":"<p>Always use contexts with timeouts:</p> <pre><code>// Connection test\nconnCtx, cancel := context.WithTimeout(ctx, time.Duration(timeout)*time.Second)\ndefer cancel()\n\nif err := clusterClient.TestConnection(connCtx); err != nil {\n    return fmt.Errorf(\"connection test failed: %w\", err)\n}\n</code></pre> <p>Use errgroup for parallel operations:</p> <pre><code>g, gctx := errgroup.WithContext(ctx)\n\ng.Go(func() error {\n    nodeMetrics, err = client.GetNodeMetrics(gctx)\n    return err\n})\n\ng.Go(func() error {\n    clusterMetrics, err = client.GetClusterMetrics(gctx)\n    return err\n})\n\nif err := g.Wait(); err != nil {\n    return err\n}\n</code></pre>"},{"location":"contributing/cluster-controller/#redis-storage-patterns","title":"Redis Storage Patterns","text":"<p>Always store Python-compatible data:</p> <pre><code>// DON'T - Go conventions\ndata := map[string]interface{}{\n    \"cpuCapacity\": metrics.CPUCapacity,  // \u274c camelCase\n    \"nodes\": nil,                         // \u274c nil array\n}\n\n// DO - Python conventions\ndata := map[string]interface{}{\n    \"cpu_capacity\": metrics.CPUCapacity,  // \u2705 snake_case\n    \"nodes\": []string{},                  // \u2705 empty array\n    \"timestamp\": time.Now().Format(time.RFC3339),  // \u2705 ISO format\n}\n</code></pre> <p>Use pipelines for batch operations:</p> <pre><code>pipe := r.RedisClient.client.Pipeline()\n\n// Add multiple operations\npipe.Set(ctx, key1, val1, ttl)\npipe.Set(ctx, key2, val2, ttl)\npipe.HSet(ctx, key3, field, value)\n\n// Execute all at once\n_, err := pipe.Exec(ctx)\n</code></pre>"},{"location":"contributing/cluster-controller/#client-pool-usage","title":"Client Pool Usage","text":"<p>Always use the pool for cluster clients:</p> <pre><code>// DON'T create clients directly in reconciler\nclient, err := cluster.NewClusterClient(name, endpoint, token, caCert)\n\n// DO use the pool\nclient, err := r.clientPool.Get(name, endpoint, token, caCert)\n</code></pre> <p>The pool handles: - Connection reuse - Connection testing before return - Automatic cleanup of idle clients - Thread safety</p>"},{"location":"contributing/cluster-controller/#status-updates","title":"Status Updates","text":"<p>Use <code>Patch</code> to avoid triggering reconciliation:</p> <pre><code>// Save original for comparison\noriginalClusterConn := clusterConn.DeepCopy()\n\n// Modify status\nclusterConn.Status.Phase = \"Connected\"\nclusterConn.Status.Health = string(health)\nnow := metav1.Now()\nclusterConn.Status.LastSyncTime = &amp;now\n\n// Only patch if changed\nif !r.statusEqual(originalClusterConn.Status, clusterConn.Status) {\n    if err := r.Status().Patch(ctx, clusterConn, k8sclient.MergeFrom(originalClusterConn)); err != nil {\n        log.WithError(err).Debug(\"Failed to patch status\")\n    }\n}\n</code></pre> <p>Use <code>Update</code> only when you want to trigger reconciliation:</p> <pre><code>// This will trigger a new reconciliation\nif err := r.Status().Update(ctx, clusterConn); err != nil {\n    return err\n}\n</code></pre>"},{"location":"contributing/cluster-controller/#using-pkgutils-in-your-code","title":"Using pkg/utils in Your Code","text":"<p>Always use utilities when appropriate:</p> <pre><code>import \"github.com/clusterpulse/cluster-controller/pkg/utils\"\n\n// Parse CPU resources\ncpuStr := container.Resources.Requests.Cpu().String()\ncpuCores := utils.ParseCPU(cpuStr)\n\n// Parse memory resources\nmemStr := container.Resources.Requests.Memory().String()\nmemBytes := utils.ParseMemory(memStr)\n\n// Calculate percentages\ncpuPercent := (cpuCores / totalCPU) * 100\nmemPercent := float64(memBytes) / float64(totalMemory) * 100\n\n// Wrap API calls with circuit breaker\nvar nodes []corev1.Node\nerr := circuitBreaker.Call(ctx, func(ctx context.Context) error {\n    nodeList, err := clientset.CoreV1().Nodes().List(ctx, metav1.ListOptions{})\n    if err != nil {\n        return err\n    }\n    nodes = nodeList.Items\n    return nil\n})\n</code></pre>"},{"location":"contributing/cluster-controller/#performance-considerations","title":"Performance Considerations","text":""},{"location":"contributing/cluster-controller/#rate-limiting","title":"Rate Limiting","text":"<p>The controller uses rate limiting to prevent API server overload:</p> <pre><code>// client.go\nconfig := &amp;rest.Config{\n    QPS:   100,  // Queries per second\n    Burst: 200,  // Burst capacity\n}\n</code></pre> <p>For high-volume clusters, increase these values:</p> <pre><code>config.QPS = 200\nconfig.Burst = 400\n</code></pre>"},{"location":"contributing/cluster-controller/#resource-collection-optimization","title":"Resource Collection Optimization","text":"<p>Resource collection uses several optimizations:</p> <ol> <li>Limits - Configure max items to collect</li> <li>Field selectors - Filter at API level</li> <li>Parallel collection - Use errgroup</li> <li>Truncation tracking - Mark when limits reached</li> </ol> <pre><code>// Only get running/pending pods\nopts := metav1.ListOptions{\n    FieldSelector: \"status.phase!=Succeeded,status.phase!=Failed\",\n    Limit: int64(config.MaxTotalPods),\n}\n\npodList, err := c.clientset.CoreV1().Pods(\"\").List(ctx, opts)\n</code></pre>"},{"location":"contributing/cluster-controller/#redis-batching","title":"Redis Batching","text":"<p>Use pipelines for multiple Redis operations:</p> <pre><code>pipe := c.client.Pipeline()\n\n// Batch multiple operations\nfor _, node := range nodes {\n    nodeData := nodeToDict(node)\n    dataJSON, _ := json.Marshal(nodeData)\n    pipe.HSet(ctx, nodeKey, \"current\", dataJSON)\n}\n\n// Execute once\n_, err := pipe.Exec(ctx)\n</code></pre>"},{"location":"contributing/cluster-controller/#circuit-breakers","title":"Circuit Breakers","text":"<p>The cluster client uses circuit breakers to prevent hanging on unhealthy clusters:</p> <pre><code>type CircuitBreaker struct {\n    failures  int\n    threshold int\n    timeout   time.Duration\n    lastFail  time.Time\n}\n\nfunc (cb *CircuitBreaker) Call(ctx context.Context, fn func(context.Context) error) error {\n    // Check if circuit is open\n    if cb.isOpen() {\n        return fmt.Errorf(\"circuit breaker is open\")\n    }\n\n    err := fn(ctx)\n\n    if err != nil {\n        cb.recordFailure()\n    } else {\n        cb.reset()\n    }\n\n    return err\n}\n</code></pre> <p>The circuit opens after 5 consecutive failures and stays open for 60 seconds.</p>"},{"location":"contributing/cluster-controller/#code-style","title":"Code Style","text":"<p>Use <code>gofmt</code></p> <pre><code># Format code\ngofmt -w .\n</code></pre> <p>Comment style: <pre><code>// GetNodeMetrics retrieves detailed metrics for all nodes in the cluster.\n// It collects resource usage, conditions, and pod counts for each node.\nfunc (c *ClusterClient) GetNodeMetrics(ctx context.Context) ([]types.NodeMetrics, error) {\n    // Implementation\n}\n</code></pre></p>"},{"location":"contributing/cluster-controller/#pull-request-process","title":"Pull Request Process","text":"<ol> <li> <p>Branch naming: <code>feature/add-ingress-collection</code> or <code>fix/registry-timeout</code></p> </li> <li> <p>Commits:</p> </li> <li>\u2705 \"Add ingress collection to cluster metrics\"</li> <li>\u2705 \"Fix registry health check timeout handling\"</li> <li> <p>\u274c \"WIP\" or \"Fixes\"</p> </li> <li> <p>Before submitting: <pre><code># Format code\ngofmt -w .\n\n# Run tests - TODO\ngo test ./...\n\n# Generate CRDs\ncontroller-gen object paths=\"./...\"\ncontroller-gen crd paths=\"./...\" output:crd:artifacts:config=config/crd/bases\n\n# Verify CRDs compile\noc apply --dry-run=client -f config/crd/bases/\n</code></pre></p> </li> <li> <p>PR description should include:</p> </li> <li>What changed and why</li> <li>How to test it</li> <li>Impact on existing clusters</li> <li> <p>Redis schema changes (if any)</p> </li> <li> <p>Things reviewers look for:</p> </li> <li>Data is stored in Python-compatible format</li> <li>Reconciliation always returns <code>RequeueAfter</code></li> <li>Non-critical operations don't fail reconciliation</li> <li>Proper error wrapping and logging</li> <li>Status updates use <code>Patch</code> not <code>Update</code></li> <li>Tests cover new functionality</li> <li>CRD changes are documented</li> <li>Utilities used from <code>pkg/utils</code> where appropriate</li> </ol>"},{"location":"contributing/cluster-controller/#common-pitfalls","title":"Common Pitfalls","text":"<ol> <li> <p>Not storing Python-compatible data: <pre><code>// \u274c Wrong\ndata := map[string]interface{}{\n    \"nodes\": nil,  // Python expects []\n    \"cpuCapacity\": 100,  // Should be cpu_capacity\n}\n\n// \u2705 Right\ndata := map[string]interface{}{\n    \"nodes\": []string{},\n    \"cpu_capacity\": 100,\n}\n</code></pre></p> </li> <li> <p>Forgetting to requeue: <pre><code>// \u274c Wrong - reconciliation stops\nreturn reconcile.Result{}, nil\n\n// \u2705 Right - periodic reconciliation\nreturn reconcile.Result{RequeueAfter: time.Duration(interval) * time.Second}, nil\n</code></pre></p> </li> <li> <p>Triggering reconciliation loops with status updates: <pre><code>// \u274c Wrong - triggers reconciliation\nr.Status().Update(ctx, resource)\n\n// \u2705 Right - doesn't trigger reconciliation\nr.Status().Patch(ctx, resource, k8sclient.MergeFrom(original))\n</code></pre></p> </li> <li> <p>Not using timeouts: <pre><code>// \u274c Wrong - can hang forever\nerr := clusterClient.TestConnection(ctx)\n\n// \u2705 Right - has timeout\nconnCtx, cancel := context.WithTimeout(ctx, 10*time.Second)\ndefer cancel()\nerr := clusterClient.TestConnection(connCtx)\n</code></pre></p> </li> <li> <p>Creating clients directly instead of using pool: <pre><code>// \u274c Wrong - expensive, not reused\nclient, err := cluster.NewClusterClient(...)\n\n// \u2705 Right - reuses connections\nclient, err := r.clientPool.Get(...)\n</code></pre></p> </li> <li> <p>Failing reconciliation for non-critical operations: <pre><code>// \u274c Wrong - operators are optional\noperators, err := client.GetOperators(ctx)\nif err != nil {\n    return err  // Fails entire reconciliation\n}\n\n// \u2705 Right - log and continue\noperators, err := client.GetOperators(ctx)\nif err != nil {\n    log.Debug(\"Failed to get operators (may not be installed)\")\n    operators = []types.OperatorInfo{}\n}\n</code></pre></p> </li> <li> <p>Not handling deletions: <pre><code>// \u2705 Must handle deletion timestamp\nif !clusterConn.DeletionTimestamp.IsZero() {\n    return r.handleDeletion(ctx, req.Name)\n}\n</code></pre></p> </li> <li> <p>Forgetting to regenerate after CRD changes: <pre><code># After editing api/v1alpha1/*.go, always run:\ncontroller-gen object paths=\"./...\"\ncontroller-gen crd paths=\"./...\" output:crd:artifacts:config=config/crd/bases\n</code></pre></p> </li> <li> <p>Not using utilities from pkg/utils: <pre><code>// \u274c Wrong - reinventing the wheel\ncpuStr := strings.TrimSuffix(cpu, \"m\")\ncpuVal, _ := strconv.ParseFloat(cpuStr, 64)\ncpuCores := cpuVal / 1000\n\n// \u2705 Right - use existing utility\ncpuCores := utils.ParseCPU(cpu)\n</code></pre></p> </li> <li> <p>Not wrapping API calls with circuit breaker: <pre><code>// \u274c Wrong - can hang on unhealthy cluster\nnodes, err := clientset.CoreV1().Nodes().List(ctx, opts)\n\n// \u2705 Right - protected by circuit breaker\nerr := c.circuitBreaker.Call(ctx, func(ctx context.Context) error {\n    nodeList, err := c.clientset.CoreV1().Nodes().List(ctx, opts)\n    if err != nil {\n        return err\n    }\n    nodes = nodeList.Items\n    return nil\n})\n</code></pre></p> </li> </ol>"},{"location":"contributing/cluster-controller/#security-considerations","title":"Security Considerations","text":""},{"location":"contributing/cluster-controller/#credential-handling","title":"Credential Handling","text":"<p>Cluster credentials are stored in Kubernetes Secrets:</p> <pre><code>// Get credentials from secret\nsecret := &amp;corev1.Secret{}\nif err := r.Get(ctx, k8sclient.ObjectKey{Name: secretName, Namespace: secretNamespace}, secret); err != nil {\n    return nil, fmt.Errorf(\"failed to get secret: %w\", err)\n}\n\ntoken := string(secret.Data[\"token\"])\ncaCert := secret.Data[\"ca.crt\"]\n</code></pre> <p>Never log credentials: <pre><code>// \u274c Don't do this\nlog.Debugf(\"Token: %s\", token)\n\n// \u2705 Do this\nlog.Debug(\"Retrieved credentials from secret\")\n</code></pre></p>"},{"location":"contributing/cluster-controller/#rbac-in-kubernetes","title":"RBAC in Kubernetes","text":"<p>The controller needs proper RBAC permissions:</p> <pre><code># config/rbac/role.yaml\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRole\nmetadata:\n  name: cluster-controller-manager-role\nrules:\n- apiGroups:\n  - clusterpulse.io\n  resources:\n  - clusterconnections\n  - registryconnections\n  verbs:\n  - get\n  - list\n  - watch\n  - update\n  - patch\n- apiGroups:\n  - clusterpulse.io\n  resources:\n  - clusterconnections/status\n  - registryconnections/status\n  verbs:\n  - get\n  - update\n  - patch\n- apiGroups:\n  - \"\"\n  resources:\n  - secrets\n  verbs:\n  - get\n  - list\n  - watch\n</code></pre>"},{"location":"contributing/cluster-controller/#quick-reference","title":"Quick Reference","text":""},{"location":"contributing/cluster-controller/#typical-controller-pattern","title":"Typical Controller Pattern","text":"<pre><code>func (r *ClusterReconciler) Reconcile(ctx context.Context, req reconcile.Request) (reconcile.Result, error) {\n    log := logrus.WithField(\"cluster\", req.Name)\n\n    // 1. Fetch resource\n    resource := &amp;v1alpha1.ClusterConnection{}\n    if err := r.Get(ctx, req.NamespacedName, resource); err != nil {\n        if errors.IsNotFound(err) {\n            return r.handleDeletion(ctx, req.Name)\n        }\n        return reconcile.Result{}, err\n    }\n\n    // 2. Handle deletion\n    if !resource.DeletionTimestamp.IsZero() {\n        return r.handleDeletion(ctx, req.Name)\n    }\n\n    // 3. Get reconciliation interval\n    interval := r.getReconcileInterval(resource)\n\n    // 4. Do the work\n    if err := r.reconcileResource(ctx, resource); err != nil {\n        log.WithError(err).Error(\"Reconciliation failed\")\n\n        // Update status with error\n        resource.Status.Phase = \"Error\"\n        resource.Status.Message = err.Error()\n        r.Status().Patch(ctx, resource, k8sclient.MergeFrom(resource))\n\n        // Retry after 1 minute\n        return reconcile.Result{RequeueAfter: time.Minute}, nil\n    }\n\n    log.Debug(\"Reconciliation completed\")\n\n    // 5. Always requeue for periodic reconciliation\n    return reconcile.Result{RequeueAfter: time.Duration(interval) * time.Second}, nil\n}\n</code></pre>"},{"location":"contributing/cluster-controller/#common-imports","title":"Common Imports","text":"<pre><code>// Kubernetes\nimport (\n    corev1 \"k8s.io/api/core/v1\"\n    \"k8s.io/apimachinery/pkg/api/errors\"\n    metav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"\n    \"k8s.io/apimachinery/pkg/runtime\"\n    \"k8s.io/client-go/kubernetes\"\n    ctrl \"sigs.k8s.io/controller-runtime\"\n    \"sigs.k8s.io/controller-runtime/pkg/client\"\n    \"sigs.k8s.io/controller-runtime/pkg/reconcile\"\n)\n\n// Local\nimport (\n    \"github.com/clusterpulse/cluster-controller/api/v1alpha1\"\n    \"github.com/clusterpulse/cluster-controller/internal/config\"\n    \"github.com/clusterpulse/cluster-controller/internal/store\"\n    \"github.com/clusterpulse/cluster-controller/pkg/types\"\n    \"github.com/clusterpulse/cluster-controller/pkg/utils\"\n)\n\n// Third-party\nimport (\n    \"github.com/sirupsen/logrus\"\n    \"golang.org/x/sync/errgroup\"\n)\n</code></pre>"},{"location":"contributing/cluster-controller/#useful-commands","title":"Useful Commands","text":"<pre><code># Development\ncontroller-gen object paths=\"./...\"\ncontroller-gen crd paths=\"./...\" output:crd:artifacts:config=config/crd/bases\ngo run cmd/manager/main.go --namespace=clusterpulse\n\n# Testing\ngo test ./...\ngo test -v ./internal/controller/cluster/\ngo test -v ./pkg/utils/\ngo test -cover ./...\n\n# Linting\ngofmt -w .\ngolangci-lint run\n\n# Building\ngo build -o bin/manager cmd/manager/main.go\n\n# Docker\ndocker build -t cluster-controller:latest .\n\n# Applying CRDs\noc apply -f config/crd/bases/\n</code></pre>"},{"location":"contributing/cluster-controller/#getting-help","title":"Getting Help","text":"<ul> <li>Check existing controllers in <code>internal/controller/</code> for patterns</li> <li>Look at client implementations in <code>internal/client/cluster/</code> for examples</li> <li>Review Redis storage in <code>internal/store/</code> for data format</li> <li>Check utilities in <code>pkg/utils/</code> for reusable functions</li> <li>Review types in <code>pkg/types/</code> for data models</li> <li>Read controller-runtime docs: https://book.kubebuilder.io</li> <li>Check kubebuilder markers: https://book.kubebuilder.io/reference/markers.html</li> <li>Review errgroup examples for parallel operations</li> </ul>"},{"location":"contributing/cluster-controller/#project-specific-notes","title":"Project-Specific Notes","text":"<ul> <li>Two reconcilers: ClusterConnection and RegistryConnection controllers</li> <li>Redis is the bridge: Controller writes, API reads</li> <li>Python compatibility: All Redis data must work with Python (snake_case, no nil arrays)</li> <li>Periodic reconciliation: Always return <code>RequeueAfter</code> to ensure monitoring continues</li> <li>Status updates: Use <code>Patch</code> to avoid reconciliation loops</li> <li>Client pooling: Reuse cluster connections via the pool</li> <li>Parallel collection: Use errgroup for collecting multiple metrics simultaneously</li> <li>Circuit breakers: Prevent hanging on unhealthy clusters (use from <code>pkg/utils</code>)</li> <li>Resource limits: Configure collection limits for large clusters</li> <li>OpenShift support: Special handling for ClusterVersion, ClusterOperators, and Routes</li> <li>Shared utilities: Use <code>pkg/utils</code> for parsing and circuit breakers</li> <li>Domain types: Define core types in <code>pkg/types</code> for reusability</li> </ul>"},{"location":"contributing/policy-controller/","title":"Contributing to ClusterPulse Policy Controller","text":""},{"location":"contributing/policy-controller/#getting-started","title":"Getting Started","text":""},{"location":"contributing/policy-controller/#local-setup","title":"Local Setup","text":"<pre><code># Install dependencies\npip install -r policy-controller/requirements.txt\n\n# Set up environment\nexport NAMESPACE=clusterpulse\nexport REDIS_HOST=localhost\nexport REDIS_PORT=6379\n\n# Start Redis\ndocker run -d -p 6379:6379 redis:latest\n\n# Run locally (connects to your current kubeconfig cluster)\ncd policy-controller\npython policy_controller.py\n</code></pre>"},{"location":"contributing/policy-controller/#development-dependencies","title":"Development Dependencies","text":"<pre><code>pip install pytest pytest-asyncio black ruff mypy\n</code></pre>"},{"location":"contributing/policy-controller/#project-structure","title":"Project Structure","text":"<p>The policy-controller is a single Python file organized into logical sections. Here's what each part does.</p>"},{"location":"contributing/policy-controller/#file-organization","title":"File Organization","text":"<pre><code>policy-controller/\n\u251c\u2500\u2500 policy_controller.py    # Main controller (all sections below)\n\u251c\u2500\u2500 requirements.txt         # Python dependencies\n\u2514\u2500\u2500 tests/                   # Tests (TODO)\n</code></pre>"},{"location":"contributing/policy-controller/#code-sections-in-policy_controllerpy","title":"Code Sections in <code>policy_controller.py</code>","text":"<p>The file is organized into these sections (in order):</p>"},{"location":"contributing/policy-controller/#1-constants-configuration","title":"1. Constants &amp; Configuration","text":"<p>Environment variables and Redis key patterns.</p> <p>What's here: - Environment configuration (REDIS_HOST, NAMESPACE, etc.) - Policy settings (cache TTL, validation intervals) - Redis key patterns for storing policies and indexes - Batch processing constants</p> <p>When to edit: - Adding new environment variables - Changing default values - Adding new Redis key patterns - Adjusting batch sizes</p> <pre><code># Example: Adding a new configuration\nPOLICY_MAX_SIZE = int(os.getenv(\"POLICY_MAX_SIZE\", 100000))  # bytes\n</code></pre>"},{"location":"contributing/policy-controller/#2-logging","title":"2. Logging","text":"<p>Basic logging configuration.</p> <pre><code>logging.basicConfig(\n    level=logging.INFO,\n    format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n)\nlogger = logging.getLogger(\"policy-controller\")\n</code></pre>"},{"location":"contributing/policy-controller/#3-metrics","title":"3. Metrics","text":"<p>Prometheus metrics for monitoring policy operations.</p> <p>Available metrics: - <code>policy_compilation_duration_seconds</code> - Time to compile a policy - <code>policy_cache_operations_total</code> - Cache operations counter - <code>active_policies_total</code> - Number of active policies - <code>policy_errors_total</code> - Error counter by type - <code>redis_operation_duration_seconds</code> - Redis operation timings</p> <p>When to add: - New performance metrics - New error types to track - New cache operations</p> <pre><code># Example: Adding a new metric\npolicy_validations = Counter(\n    \"policy_validations_total\",\n    \"Total policy validations\",\n    [\"result\"]\n)\n</code></pre>"},{"location":"contributing/policy-controller/#4-exceptions","title":"4. Exceptions","text":"<p>Custom exception hierarchy for policy errors.</p> <pre><code>class PolicyError(Exception): pass\nclass PolicyCompilationError(PolicyError): pass\nclass PolicyValidationError(PolicyError): pass\nclass PolicyStorageError(PolicyError): pass\n</code></pre>"},{"location":"contributing/policy-controller/#5-enums","title":"5. Enums","text":"<p>Type-safe constants for policy effects, visibility, and states.</p> <pre><code>class PolicyEffect(str, Enum):\n    ALLOW = \"Allow\"\n    DENY = \"Deny\"\n\nclass PolicyState(str, Enum):\n    ACTIVE = \"Active\"\n    INACTIVE = \"Inactive\"\n    ERROR = \"Error\"\n    EXPIRED = \"Expired\"\n</code></pre>"},{"location":"contributing/policy-controller/#6-data-classes","title":"6. Data Classes","text":"<p>Compiled policy structures for efficient evaluation.</p> <p>Key classes: - <code>CompiledResourceFilter</code> - Compiled resource filters (namespaces, nodes, operators, pods) - <code>CompiledClusterRule</code> - Cluster access rules with filters - <code>CompiledPolicy</code> - Complete compiled policy ready for Redis</p> <p>Critical: These classes define the Redis storage format. Changes here impact the API's RBAC engine.</p> <pre><code>@dataclass\nclass CompiledPolicy:\n    policy_name: str\n    namespace: str\n    priority: int\n    effect: str\n    enabled: bool\n    users: Set[str]\n    groups: Set[str]\n    service_accounts: Set[str]\n    cluster_rules: List[CompiledClusterRule]\n    # ... more fields\n\n    def to_dict(self):\n        \"\"\"This format MUST remain unchanged for Redis compatibility\"\"\"\n        return {...}\n</code></pre> <p>Important: The <code>to_dict()</code> method creates the format that the API reads. Any changes must be coordinated with API changes.</p>"},{"location":"contributing/policy-controller/#7-utilities","title":"7. Utilities","text":"<p>Helper classes for batch processing and resource management.</p> <p>RedisBatchProcessor: Efficiently batches Redis operations to avoid network overhead.</p> <pre><code>with RedisBatchProcessor(redis_client, batch_size=1000) as batch:\n    for item in items:\n        batch.add_operation(\"set\", key, value)\n    # Auto-executes on context exit\n</code></pre> <p>ResourceManager: Handles cleanup on shutdown (signal handlers, atexit).</p>"},{"location":"contributing/policy-controller/#8-redis-connection","title":"8. Redis Connection","text":"<p>Connection pool for Redis client.</p> <pre><code>redis_pool = redis.ConnectionPool(\n    host=REDIS_HOST,\n    port=REDIS_PORT,\n    decode_responses=True,\n    max_connections=50,\n)\nredis_client = redis.Redis(connection_pool=redis_pool)\n</code></pre>"},{"location":"contributing/policy-controller/#9-kubernetes-client","title":"9. Kubernetes Client","text":"<p>Connection to the Kubernetes API.</p> <pre><code>config.load_incluster_config()  # In cluster\n# or\nconfig.load_kube_config()  # Local dev\n\nk8s_client = client.ApiClient()\ndynamic_client = DynamicClient(k8s_client)\n</code></pre>"},{"location":"contributing/policy-controller/#10-policy-compiler","title":"10. Policy Compiler","text":"<p>Compiles MonitorAccessPolicy CRDs into efficient structures.</p> <p>Main method: <pre><code>def compile_policy(name: str, namespace: str, spec: Dict) -&gt; CompiledPolicy\n</code></pre></p> <p>What it does: 1. Validates the policy spec (new format) 2. Extracts subjects (users, groups, service accounts) 3. Compiles cluster rules with resource filters 4. Processes patterns into regex or literals 5. Extracts validity periods and audit config 6. Generates a hash for change detection 7. Returns a CompiledPolicy object</p> <p>Pattern compilation: - Literal strings stored as-is for fast lookup - Wildcards (<code>*</code>, <code>?</code>) compiled to regex - Results cached with <code>@lru_cache</code></p> <pre><code>@lru_cache(maxsize=1024)\ndef _compile_pattern(self, pattern: str) -&gt; Tuple[str, Any]:\n    if \"*\" in pattern or \"?\" in pattern:\n        # Convert to regex\n        return (\"regex\", re.compile(f\"^{regex_pattern}$\"))\n    else:\n        return (\"literal\", pattern)\n</code></pre>"},{"location":"contributing/policy-controller/#11-policy-store","title":"11. Policy Store","text":"<p>Manages policy storage and indexing in Redis.</p> <p>Main methods: - <code>store_policy(policy)</code> - Store compiled policy with indexes - <code>remove_policy(namespace, name)</code> - Remove policy and indexes - <code>_invalidate_evaluation_caches(...)</code> - Clear caches for affected users/groups</p> <p>Redis structure: <pre><code>policy:{namespace}:{name}              # Policy data (hash)\npolicy:user:{user}                     # User's policies (set)\npolicy:user:{user}:sorted              # Sorted by priority (zset)\npolicy:group:{group}                   # Group's policies (set)\npolicy:group:{group}:sorted            # Sorted by priority (zset)\npolicy:sa:{sa}                         # Service account policies (set)\npolicies:all                           # All policies (set)\npolicies:enabled                       # Only enabled policies (set)\npolicies:by:priority                   # All policies by priority (zset)\npolicy:eval:{identity}:{cluster}       # Evaluation cache\nuser:groups:{username}                 # User's group membership\ngroup:members:{group}                  # Group's members\n</code></pre></p> <p>Indexing strategy: - Policies indexed by user, group, and service account - Priority-sorted sets for efficient lookup - Global indexes for all policies - Evaluation caches for performance</p> <p>Cache invalidation: When a policy changes, all affected evaluation caches must be cleared: <pre><code>def _invalidate_evaluation_caches(self, users, groups, service_accounts):\n    # Clear user caches\n    # Clear group member caches\n    # Clear service account caches\n    # Uses SCAN to find and delete matching keys\n</code></pre></p>"},{"location":"contributing/policy-controller/#12-policy-validator","title":"12. Policy Validator","text":"<p>Validates policies for expiration and conditions.</p> <p>Main methods: - <code>validate_policy(namespace, name, spec)</code> - Validate single policy - <code>validate_all_policies()</code> - Periodic validation of all policies</p> <p>Validation checks: - <code>notBefore</code> date - Policy not yet valid - <code>notAfter</code> date - Policy expired - <code>enabled</code> flag - Policy disabled</p> <pre><code>async def validate_policy(self, namespace, name, spec):\n    now = datetime.now(timezone.utc)\n\n    if validity.get(\"notBefore\"):\n        not_before = datetime.fromisoformat(...)\n        if now &lt; not_before:\n            return {\"state\": \"Inactive\", \"message\": \"Not yet valid\"}\n\n    if validity.get(\"notAfter\"):\n        not_after = datetime.fromisoformat(...)\n        if now &gt; not_after:\n            return {\"state\": \"Expired\", \"message\": \"Policy expired\"}\n</code></pre>"},{"location":"contributing/policy-controller/#13-kopf-handlers","title":"13. Kopf Handlers","text":"<p>Kubernetes operator event handlers using kopf framework.</p> <p>Handlers:</p> <p><code>@kopf.on.create</code> / <code>@kopf.on.update</code> - Triggered when MonitorAccessPolicy is created/updated - Compiles the policy - Stores in Redis - Validates and updates status</p> <p><code>@kopf.on.delete</code> - Triggered when MonitorAccessPolicy is deleted - Removes from Redis - Clears all indexes</p> <p><code>@kopf.timer</code> - Periodic validation (every 5 minutes) - Checks for expired policies - Updates status if state changed</p> <p><code>@kopf.on.startup</code> - Initializes Redis connection - Clears stale caches - Starts background tasks</p> <p><code>@kopf.on.cleanup</code> - Closes Redis connection - Cleanup on shutdown</p> <p><code>@kopf.on.probe</code> - Health check endpoint - Returns policy counts</p>"},{"location":"contributing/policy-controller/#understanding-policy-compilation","title":"Understanding Policy Compilation","text":"<p>Policy compilation is the core function. Here's how it works:</p>"},{"location":"contributing/policy-controller/#input-monitoraccesspolicy-crd","title":"Input: MonitorAccessPolicy CRD","text":"<pre><code>apiVersion: clusterpulse.io/v1alpha1\nkind: MonitorAccessPolicy\nmetadata:\n  name: dev-team-policy\n  namespace: clusterpulse\nspec:\n  identity:\n    priority: 100\n    subjects:\n      users: [\"john.doe\", \"jane.smith\"]\n      groups: [\"developers\"]\n  access:\n    effect: Allow\n    enabled: true\n  scope:\n    clusters:\n      default: none\n      rules:\n        - selector:\n            names: [\"dev-*\"]\n          permissions:\n            view: true\n            viewMetrics: true\n          resources:\n            namespaces:\n              visibility: filtered\n              filters:\n                allowed: [\"team-a-*\", \"shared-*\"]\n</code></pre>"},{"location":"contributing/policy-controller/#compilation-process","title":"Compilation Process","text":"<ol> <li>Validation:</li> <li>Check required sections (identity, access, scope)</li> <li>Validate effect (Allow/Deny)</li> <li> <p>Validate priority (must be &gt;= 0)</p> </li> <li> <p>Extract Subjects: <pre><code>users = set([\"john.doe\", \"jane.smith\"])\ngroups = set([\"developers\"])\nservice_accounts = set()  # Converted to k8s format\n</code></pre></p> </li> <li> <p>Compile Cluster Rules:</p> </li> <li>Process each rule's selector and permissions</li> <li>Compile resource filters (namespaces, nodes, operators, pods)</li> <li> <p>Convert patterns to regex or literals</p> </li> <li> <p>Pattern Compilation: <pre><code>\"team-a-*\" \u2192 regex: ^team-a-.*$\n\"shared-prod\" \u2192 literal: \"shared-prod\"\n</code></pre></p> </li> <li> <p>Generate Hash:</p> </li> <li>Hash the entire spec for change detection</li> <li>Used by API to detect policy changes</li> </ol>"},{"location":"contributing/policy-controller/#output-compiledpolicy-in-redis","title":"Output: CompiledPolicy in Redis","text":"<pre><code>{\n    \"policy_name\": \"dev-team-policy\",\n    \"namespace\": \"clusterpulse\",\n    \"priority\": 100,\n    \"effect\": \"Allow\",\n    \"enabled\": True,\n    \"users\": [\"john.doe\", \"jane.smith\"],\n    \"groups\": [\"developers\"],\n    \"cluster_rules\": [\n        {\n            \"cluster_selector\": {\"names\": [\"dev-*\"]},\n            \"permissions\": {\"view\": True, \"viewMetrics\": True},\n            \"namespace_filter\": {\n                \"visibility\": \"filtered\",\n                \"allowed_patterns\": [(\"team-a-*\", \"^team-a-.*$\")],\n                \"allowed_literals\": [],\n                ...\n            }\n        }\n    ],\n    \"compiled_at\": \"2025-01-15T10:30:00Z\",\n    \"hash\": \"a1b2c3d4e5f6\"\n}\n</code></pre>"},{"location":"contributing/policy-controller/#redis-storage-and-indexing","title":"Redis Storage and Indexing","text":"<p>When stored, the policy is indexed multiple ways:</p> <pre><code># Main policy data\nSET policy:clusterpulse:dev-team-policy {...}\n\n# Index by users\nSADD policy:user:john.doe policy:clusterpulse:dev-team-policy\nZADD policy:user:john.doe:sorted 100 policy:clusterpulse:dev-team-policy\n\n# Index by groups\nSADD policy:group:developers policy:clusterpulse:dev-team-policy\nZADD policy:group:developers:sorted 100 policy:clusterpulse:dev-team-policy\n\n# Global indexes\nSADD policies:all policy:clusterpulse:dev-team-policy\nSADD policies:enabled policy:clusterpulse:dev-team-policy\nZADD policies:by:priority 100 policy:clusterpulse:dev-team-policy\n</code></pre> <p>This allows the API to quickly find all policies for a user/group sorted by priority.</p>"},{"location":"contributing/policy-controller/#common-tasks","title":"Common Tasks","text":""},{"location":"contributing/policy-controller/#adding-a-new-policy-field","title":"Adding a New Policy Field","text":"<ol> <li>Update the validation:</li> </ol> <pre><code>def _validate_spec(self, spec: Dict[str, Any]):\n    # Add validation for new field\n    if \"newSection\" in spec:\n        new_value = spec[\"newSection\"].get(\"newField\")\n        if new_value and not isinstance(new_value, str):\n            raise PolicyValidationError(\"newField must be a string\")\n</code></pre> <ol> <li>Extract the field during compilation:</li> </ol> <pre><code>def compile_policy(self, name: str, namespace: str, spec: Dict) -&gt; CompiledPolicy:\n    # Extract new field\n    new_section = spec.get(\"newSection\", {})\n    new_value = new_section.get(\"newField\", \"default\")\n\n    # Add to compiled policy\n    return CompiledPolicy(\n        # ... existing fields\n        new_field=new_value,\n    )\n</code></pre> <ol> <li>Add to CompiledPolicy dataclass:</li> </ol> <pre><code>@dataclass\nclass CompiledPolicy:\n    # ... existing fields\n    new_field: str\n\n    def to_dict(self):\n        return {\n            # ... existing fields\n            \"new_field\": self.new_field,\n        }\n</code></pre> <ol> <li>Update the CRD (in another repository):</li> <li>Add the field to the OpenAPI schema</li> <li>Update examples and documentation</li> </ol>"},{"location":"contributing/policy-controller/#adding-a-new-resource-filter-type","title":"Adding a New Resource Filter Type","text":"<p>If you need to filter a new resource type (e.g., ConfigMaps):</p> <ol> <li>Add compilation method:</li> </ol> <pre><code>def _compile_configmap_filter(\n    self, visibility: str, filters: Dict\n) -&gt; CompiledResourceFilter:\n    \"\"\"Compile configmap-specific filters\"\"\"\n    filter_obj = CompiledResourceFilter(visibility=visibility)\n\n    # Process namespace filters\n    for pattern in filters.get(\"allowedNamespaces\", []):\n        compiled = self._compile_pattern(pattern)\n        if compiled[0] == \"literal\":\n            filter_obj.allowed_literals.add(compiled[1])\n        else:\n            filter_obj.allowed_patterns.append((pattern, compiled[1]))\n\n    # Add configmap-specific filters\n    if \"maxDataSize\" in filters:\n        filter_obj.additional_filters[\"max_data_size\"] = filters[\"maxDataSize\"]\n\n    return filter_obj\n</code></pre> <ol> <li>Add to cluster rules compilation:</li> </ol> <pre><code>def _compile_cluster_rules(self, clusters: Dict) -&gt; List[CompiledClusterRule]:\n    # ... existing code\n\n    # Process configmaps\n    if \"configmaps\" in resources:\n        cm_config = resources[\"configmaps\"]\n        configmap_filter = self._compile_configmap_filter(\n            cm_config.get(\"visibility\", \"all\"),\n            cm_config.get(\"filters\", {})\n        )\n</code></pre> <ol> <li>Add field to CompiledClusterRule:</li> </ol> <pre><code>@dataclass\nclass CompiledClusterRule:\n    # ... existing fields\n    configmap_filter: Optional[CompiledResourceFilter] = None\n\n    def to_dict(self):\n        return {\n            # ... existing fields\n            \"configmap_filter\": (\n                self.configmap_filter.to_dict() if self.configmap_filter else None\n            ),\n        }\n</code></pre>"},{"location":"contributing/policy-controller/#adding-a-new-validation-rule","title":"Adding a New Validation Rule","text":"<ol> <li>Add to <code>_validate_spec</code>:</li> </ol> <pre><code>def _validate_spec(self, spec: Dict[str, Any]):\n    # ... existing validations\n\n    # New validation\n    scope = spec.get(\"scope\", {})\n    restrictions = scope.get(\"restrictions\", {})\n\n    if \"maxClusters\" in restrictions:\n        max_clusters = restrictions[\"maxClusters\"]\n        if not isinstance(max_clusters, int) or max_clusters &lt; 1:\n            raise PolicyValidationError(\"maxClusters must be &gt;= 1\")\n</code></pre> <ol> <li>Use during compilation:</li> </ol> <pre><code>def compile_policy(self, name, namespace, spec):\n    try:\n        self._validate_spec(spec)\n        # ... continue compilation\n    except PolicyValidationError as e:\n        policy_errors.labels(error_type=\"validation\").inc()\n        raise\n</code></pre>"},{"location":"contributing/policy-controller/#changing-cache-invalidation-logic","title":"Changing Cache Invalidation Logic","text":"<p>When policies change, caches must be cleared. To modify this:</p> <pre><code>def _invalidate_evaluation_caches(self, users, groups, service_accounts):\n    count = 0\n\n    with RedisBatchProcessor(self.redis) as batch:\n        # Clear user caches\n        for user in users:\n            pattern = f\"policy:eval:{user}:*\"\n            count += self._scan_and_delete(batch, pattern)\n\n            # Add new cache type\n            batch.add_operation(\"delete\", f\"user:computed_permissions:{user}\")\n\n        # ... rest of invalidation\n</code></pre>"},{"location":"contributing/policy-controller/#adding-a-new-metric","title":"Adding a New Metric","text":"<pre><code># At top of file with other metrics\npolicy_size_bytes = Histogram(\n    \"policy_size_bytes\",\n    \"Size of compiled policies in bytes\",\n    [\"namespace\"]\n)\n\n# Use in code\ndef store_policy(self, policy: CompiledPolicy):\n    policy_data = json.dumps(policy.to_dict())\n\n    # Record metric\n    policy_size_bytes.labels(namespace=policy.namespace).observe(len(policy_data))\n\n    # Store in Redis\n    # ...\n</code></pre>"},{"location":"contributing/policy-controller/#modifying-periodic-validation","title":"Modifying Periodic Validation","text":"<p>The timer handler runs every 5 minutes by default:</p> <pre><code>@kopf.timer(\n    \"clusterpulse.io\",\n    \"v1alpha1\",\n    \"monitoraccesspolicies\",\n    interval=300,  # Change this value\n)\nasync def periodic_policy_validation(...):\n    # Validation logic\n</code></pre> <p>To make it configurable:</p> <pre><code># Add to constants\nPOLICY_VALIDATION_INTERVAL = int(os.getenv(\"POLICY_VALIDATION_INTERVAL\", 300))\n\n# Use in handler\n@kopf.timer(\n    \"clusterpulse.io\",\n    \"v1alpha1\",\n    \"monitoraccesspolicies\",\n    interval=POLICY_VALIDATION_INTERVAL,\n)\n</code></pre>"},{"location":"contributing/policy-controller/#testing","title":"Testing","text":"<p>Tests should cover:</p> <ol> <li>Policy compilation:</li> <li>Valid policy specs compile correctly</li> <li>Invalid specs raise appropriate errors</li> <li>Pattern compilation (literals vs regex)</li> <li> <p>Filter compilation for each resource type</p> </li> <li> <p>Redis storage:</p> </li> <li>Policies stored with correct indexes</li> <li>Cache invalidation clears correct keys</li> <li> <p>Batch operations work correctly</p> </li> <li> <p>Validation:</p> </li> <li>Time-based validation (notBefore, notAfter)</li> <li>Enabled/disabled flag handling</li> <li> <p>State transitions</p> </li> <li> <p>Kopf handlers:</p> </li> <li>Create/update handlers compile and store</li> <li>Delete handler removes all traces</li> <li>Status updates work correctly</li> </ol> <p>Test pattern: - TODO</p> <pre><code>import pytest\nimport fakeredis\nfrom policy_controller import PolicyCompiler, PolicyStore\n\n@pytest.fixture\ndef fake_redis():\n    return fakeredis.FakeRedis(decode_responses=True)\n\ndef test_compile_basic_policy():\n    compiler = PolicyCompiler()\n\n    spec = {\n        \"identity\": {\n            \"priority\": 100,\n            \"subjects\": {\"users\": [\"test.user\"]}\n        },\n        \"access\": {\"effect\": \"Allow\", \"enabled\": True},\n        \"scope\": {\n            \"clusters\": {\"default\": \"none\", \"rules\": []}\n        }\n    }\n\n    policy = compiler.compile_policy(\"test\", \"default\", spec)\n\n    assert policy.policy_name == \"test\"\n    assert policy.priority == 100\n    assert \"test.user\" in policy.users\n    assert policy.enabled is True\n</code></pre> <p>See <code>docs/api/tests.md</code> for more testing patterns.</p>"},{"location":"contributing/policy-controller/#code-patterns","title":"Code Patterns","text":""},{"location":"contributing/policy-controller/#error-handling","title":"Error Handling","text":"<p>Always wrap errors with context:</p> <pre><code>try:\n    compiled = policy_compiler.compile_policy(name, namespace, spec)\nexcept PolicyValidationError as e:\n    policy_errors.labels(error_type=\"validation\").inc()\n    raise PolicyCompilationError(f\"Failed to compile {namespace}/{name}: {str(e)}\")\n</code></pre> <p>Use specific exception types:</p> <pre><code>if not isinstance(spec, dict):\n    raise PolicyValidationError(\"Policy spec must be a dictionary\")\n\nif redis_error:\n    raise PolicyStorageError(f\"Failed to store policy: {str(error)}\")\n</code></pre>"},{"location":"contributing/policy-controller/#logging","title":"Logging","text":"<p>Use appropriate log levels:</p> <pre><code># Info - important state changes\nlogger.info(f\"Stored policy {policy_key} and cleared evaluation caches\")\n\n# Debug - detailed operations\nlogger.debug(f\"Cleared {count} evaluation cache entries\")\n\n# Warning - unusual but handled\nlogger.warning(f\"Policy {policy_key} not found for removal\")\n\n# Error - actual problems\nlogger.error(f\"Failed to compile policy {namespace}/{name}: {str(e)}\")\n</code></pre>"},{"location":"contributing/policy-controller/#redis-operations","title":"Redis Operations","text":"<p>Use batch operations for efficiency:</p> <pre><code>with RedisBatchProcessor(self.redis, batch_size=1000) as batch:\n    for user in policy.users:\n        batch.add_operation(\"sadd\", user_key, policy_key)\n        batch.add_operation(\"zadd\", sorted_key, {policy_key: priority})\n</code></pre> <p>Use SCAN for large key sets:</p> <pre><code>cursor = 0\nwhile True:\n    cursor, keys = self.redis.scan(\n        cursor, match=pattern, count=REDIS_SCAN_BATCH_SIZE\n    )\n    for key in keys:\n        batch.add_operation(\"delete\", key)\n    if cursor == 0:\n        break\n</code></pre>"},{"location":"contributing/policy-controller/#pattern-compilation","title":"Pattern Compilation","text":"<p>Cache compiled patterns:</p> <pre><code>@lru_cache(maxsize=1024)\ndef _compile_pattern(self, pattern: str) -&gt; Tuple[str, Any]:\n    if \"*\" in pattern or \"?\" in pattern:\n        regex_pattern = pattern.replace(\".\", r\"\\.\")\n        regex_pattern = regex_pattern.replace(\"*\", \".*\")\n        regex_pattern = regex_pattern.replace(\"?\", \".\")\n        return (\"regex\", re.compile(f\"^{regex_pattern}$\"))\n    else:\n        return (\"literal\", pattern)\n</code></pre> <p>Separate literals from patterns for performance:</p> <pre><code>for pattern in filters.get(\"allowed\", []):\n    compiled = self._compile_pattern(pattern)\n    if compiled[0] == \"literal\":\n        filter_obj.allowed_literals.add(compiled[1])  # Fast set lookup\n    else:\n        filter_obj.allowed_patterns.append((pattern, compiled[1]))  # Regex match\n</code></pre>"},{"location":"contributing/policy-controller/#status-updates","title":"Status Updates","text":"<p>Update status in handlers:</p> <pre><code>@kopf.on.update(\"clusterpulse.io\", \"v1alpha1\", \"monitoraccesspolicies\")\nasync def policy_changed(name, namespace, spec, patch, **kwargs):\n    try:\n        compiled = policy_compiler.compile_policy(name, namespace, spec)\n        policy_store.store_policy(compiled)\n\n        # Success status\n        patch[\"status\"] = {\n            \"state\": \"Active\",\n            \"compiledAt\": compiled.compiled_at,\n            \"hash\": compiled.hash,\n        }\n    except PolicyCompilationError as e:\n        # Error status\n        patch[\"status\"] = {\n            \"state\": \"Error\",\n            \"message\": str(e),\n            \"error_at\": datetime.now(timezone.utc).isoformat(),\n        }\n</code></pre>"},{"location":"contributing/policy-controller/#dataclass-serialization","title":"Dataclass Serialization","text":"<p>Ensure Redis compatibility:</p> <pre><code>def to_dict(self):\n    \"\"\"This format MUST remain unchanged for Redis compatibility\"\"\"\n    return {\n        \"policy_name\": self.policy_name,\n        \"users\": list(self.users),  # Convert sets to lists\n        \"groups\": list(self.groups),\n        \"cluster_rules\": [r.to_dict() for r in self.cluster_rules],  # Nested\n        \"compiled_at\": self.compiled_at,  # ISO format string\n    }\n\n@classmethod\ndef from_dict(cls, data: Dict) -&gt; \"CompiledResourceFilter\":\n    \"\"\"Reconstruct from Redis data\"\"\"\n    obj = cls(visibility=data.get(\"visibility\", \"all\"))\n\n    # Reconstruct compiled patterns\n    for pattern_str, regex_str in data.get(\"allowed_patterns\", []):\n        obj.allowed_patterns.append((pattern_str, re.compile(regex_str)))\n\n    obj.allowed_literals = set(data.get(\"allowed_literals\", []))\n    return obj\n</code></pre>"},{"location":"contributing/policy-controller/#performance-considerations","title":"Performance Considerations","text":""},{"location":"contributing/policy-controller/#batch-operations","title":"Batch Operations","text":"<p>Always batch Redis operations:</p> <pre><code># DON'T - N individual operations\nfor key in keys:\n    redis_client.delete(key)\n\n# DO - Single pipeline\nwith RedisBatchProcessor(redis_client) as batch:\n    for key in keys:\n        batch.add_operation(\"delete\", key)\n</code></pre>"},{"location":"contributing/policy-controller/#pattern-compilation-caching","title":"Pattern Compilation Caching","text":"<p>The <code>@lru_cache</code> decorator caches compiled patterns:</p> <pre><code>@lru_cache(maxsize=1024)\ndef _compile_pattern(self, pattern: str):\n    # This result is cached - subsequent calls with same pattern are instant\n</code></pre>"},{"location":"contributing/policy-controller/#scan-instead-of-keys","title":"SCAN Instead of KEYS","text":"<p>Use SCAN for large keysets to avoid blocking:</p> <pre><code># DON'T - Blocks Redis\nkeys = redis_client.keys(\"policy:eval:*\")\n\n# DO - Iterative scan\ncursor = 0\nwhile True:\n    cursor, keys = redis_client.scan(cursor, match=\"policy:eval:*\", count=100)\n    # Process keys\n    if cursor == 0:\n        break\n</code></pre>"},{"location":"contributing/policy-controller/#parallel-operations","title":"Parallel Operations","text":"<p>Use <code>asyncio</code> for parallel validation:</p> <pre><code>async def validate_all_policies(self):\n    policies = self.policy_store.list_policies()\n\n    # Process in batches\n    tasks = []\n    for policy_key in policies:\n        task = self.validate_single_policy(policy_key)\n        tasks.append(task)\n\n    await asyncio.gather(*tasks, return_exceptions=True)\n</code></pre>"},{"location":"contributing/policy-controller/#metrics-collection-overhead","title":"Metrics Collection Overhead","text":"<p>Metrics are lightweight but add up. Use labels wisely:</p> <pre><code># Good - Few label values\npolicy_errors.labels(error_type=\"validation\").inc()\n\n# Bad - Too many unique label combinations\npolicy_errors.labels(\n    namespace=namespace,\n    name=name,\n    error_type=type,\n    user=user,\n    cluster=cluster\n).inc()\n</code></pre>"},{"location":"contributing/policy-controller/#common-pitfalls","title":"Common Pitfalls","text":"<ol> <li> <p>Breaking Redis compatibility: <pre><code># \u274c Wrong - Changes API expects\ndef to_dict(self):\n    return {\n        \"policyName\": self.policy_name,  # Should be policy_name\n        \"users\": self.users,              # Should be list(self.users)\n    }\n\n# \u2705 Right\ndef to_dict(self):\n    return {\n        \"policy_name\": self.policy_name,\n        \"users\": list(self.users),\n    }\n</code></pre></p> </li> <li> <p>Not invalidating caches: <pre><code># \u274c Wrong - API will serve stale decisions\ndef store_policy(self, policy):\n    self.redis.set(policy_key, data)\n    # Forgot to clear caches!\n\n# \u2705 Right\ndef store_policy(self, policy):\n    self.redis.set(policy_key, data)\n    self._invalidate_evaluation_caches(\n        policy.users, policy.groups, policy.service_accounts\n    )\n</code></pre></p> </li> <li> <p>Using KEYS instead of SCAN: <pre><code># \u274c Wrong - Blocks Redis on large datasets\nkeys = redis_client.keys(\"policy:eval:*\")\n\n# \u2705 Right\ndef _scan_and_delete(self, batch, pattern):\n    cursor = 0\n    while True:\n        cursor, keys = self.redis.scan(cursor, match=pattern, count=100)\n        # Process keys\n        if cursor == 0:\n            break\n</code></pre></p> </li> <li> <p>Not handling None values: <pre><code># \u274c Wrong - Will crash on None\nallowed = filters[\"allowed\"]\n\n# \u2705 Right\nallowed = filters.get(\"allowed\", [])\n</code></pre></p> </li> <li> <p>Forgetting to update status: <pre><code># \u274c Wrong - User doesn't see compilation errors\n@kopf.on.update(...)\nasync def policy_changed(name, namespace, spec, **kwargs):\n    compiled = compiler.compile_policy(name, namespace, spec)\n    # No status update!\n\n# \u2705 Right\n@kopf.on.update(...)\nasync def policy_changed(name, namespace, spec, patch, **kwargs):\n    try:\n        compiled = compiler.compile_policy(name, namespace, spec)\n        patch[\"status\"] = {\"state\": \"Active\", ...}\n    except Exception as e:\n        patch[\"status\"] = {\"state\": \"Error\", \"message\": str(e)}\n</code></pre></p> </li> <li> <p>Not using batch processor context manager: <pre><code># \u274c Wrong - Manual execution\nbatch = RedisBatchProcessor(redis_client)\nbatch.add_operation(\"set\", key, value)\nbatch.execute()  # Easy to forget!\n\n# \u2705 Right - Auto-executes\nwith RedisBatchProcessor(redis_client) as batch:\n    batch.add_operation(\"set\", key, value)\n</code></pre></p> </li> <li> <p>Storing sets directly in JSON: <pre><code># \u274c Wrong - Sets aren't JSON serializable\njson.dumps({\"users\": policy.users})\n\n# \u2705 Right - Convert to list\njson.dumps({\"users\": list(policy.users)})\n</code></pre></p> </li> </ol>"},{"location":"contributing/policy-controller/#code-style","title":"Code Style","text":"<p>Use <code>black</code> for formatting:</p> <pre><code>black policy_controller.py\n</code></pre> <p>Use <code>autoflake</code> to remove unused imports and variables</p> <pre><code>autoflake --remove-all-unused-imports --remove-unused-variables --recursive --in-place policy_controller.py\n</code></pre> <p>Use <code>isort</code> to sort imports</p> <pre><code>isort policy_controller.py\n</code></pre> <p>Use type hints:</p> <pre><code>def compile_policy(\n    self, name: str, namespace: str, spec: Dict[str, Any]\n) -&gt; CompiledPolicy:\n    # Implementation\n</code></pre> <p>Docstrings for public methods:</p> <pre><code>def store_policy(self, policy: CompiledPolicy):\n    \"\"\"Store compiled policy in Redis with indexes\n\n    Args:\n        policy: The compiled policy to store\n\n    Raises:\n        PolicyStorageError: If Redis operation fails\n    \"\"\"\n</code></pre>"},{"location":"contributing/policy-controller/#pull-request-process","title":"Pull Request Process","text":"<ol> <li> <p>Branch naming: <code>feature/add-configmap-filter</code> or <code>fix/cache-invalidation</code></p> </li> <li> <p>Commits:</p> </li> <li>\u2705 \"Add ConfigMap resource filter support\"</li> <li>\u2705 \"Fix cache invalidation for service accounts\"</li> <li> <p>\u274c \"WIP\" or \"Fix stuff\"</p> </li> <li> <p>Before submitting: <pre><code># Format code\nblack policy_controller.py\n\n# Run tests - TODO\npytest tests/\n\n# Check types\nmypy policy_controller.py\n\n# Test with real CRD\noc apply -f examples/policy.yaml\n</code></pre></p> </li> <li> <p>PR description should include:</p> </li> <li>What changed and why</li> <li>Redis format changes (critical!)</li> <li>Impact on API RBAC engine</li> <li> <p>How to test it</p> </li> <li> <p>Things reviewers look for:</p> </li> <li>Redis format compatibility maintained</li> <li>Cache invalidation is correct</li> <li>Status updates on errors</li> <li>Batch operations used</li> <li>Metrics added for new operations</li> <li>Tests cover new functionality</li> </ol>"},{"location":"contributing/policy-controller/#coordination-with-api","title":"Coordination with API","text":"<p>The policy-controller and API are tightly coupled through Redis:</p> <p>Policy Controller writes: <pre><code>{\n    \"policy_name\": \"dev-policy\",\n    \"users\": [\"user1\"],\n    \"cluster_rules\": [...],\n}\n</code></pre></p> <p>API reads: <pre><code># api/services/rbac.py\npolicy_data = redis.hget(policy_key, \"data\")\npolicy = json.loads(policy_data)\nusers = policy[\"users\"]\n</code></pre></p> <p>Critical: Any change to the compiled format requires coordinated deployment: 1. Update policy-controller code 2. Update API RBAC engine code 3. Deploy policy-controller first 4. Recompile all policies (triggers update handlers) 5. Deploy API</p> <p>Safe changes: - Adding optional fields (with defaults in API) - Adding new filter types (ignored if API doesn't check) - Adding metrics</p> <p>Breaking changes: - Renaming fields - Changing data types - Removing fields</p>"},{"location":"contributing/policy-controller/#quick-reference","title":"Quick Reference","text":""},{"location":"contributing/policy-controller/#environment-variables","title":"Environment Variables","text":"<pre><code>NAMESPACE=clusterpulse                 # Operator namespace\nREDIS_HOST=redis                       # Redis host\nREDIS_PORT=6379                        # Redis port\nREDIS_PASSWORD=                        # Redis password (optional)\nPOLICY_CACHE_TTL=300                   # Cache TTL in seconds\nPOLICY_VALIDATION_INTERVAL=300         # Validation interval\nMAX_POLICIES_PER_USER=100              # User policy limit\n</code></pre>"},{"location":"contributing/policy-controller/#common-redis-keys","title":"Common Redis Keys","text":"<pre><code>policy:{namespace}:{name}              # Policy data\npolicy:user:{user}                     # User's policies\npolicy:group:{group}                   # Group's policies\npolicy:eval:{identity}:{cluster}       # Evaluation cache\nuser:groups:{username}                 # User's groups\n</code></pre>"},{"location":"contributing/policy-controller/#useful-commands","title":"Useful Commands","text":"<pre><code># Development\npython policy_controller.py\n\n# Testing - TODO\npytest tests/\n\n# Format\nblack policy_controller.py\n\n# Remove unused imports\nautoflake --remove-all-unused-imports --remove-unused-variables --recursive --in-place &lt;path&gt;\n\n# Sort imports\nisort &lt;path&gt;\n\n# Check Redis\nredis-cli\n&gt; KEYS policy:*\n&gt; HGETALL policy:clusterpulse:dev-policy\n&gt; SMEMBERS policy:user:john.doe\n\n# Watch logs\noc logs -f -n clusterpulse deployment/policy-controller\n</code></pre>"},{"location":"contributing/policy-controller/#kopf-commands","title":"Kopf Commands","text":"<pre><code># Run with debug logging\nkopf run policy_controller.py --verbose\n\n# Run in standalone mode (no leader election)\nkopf run policy_controller.py --standalone\n\n# Configure namespace\nkopf run policy_controller.py --namespace=clusterpulse\n</code></pre>"},{"location":"contributing/policy-controller/#getting-help","title":"Getting Help","text":"<ul> <li>Review RBAC engine in API (<code>api/services/rbac.py</code>) to understand usage</li> <li>Read kopf documentation: https://kopf.readthedocs.io</li> <li>Check Redis data directly with <code>redis-cli</code> to debug storage issues</li> <li>Look at Prometheus metrics for performance insights</li> </ul>"},{"location":"contributing/policy-controller/#project-specific-notes","title":"Project-Specific Notes","text":"<ul> <li>Single file architecture: All code in one file, organized by sections</li> <li>Redis is the contract: Format cannot change without API coordination</li> <li>Kopf framework: Uses decorators for event handlers</li> <li>Batch everything: Redis operations should use pipelines</li> <li>Cache invalidation is critical: Stale caches cause incorrect authorization</li> <li>Pattern compilation is cached: Same patterns reused across policies</li> <li>Status updates in CRD: Users see compilation errors/success in oc</li> <li>Metrics for observability: All operations instrumented with Prometheus</li> </ul>"},{"location":"getting-started/","title":"Quickstart","text":"<p>Get ClusterPulse running and monitoring a cluster in 5 minutes.</p>"},{"location":"getting-started/#prerequisites","title":"Prerequisites","text":"<ul> <li>Kubernetes cluster with <code>oc</code> access</li> <li>Helm 3.x installed</li> <li>Redis instance (or use the bundled one)</li> </ul>"},{"location":"getting-started/#step-1-install-clusterpulse","title":"Step 1: Install ClusterPulse","text":""},{"location":"getting-started/#operatorhub","title":"OperatorHub","text":"<p>ClusterPulse can be deployed through OLM in the OperatorHub. It is currently inside the community operator index!</p>"},{"location":"getting-started/#helm","title":"Helm","text":"<pre><code>git clone https://github.com/ClusterPulse/operator.git\ncd operator/\nmake install                            # Will install CRDs\nhelm install clusterpulse ./helm-charts/clusterpulse        # Will install ClusterPulse\n</code></pre>"},{"location":"getting-started/#step-2-connect-a-cluster","title":"Step 2: Connect a Cluster","text":"<p>Create a ClusterConnection to monitor your cluster: <pre><code>apiVersion: clusterpulse.io/v1alpha1\nkind: ClusterConnection\nmetadata:\n  name: my-cluster\n  namespace: clusterpulse\nspec:\n  displayName: \"My Production Cluster\"\n  endpoint: https://api.my-cluster.example.com:6443\n  credentialsRef:\n    name: my-cluster-creds\n  monitoring:\n    interval: 30\n</code></pre> <pre><code>oc apply -f cluster-connection.yaml\n</code></pre></p>"},{"location":"getting-started/#step-3-create-an-access-policy","title":"Step 3: Create an Access Policy","text":"<p>Allow your team to view the cluster: <pre><code>apiVersion: clusterpulse.io/v1alpha1\nkind: MonitorAccessPolicy\nmetadata:\n  name: dev-team-access\n  namespace: clusterpulse\nspec:\n  identity:\n    priority: 100\n    subjects:\n      groups: [\"developers\"]\n  access:\n    effect: Allow\n    enabled: true\n  scope:\n    clusters:\n      default: none\n      rules:\n        - selector:\n            names: [\"my-cluster\"]\n          permissions:\n            view: true\n            viewMetrics: true\n</code></pre> <pre><code>oc apply -f policy.yaml\n</code></pre></p>"},{"location":"getting-started/#step-4-access-the-ui","title":"Step 4: Access the UI","text":"<pre><code># Get the route ClusterPulse created\noc get routes -n &lt;clusterpulse_ns&gt;\n</code></pre>"},{"location":"getting-started/#next-steps","title":"Next Steps","text":"<ul> <li>Add more clusters</li> <li>Learn RBAC concepts</li> <li>Create namespace-filtered policies</li> </ul>"},{"location":"getting-started/installation/","title":"Installation","text":"<p>ClusterPulse can be installed on OpenShift clusters via OperatorHub or on any Kubernetes cluster using Helm.</p>"},{"location":"getting-started/installation/#prerequisites","title":"Prerequisites","text":"<ul> <li>OpenShift 4.x or Kubernetes 1.21+ cluster</li> <li>Cluster administrator privileges</li> <li>For Helm installation: Helm 3.x installed locally</li> </ul>"},{"location":"getting-started/installation/#operatorhub-installation-openshift","title":"OperatorHub Installation (OpenShift)","text":"<p>ClusterPulse is available in the OperatorHub community operator index.</p>"},{"location":"getting-started/installation/#gui-installation","title":"GUI Installation","text":"<ol> <li> <p>Log in to the OpenShift web console as a cluster administrator.</p> </li> <li> <p>Navigate to Operators &gt; OperatorHub in the left sidebar.</p> </li> <li> <p>In the search field, enter <code>ClusterPulse</code>.</p> </li> <li> <p>Select the ClusterPulse tile from the search results.</p> </li> <li> <p>Review the operator information and click Install.</p> </li> <li> <p>Configure the installation options:</p> <ul> <li>Update channel: Select the desired release channel.</li> <li>Installation mode: Choose whether to install in a specific namespace or all namespaces.</li> <li>Installed Namespace: Select or create the target namespace.</li> <li>Update approval: Select <code>Automatic</code> or <code>Manual</code> based on your upgrade policy.</li> </ul> </li> <li> <p>Click Install to begin the installation.</p> </li> <li> <p>Wait for the operator status to display <code>Succeeded</code>. This can be monitored under Operators &gt; Installed Operators.</p> </li> <li> <p>Once installed, create a ClusterPulse instance by navigating to the operator's detail page and selecting Create Instance under the provided API.</p> </li> </ol>"},{"location":"getting-started/installation/#cli-installation","title":"CLI Installation","text":"<ol> <li> <p>Create a namespace for the operator (optional, if not using an existing namespace):</p> <pre><code>oc create namespace clusterpulse\n</code></pre> </li> <li> <p>Create an <code>OperatorGroup</code> if one does not already exist in the target namespace:</p> <pre><code>apiVersion: operators.coreos.com/v1\nkind: OperatorGroup\nmetadata:\n  name: clusterpulse-operatorgroup\n  namespace: clusterpulse\nspec:\n  targetNamespaces:\n    - clusterpulse\n</code></pre> <p>Apply the manifest:</p> <pre><code>oc apply -f operatorgroup.yaml\n</code></pre> </li> <li> <p>Create a <code>Subscription</code> to install the operator:</p> <pre><code>apiVersion: operators.coreos.com/v1alpha1\nkind: Subscription\nmetadata:\n  name: clusterpulse\n  namespace: clusterpulse\nspec:\n  channel: stable\n  name: clusterpulse\n  source: community-operators\n  sourceNamespace: openshift-marketplace\n  installPlanApproval: Automatic\n</code></pre> <p>Apply the manifest:</p> <pre><code>oc apply -f subscription.yaml\n</code></pre> </li> <li> <p>Verify the operator installation:</p> <pre><code>oc get csv -n clusterpulse\n</code></pre> <p>The output should show the ClusterPulse operator with a phase of <code>Succeeded</code>.</p> </li> <li> <p>Create a ClusterPulse custom resource to deploy the application. The default options should suffice for most instances:</p> <pre><code>apiVersion: clusterpulse.io/v1alpha1\nkind: ClusterPulse\nmetadata:\n  name: clusterpulse\n  namespace: clusterpulse\nspec:\n  # Add configuration options as needed\n</code></pre> <p>Apply the manifest:</p> <pre><code>oc apply -f clusterpulse-cr.yaml\n</code></pre> </li> </ol>"},{"location":"getting-started/installation/#helm-installation","title":"Helm Installation","text":"<p>Helm installation is suitable for any Kubernetes cluster, including OpenShift.</p> <ol> <li> <p>Clone the operator repository:</p> <pre><code>git clone https://github.com/ClusterPulse/operator.git\ncd operator/\n</code></pre> </li> <li> <p>Install the Custom Resource Definitions:</p> <pre><code>make install\n</code></pre> </li> <li> <p>Install ClusterPulse using Helm:</p> <pre><code>helm install clusterpulse ./helm-charts/clusterpulse\n</code></pre> </li> <li> <p>To install in a specific namespace:</p> <pre><code>helm install clusterpulse ./helm-charts/clusterpulse --namespace clusterpulse --create-namespace\n</code></pre> </li> <li> <p>Verify the installation:</p> <pre><code>oc get pods -n clusterpulse\n</code></pre> </li> </ol>"},{"location":"getting-started/installation/#helm-configuration","title":"Helm Configuration","text":"<p>To customize the installation, create a <code>values.yaml</code> file with your configuration overrides:</p> <pre><code>helm install clusterpulse ./helm-charts/clusterpulse -f values.yaml\n</code></pre> <p>Refer to the chart's default <code>values.yaml</code> in <code>./helm-charts/clusterpulse/values.yaml</code> for available configuration options.</p>"},{"location":"getting-started/installation/#upgrading","title":"Upgrading","text":"<p>To upgrade an existing Helm installation:</p> <pre><code>cd operator/\ngit pull\nhelm upgrade clusterpulse ./helm-charts/clusterpulse\n</code></pre>"},{"location":"getting-started/installation/#uninstalling","title":"Uninstalling","text":"<p>To remove ClusterPulse installed via Helm:</p> <pre><code>helm uninstall clusterpulse\nmake uninstall  # Removes CRDs\n</code></pre>"},{"location":"getting-started/installation/#post-installation","title":"Post-Installation","text":"<p>After installation, configure the following:</p> <ol> <li>Target Clusters: Add the Kubernetes clusters you want to monitor.</li> <li>RBAC Policies: Define access control policies for your users and teams.</li> <li>Authentication: Configure OAuth2 integration with your identity provider.</li> </ol>"},{"location":"how-to/","title":"Index","text":"<ul> <li>Create Read-only Policy</li> <li>Filter By Namespace</li> <li>Add an OpenShift Cluster</li> </ul>"},{"location":"how-to/clusters/add-openshift-cluster/","title":"Add an OpenShift Cluster","text":"<p>This guide covers connecting an OpenShift cluster to ClusterPulse for monitoring.</p>"},{"location":"how-to/clusters/add-openshift-cluster/#prerequisites","title":"Prerequisites","text":"<ul> <li><code>oc</code> CLI installed and authenticated to the target OpenShift cluster</li> <li><code>cluster-admin</code> or equivalent permissions on the target cluster</li> <li>ClusterPulse deployed and running</li> </ul>"},{"location":"how-to/clusters/add-openshift-cluster/#step-1-create-a-service-account","title":"Step 1: Create a Service Account","text":"<p>Create a service account on the target cluster that ClusterPulse will use for authentication.</p> <pre><code>oc create serviceaccount clusterpulse-reader -n kube-system\n</code></pre>"},{"location":"how-to/clusters/add-openshift-cluster/#step-2-assign-permissions","title":"Step 2: Assign Permissions","text":"<p>Bind the <code>cluster-reader</code> ClusterRole to the service account. This grants read-only access to cluster resources.</p> <pre><code>oc adm policy add-cluster-role-to-user cluster-reader \\\n  system:serviceaccount:kube-system:clusterpulse-reader\n</code></pre> <p>For collecting operator information via OLM, add view permissions for the <code>operators.coreos.com</code> API group:</p> <pre><code>oc adm policy add-cluster-role-to-user view \\\n  system:serviceaccount:kube-system:clusterpulse-reader\n</code></pre>"},{"location":"how-to/clusters/add-openshift-cluster/#step-3-generate-a-long-lived-token","title":"Step 3: Generate a Long-Lived Token","text":"<p>OpenShift 4.11+ requires explicit token creation. Create a secret to hold the service account token:</p> <pre><code>apiVersion: v1\nkind: Secret\nmetadata:\n  name: clusterpulse-reader-token\n  namespace: kube-system\n  annotations:\n    kubernetes.io/service-account.name: clusterpulse-reader\ntype: kubernetes.io/service-account-token\n</code></pre> <p>Apply the secret:</p> <pre><code>oc apply -f - &lt;&lt;EOF\napiVersion: v1\nkind: Secret\nmetadata:\n  name: clusterpulse-reader-token\n  namespace: kube-system\n  annotations:\n    kubernetes.io/service-account.name: clusterpulse-reader\ntype: kubernetes.io/service-account-token\nEOF\n</code></pre> <p>Wait a few seconds for the token to be populated, then extract it:</p> <pre><code>TOKEN=$(oc get secret clusterpulse-reader-token -n kube-system \\\n  -o jsonpath='{.data.token}' | base64 -d)\n</code></pre>"},{"location":"how-to/clusters/add-openshift-cluster/#step-4-extract-the-ca-certificate","title":"Step 4: Extract the CA Certificate","text":"<p>Retrieve the cluster CA certificate:</p> <pre><code>oc get secret clusterpulse-reader-token -n kube-system \\\n  -o jsonpath='{.data.ca\\.crt}' | base64 -d &gt; ca.crt\n</code></pre>"},{"location":"how-to/clusters/add-openshift-cluster/#step-5-get-the-api-server-endpoint","title":"Step 5: Get the API Server Endpoint","text":"<pre><code>API_SERVER=$(oc whoami --show-server)\necho $API_SERVER\n</code></pre>"},{"location":"how-to/clusters/add-openshift-cluster/#step-6-create-the-credentials-secret-in-clusterpulse","title":"Step 6: Create the Credentials Secret in ClusterPulse","text":"<p>Switch to the cluster where ClusterPulse is deployed and create a secret containing the credentials:</p> <pre><code>oc create secret generic my-openshift-cluster-creds \\\n  --namespace clusterpulse \\\n  --from-literal=token=\"$TOKEN\" \\\n  --from-file=ca.crt=ca.crt\n</code></pre>"},{"location":"how-to/clusters/add-openshift-cluster/#step-7-create-the-clusterconnection-resource","title":"Step 7: Create the ClusterConnection Resource","text":"<p>Create a <code>ClusterConnection</code> custom resource to register the cluster:</p> <pre><code>apiVersion: clusterpulse.io/v1alpha1\nkind: ClusterConnection\nmetadata:\n  name: my-openshift-cluster\n  namespace: clusterpulse\nspec:\n  displayName: \"Production OpenShift\"\n  endpoint: \"https://api.cluster.example.com:6443\"\n  credentialsRef:\n    name: my-openshift-cluster-creds\n    namespace: clusterpulse\n  labels:\n    environment: production\n    platform: openshift\n  monitoring:\n    interval: 30\n    timeout: 10\n</code></pre> <p>Apply the resource:</p> <pre><code>oc apply -f clusterconnection.yaml\n</code></pre>"},{"location":"how-to/clusters/add-openshift-cluster/#step-8-verify-the-connection","title":"Step 8: Verify the Connection","text":"<p>Check the status of the ClusterConnection:</p> <pre><code>oc get clusterconnection my-openshift-cluster -n clusterpulse\n</code></pre> <p>Expected output:</p> <pre><code>NAME                   DISPLAY NAME          ENDPOINT                              STATUS      HEALTH    AGE\nmy-openshift-cluster   Production OpenShift  https://api.cluster.example.com:6443  Connected   healthy   30s\n</code></pre> <p>For detailed status:</p> <pre><code>oc describe clusterconnection my-openshift-cluster -n clusterpulse\n</code></pre>"},{"location":"how-to/clusters/add-openshift-cluster/#configuration-reference","title":"Configuration Reference","text":""},{"location":"how-to/clusters/add-openshift-cluster/#clusterconnection-spec","title":"ClusterConnection Spec","text":"Field Type Required Description <code>displayName</code> string No Human-readable name shown in the UI <code>endpoint</code> string Yes API server URL including port <code>credentialsRef.name</code> string Yes Name of the credentials secret <code>credentialsRef.namespace</code> string No Namespace of the secret (defaults to ClusterConnection namespace) <code>labels</code> map No Key-value pairs for categorization <code>monitoring.interval</code> int32 No Reconciliation interval in seconds (minimum 30, default 30) <code>monitoring.timeout</code> int32 No Connection timeout in seconds (minimum 5, default 10)"},{"location":"how-to/clusters/add-openshift-cluster/#credentials-secret-format","title":"Credentials Secret Format","text":"<p>The secret must contain:</p> Key Required Description <code>token</code> Yes Bearer token for API authentication <code>ca.crt</code> No CA certificate for TLS verification. If omitted, TLS verification is skipped."},{"location":"how-to/clusters/add-openshift-cluster/#troubleshooting","title":"Troubleshooting","text":""},{"location":"how-to/clusters/add-openshift-cluster/#connection-test-failed","title":"Connection Test Failed","text":"<p>Check that the token is valid:</p> <pre><code>curl -k -H \"Authorization: Bearer $TOKEN\" \\\n  \"$API_SERVER/api/v1/namespaces?limit=1\"\n</code></pre>"},{"location":"how-to/clusters/add-openshift-cluster/#certificate-verification-errors","title":"Certificate Verification Errors","text":"<p>Ensure the CA certificate matches the cluster. Re-extract it from the service account secret or retrieve it from the cluster:</p> <pre><code>oc config view --raw -o jsonpath='{.clusters[0].cluster.certificate-authority-data}' | base64 -d\n</code></pre>"},{"location":"how-to/clusters/add-openshift-cluster/#insufficient-permissions","title":"Insufficient Permissions","text":"<p>Verify the service account has the required roles:</p> <pre><code>oc auth can-i --list --as=system:serviceaccount:kube-system:clusterpulse-reader\n</code></pre> <p>The service account needs at minimum: - <code>get</code>, <code>list</code>, <code>watch</code> on nodes, namespaces, pods, deployments, services, statefulsets, daemonsets - <code>get</code>, <code>list</code> on clusterversions, clusteroperators (for OpenShift-specific features) - <code>get</code>, <code>list</code> on subscriptions, clusterserviceversions (for OLM operator discovery)</p>"},{"location":"how-to/policies/create-readonly-policy/","title":"Create a Read-Only Policy","text":"<p>This guide demonstrates how to create a <code>MonitorAccessPolicy</code> that grants read-only access to cluster resources.</p>"},{"location":"how-to/policies/create-readonly-policy/#prerequisites","title":"Prerequisites","text":"<ul> <li>ClusterPulse installed and running</li> <li><code>oc</code> access to the cluster</li> <li>Appropriate RBAC permissions to create <code>MonitorAccessPolicy</code> resources</li> </ul>"},{"location":"how-to/policies/create-readonly-policy/#basic-read-only-policy","title":"Basic Read-Only Policy","text":"<p>The following policy grants view-only access to all clusters for members of the <code>cluster-viewers</code> group:</p> <pre><code>apiVersion: clusterpulse.io/v1alpha1\nkind: MonitorAccessPolicy\nmetadata:\n  name: readonly-viewers\n  namespace: clusterpulse\nspec:\n  identity:\n    priority: 100\n    subjects:\n      groups:\n        - cluster-viewers\n\n  access:\n    effect: Allow\n    enabled: true\n\n  scope:\n    clusters:\n      default: all\n      rules:\n        - selector:\n            matchPattern: .*\n          permissions:\n            view: true\n            viewMetrics: true\n            exec: false\n            portForward: false\n            logs: false\n</code></pre> <p>Apply the policy:</p> <pre><code>oc apply -f readonly-viewers.yaml\n</code></pre>"},{"location":"how-to/policies/create-readonly-policy/#read-only-policy-for-specific-users","title":"Read-Only Policy for Specific Users","text":"<p>To grant read-only access to specific users instead of groups:</p> <pre><code>apiVersion: clusterpulse.io/v1alpha1\nkind: MonitorAccessPolicy\nmetadata:\n  name: readonly-users\n  namespace: clusterpulse\nspec:\n  identity:\n    priority: 100\n    subjects:\n      users:\n        - alice@example.com\n        - bob@example.com\n\n  access:\n    effect: Allow\n    enabled: true\n\n  scope:\n    clusters:\n      default: all\n      rules:\n        - selector:\n            matchPattern: .*\n          permissions:\n            view: true\n            viewMetrics: true\n</code></pre>"},{"location":"how-to/policies/create-readonly-policy/#read-only-access-to-specific-clusters","title":"Read-Only Access to Specific Clusters","text":"<p>Restrict read-only access to clusters matching specific criteria:</p> <pre><code>apiVersion: clusterpulse.io/v1alpha1\nkind: MonitorAccessPolicy\nmetadata:\n  name: readonly-production\n  namespace: clusterpulse\nspec:\n  identity:\n    priority: 100\n    subjects:\n      groups:\n        - production-viewers\n\n  access:\n    effect: Allow\n    enabled: true\n\n  scope:\n    clusters:\n      default: none\n      rules:\n        - selector:\n            environment: production\n          permissions:\n            view: true\n            viewMetrics: true\n</code></pre> <p>The <code>default: none</code> setting ensures users only see clusters that explicitly match the selector rules.</p>"},{"location":"how-to/policies/create-readonly-policy/#verification","title":"Verification","text":"<p>After applying the policy, verify it was compiled successfully:</p> <pre><code>oc get monitoraccesspolicy readonly-viewers -n clusterpulse -o yaml\n</code></pre> <p>Check the <code>status</code> section:</p> <pre><code>status:\n  state: Active\n  message: Policy is active\n  compiledAt: \"2024-01-15T10:30:00Z\"\n  affectedUsers: 0\n  affectedGroups: 1\n</code></pre>"},{"location":"how-to/policies/create-readonly-policy/#troubleshooting","title":"Troubleshooting","text":""},{"location":"how-to/policies/create-readonly-policy/#policy-not-taking-effect","title":"Policy Not Taking Effect","text":"<ol> <li> <p>Verify the policy state is <code>Active</code>:    <pre><code>oc get monitoraccesspolicy -n clusterpulse\n</code></pre></p> </li> <li> <p>Check the policy controller logs:    <pre><code>oc logs -n clusterpulse deployment/policy-controller\n</code></pre></p> </li> <li> <p>Verify the user's group membership matches the policy subjects.</p> </li> </ol>"},{"location":"how-to/policies/create-readonly-policy/#conflicting-policies","title":"Conflicting Policies","text":"<p>When multiple policies apply to a user, they are evaluated by priority (lower values first). The first matching <code>Allow</code> or <code>Deny</code> policy determines access.</p> <p>To debug policy evaluation, use the <code>/api/v1/auth/policies</code> endpoint to see which policies apply to the current user.</p>"},{"location":"how-to/policies/create-readonly-policy/#next-steps","title":"Next Steps","text":"<ul> <li>Filter by Namespace - Restrict access to specific namespaces</li> <li>RBAC Basics Tutorial - Learn the fundamentals of ClusterPulse RBAC</li> </ul>"},{"location":"how-to/policies/filter-by-namespace/","title":"Filter by Namespace","text":"<p>This guide explains how to configure <code>MonitorAccessPolicy</code> resources to restrict visibility to specific namespaces.</p>"},{"location":"how-to/policies/filter-by-namespace/#overview","title":"Overview","text":"<p>Namespace filtering controls which namespaces a user can see within a cluster. When namespace filtering is applied:</p> <ul> <li>Namespace lists are filtered to show only permitted namespaces</li> <li>Pod, deployment, and service counts reflect only resources in permitted namespaces</li> <li>Cluster metrics are recalculated based on visible namespaces</li> </ul>"},{"location":"how-to/policies/filter-by-namespace/#basic-namespace-filter","title":"Basic Namespace Filter","text":"<p>The following policy allows access only to namespaces starting with <code>app-</code>:</p> <pre><code>apiVersion: clusterpulse.io/v1alpha1\nkind: MonitorAccessPolicy\nmetadata:\n  name: app-namespace-access\n  namespace: clusterpulse\nspec:\n  identity:\n    priority: 100\n    subjects:\n      groups:\n        - app-developers\n\n  access:\n    effect: Allow\n    enabled: true\n\n  scope:\n    clusters:\n      default: filtered\n      rules:\n        - selector:\n            matchPattern: .*\n          permissions:\n            view: true\n            viewMetrics: true\n          resources:\n            namespaces:\n              visibility: filtered\n              filters:\n                allowed:\n                  - \"app-*\"\n</code></pre>"},{"location":"how-to/policies/filter-by-namespace/#visibility-options","title":"Visibility Options","text":"<p>The <code>visibility</code> field accepts three values:</p> Value Behavior <code>all</code> No filtering. User sees all namespaces. <code>none</code> Complete restriction. User sees no namespaces. <code>filtered</code> Apply include/exclude rules from <code>filters</code>."},{"location":"how-to/policies/filter-by-namespace/#filter-patterns","title":"Filter Patterns","text":""},{"location":"how-to/policies/filter-by-namespace/#wildcard-patterns","title":"Wildcard Patterns","text":"<p>Use <code>*</code> to match any characters and <code>?</code> to match a single character:</p> <pre><code>filters:\n  allowed:\n    - \"app-*\"        # Matches app-frontend, app-backend, etc.\n    - \"team-?-prod\"  # Matches team-a-prod, team-b-prod, etc.\n</code></pre>"},{"location":"how-to/policies/filter-by-namespace/#literal-values","title":"Literal Values","text":"<p>Exact namespace names without wildcards:</p> <pre><code>filters:\n  allowed:\n    - default\n    - monitoring\n    - logging\n</code></pre>"},{"location":"how-to/policies/filter-by-namespace/#combining-allowed-and-denied","title":"Combining Allowed and Denied","text":"<p>The <code>denied</code> list takes precedence over <code>allowed</code>:</p> <pre><code>resources:\n  namespaces:\n    visibility: filtered\n    filters:\n      allowed:\n        - \"app-*\"\n      denied:\n        - \"app-internal\"\n        - \"app-secrets\"\n</code></pre> <p>This configuration allows all <code>app-*</code> namespaces except <code>app-internal</code> and <code>app-secrets</code>.</p>"},{"location":"how-to/policies/filter-by-namespace/#complete-example-team-based-access","title":"Complete Example: Team-Based Access","text":"<pre><code>apiVersion: clusterpulse.io/v1alpha1\nkind: MonitorAccessPolicy\nmetadata:\n  name: team-alpha-access\n  namespace: clusterpulse\nspec:\n  identity:\n    priority: 100\n    subjects:\n      groups:\n        - team-alpha\n\n  access:\n    effect: Allow\n    enabled: true\n\n  scope:\n    clusters:\n      default: filtered\n      rules:\n        - selector:\n            environment: production\n          permissions:\n            view: true\n            viewMetrics: true\n          resources:\n            namespaces:\n              visibility: filtered\n              filters:\n                allowed:\n                  - \"alpha-*\"\n                  - \"shared-*\"\n                denied:\n                  - \"shared-admin\"\n            pods:\n              visibility: filtered\n              filters:\n                allowedNamespaces:\n                  - \"alpha-*\"\n                  - \"shared-*\"\n</code></pre>"},{"location":"how-to/policies/filter-by-namespace/#filtering-related-resources","title":"Filtering Related Resources","text":"<p>When filtering namespaces, you should also filter namespace-scoped resources to maintain consistency even though not explicitly necessary:</p> <pre><code>resources:\n  namespaces:\n    visibility: filtered\n    filters:\n      allowed:\n        - \"app-*\"\n\n  pods:\n    visibility: filtered\n    filters:\n      allowedNamespaces:\n        - \"app-*\"\n\n  operators:\n    visibility: filtered\n    filters:\n      allowedNamespaces:\n        - \"app-*\"\n</code></pre>"},{"location":"how-to/policies/filter-by-namespace/#filtering-operators-by-namespace","title":"Filtering Operators by Namespace","text":"<p>Operators can be filtered by the namespaces where they are available. Remember that cluster scoped (operators shown in every namespace) operators will always show:</p> <pre><code>resources:\n  operators:\n    visibility: filtered\n    filters:\n      allowedNamespaces:\n        - \"operator-*\"\n        - monitoring\n      deniedNames:\n        - \"*-test\"\n</code></pre>"},{"location":"how-to/policies/filter-by-namespace/#how-metrics-are-affected","title":"How Metrics Are Affected","text":"<p>When namespace filtering is active, cluster metrics are recalculated:</p> Metric Behavior <code>namespaces</code> Count of visible namespaces only <code>pods</code> Count of pods in visible namespaces <code>pods_running</code> Running pods in visible namespaces <code>deployments</code> Deployments in visible namespaces <code>services</code> Services in visible namespaces <p>The API response includes filtering metadata:</p> <pre><code>{\n  \"metrics\": {\n    \"namespaces\": 5,\n    \"pods\": 42,\n    \"filtered\": true,\n    \"filter_metadata\": {\n      \"allowed_namespaces\": 5,\n      \"total_namespaces\": 50\n    }\n  }\n}\n</code></pre>"},{"location":"how-to/policies/filter-by-namespace/#verification","title":"Verification","text":""},{"location":"how-to/policies/filter-by-namespace/#check-allowed-namespaces-via-api","title":"Check Allowed Namespaces via API","text":"<pre><code>curl -H \"Authorization: Bearer $TOKEN\" \\\n  https://clusterpulse.example.com/api/v1/clusters/my-cluster/namespaces\n</code></pre>"},{"location":"how-to/policies/filter-by-namespace/#check-filtered-metrics","title":"Check Filtered Metrics","text":"<pre><code>curl -H \"Authorization: Bearer $TOKEN\" \\\n  https://clusterpulse.example.com/api/v1/clusters/my-cluster/metrics?detailed=true\n</code></pre> <p>The response includes <code>filter_details</code> when filtering is applied.</p>"},{"location":"how-to/policies/filter-by-namespace/#common-patterns","title":"Common Patterns","text":""},{"location":"how-to/policies/filter-by-namespace/#exclude-system-namespaces","title":"Exclude System Namespaces","text":"<pre><code>filters:\n  allowed:\n    - \"*\"\n  denied:\n    - kube-system\n    - kube-public\n    - kube-node-lease\n    - openshift-*\n</code></pre>"},{"location":"how-to/policies/filter-by-namespace/#development-team-access","title":"Development Team Access","text":"<pre><code>filters:\n  allowed:\n    - \"dev-*\"\n    - \"staging-*\"\n  denied:\n    - \"*-secrets\"\n    - \"*-internal\"\n</code></pre>"},{"location":"how-to/policies/filter-by-namespace/#production-read-only-with-limited-namespaces","title":"Production Read-Only with Limited Namespaces","text":"<pre><code>filters:\n  allowed:\n    - \"prod-frontend\"\n    - \"prod-backend\"\n    - \"prod-api\"\n</code></pre>"},{"location":"how-to/policies/filter-by-namespace/#troubleshooting","title":"Troubleshooting","text":""},{"location":"how-to/policies/filter-by-namespace/#namespace-not-visible","title":"Namespace Not Visible","text":"<ol> <li>Verify the namespace name matches the allowed patterns exactly</li> <li>Check that the namespace is not in the denied list</li> <li>Confirm the policy is active and applies to the user</li> </ol>"},{"location":"how-to/policies/filter-by-namespace/#metrics-show-zero","title":"Metrics Show Zero","text":"<p>If metrics show zero but namespaces exist:</p> <ol> <li>Verify the pod filter matches the namespace filter</li> <li>Check that <code>visibility</code> is set to <code>filtered</code>, not <code>none</code></li> </ol>"},{"location":"how-to/policies/filter-by-namespace/#debug-policy-application","title":"Debug Policy Application","text":"<p>Use the auth endpoint to see effective permissions:</p> <pre><code>curl -H \"Authorization: Bearer $TOKEN\" \\\n  https://clusterpulse.example.com/api/v1/auth/permissions\n</code></pre>"},{"location":"how-to/policies/filter-by-namespace/#next-steps","title":"Next Steps","text":"<ul> <li>Create Read-Only Policy - Basic policy creation</li> <li>Policy Evaluation - Understand how policies are evaluated</li> </ul>"},{"location":"references/","title":"Index","text":"<p>This section is meant to contain references to the CRD/API Schemas. CRD docs auto-generated using <code>crdoc</code></p> <ul> <li>ClusterConnection CRD Schema</li> <li>RegistryConnection CRD Schema</li> <li>MonitorAccessPolicy CRD Schema</li> </ul>"},{"location":"references/crds/clusterconnection/","title":"API Reference","text":"<p>Packages:</p> <ul> <li>clusterpulse.io/v1alpha1</li> </ul>"},{"location":"references/crds/clusterconnection/#clusterpulseiov1alpha1","title":"clusterpulse.io/v1alpha1","text":"<p>Resource Types:</p> <ul> <li>ClusterConnection</li> </ul>"},{"location":"references/crds/clusterconnection/#clusterconnection","title":"ClusterConnection","text":"<p><sup><sup>\u21a9 Parent</sup></sup></p> Name Type Description Required apiVersion string clusterpulse.io/v1alpha1 true kind string ClusterConnection true metadata object Refer to the Kubernetes API documentation for the fields of the `metadata` field. true spec object false status object false"},{"location":"references/crds/clusterconnection/#clusterconnectionspec","title":"ClusterConnection.spec","text":"<p><sup><sup>\u21a9 Parent</sup></sup></p> Name Type Description Required credentialsRef object            Reference to secret containing credentials true endpoint string            Cluster API endpoint URL true displayName string            Human-friendly name for the cluster false labels map[string]string            Labels for cluster categorization false monitoring object            Monitoring configuration false"},{"location":"references/crds/clusterconnection/#clusterconnectionspeccredentialsref","title":"ClusterConnection.spec.credentialsRef","text":"<p><sup><sup>\u21a9 Parent</sup></sup></p> <p>Reference to secret containing credentials</p> Name Type Description Required name string            Name of the secret true namespace string            Namespace of the secret (defaults to same namespace) false"},{"location":"references/crds/clusterconnection/#clusterconnectionspecmonitoring","title":"ClusterConnection.spec.monitoring","text":"<p><sup><sup>\u21a9 Parent</sup></sup></p> <p>Monitoring configuration</p> Name Type Description Required interval integer            Reconciliation interval in seconds Default: 30 Minimum: 30 false timeout integer            Connection timeout in seconds Default: 10 Minimum: 5 false"},{"location":"references/crds/clusterconnection/#clusterconnectionstatus","title":"ClusterConnection.status","text":"<p><sup><sup>\u21a9 Parent</sup></sup></p> Name Type Description Required health enum Enum: healthy, degraded, unhealthy, unknown false lastSyncTime string Format: date-time false message string false namespaces integer false nodes integer false phase enum Enum: Connected, Disconnected, Error, Unknown false"},{"location":"references/crds/monitoraccesspolicy/","title":"API Reference","text":"<p>Packages:</p> <ul> <li>clusterpulse.io/v1alpha1</li> </ul>"},{"location":"references/crds/monitoraccesspolicy/#clusterpulseiov1alpha1","title":"clusterpulse.io/v1alpha1","text":"<p>Resource Types:</p> <ul> <li>MonitorAccessPolicy</li> </ul>"},{"location":"references/crds/monitoraccesspolicy/#monitoraccesspolicy","title":"MonitorAccessPolicy","text":"<p><sup><sup>\u21a9 Parent</sup></sup></p> Name Type Description Required apiVersion string clusterpulse.io/v1alpha1 true kind string MonitorAccessPolicy true metadata object Refer to the Kubernetes API documentation for the fields of the `metadata` field. true spec object true status object false"},{"location":"references/crds/monitoraccesspolicy/#monitoraccesspolicyspec","title":"MonitorAccessPolicy.spec","text":"<p><sup><sup>\u21a9 Parent</sup></sup></p> Name Type Description Required access object true identity object true scope object true lifecycle object false operations object false"},{"location":"references/crds/monitoraccesspolicy/#monitoraccesspolicyspecaccess","title":"MonitorAccessPolicy.spec.access","text":"<p><sup><sup>\u21a9 Parent</sup></sup></p> Name Type Description Required effect enum            Allow or Deny access Enum: Allow, Deny true enabled boolean            Whether this policy is active Default: true false"},{"location":"references/crds/monitoraccesspolicy/#monitoraccesspolicyspecidentity","title":"MonitorAccessPolicy.spec.identity","text":"<p><sup><sup>\u21a9 Parent</sup></sup></p> Name Type Description Required subjects object true priority integer            Higher priority policies are evaluated first Default: 100 Minimum: 1 Maximum: 10000 false"},{"location":"references/crds/monitoraccesspolicy/#monitoraccesspolicyspecidentitysubjects","title":"MonitorAccessPolicy.spec.identity.subjects","text":"<p><sup><sup>\u21a9 Parent</sup></sup></p> Name Type Description Required groups []string            List of group names false serviceAccounts []object false users []string            List of usernames or email addresses false"},{"location":"references/crds/monitoraccesspolicy/#monitoraccesspolicyspecidentitysubjectsserviceaccountsindex","title":"MonitorAccessPolicy.spec.identity.subjects.serviceAccounts[index]","text":"<p><sup><sup>\u21a9 Parent</sup></sup></p> Name Type Description Required name string            Service account name true namespace string            Service account namespace Default: default false"},{"location":"references/crds/monitoraccesspolicy/#monitoraccesspolicyspecscope","title":"MonitorAccessPolicy.spec.scope","text":"<p><sup><sup>\u21a9 Parent</sup></sup></p> Name Type Description Required clusters object true"},{"location":"references/crds/monitoraccesspolicy/#monitoraccesspolicyspecscopeclusters","title":"MonitorAccessPolicy.spec.scope.clusters","text":"<p><sup><sup>\u21a9 Parent</sup></sup></p> Name Type Description Required default enum            Default access for clusters not matching any rule Enum: allow, deny, none Default: none false rules []object false"},{"location":"references/crds/monitoraccesspolicy/#monitoraccesspolicyspecscopeclustersrulesindex","title":"MonitorAccessPolicy.spec.scope.clusters.rules[index]","text":"<p><sup><sup>\u21a9 Parent</sup></sup></p> Name Type Description Required selector object true permissions object false resources object false"},{"location":"references/crds/monitoraccesspolicy/#monitoraccesspolicyspecscopeclustersrulesindexselector","title":"MonitorAccessPolicy.spec.scope.clusters.rules[index].selector","text":"<p><sup><sup>\u21a9 Parent</sup></sup></p> Name Type Description Required matchLabels map[string]string            Label selector for clusters false matchNames []string            Exact cluster names or patterns with wildcards false matchPattern string            Regex pattern for cluster names false"},{"location":"references/crds/monitoraccesspolicy/#monitoraccesspolicyspecscopeclustersrulesindexpermissions","title":"MonitorAccessPolicy.spec.scope.clusters.rules[index].permissions","text":"<p><sup><sup>\u21a9 Parent</sup></sup></p> Name Type Description Required view boolean            Can view basic cluster information Default: true false viewAuditInfo boolean            Can view audit and policy information Default: false false viewCosts boolean            Can view cost metrics Default: false false viewMetadata boolean            Can view metadata about filtered resources (total counts, what's hidden) Default: false false viewMetrics boolean            Can view cluster-wide metrics (CPU, memory, pod counts) Default: false false viewSecrets boolean            Can view secret references Default: false false viewSensitive boolean            Can view sensitive information Default: false false"},{"location":"references/crds/monitoraccesspolicy/#monitoraccesspolicyspecscopeclustersrulesindexresources","title":"MonitorAccessPolicy.spec.scope.clusters.rules[index].resources","text":"<p><sup><sup>\u21a9 Parent</sup></sup></p> Name Type Description Required namespaces object false nodes object false operators object false pods object false"},{"location":"references/crds/monitoraccesspolicy/#monitoraccesspolicyspecscopeclustersrulesindexresourcesnamespaces","title":"MonitorAccessPolicy.spec.scope.clusters.rules[index].resources.namespaces","text":"<p><sup><sup>\u21a9 Parent</sup></sup></p> Name Type Description Required filters object false visibility enum            Namespace visibility level Enum: all, none, filtered Default: all false"},{"location":"references/crds/monitoraccesspolicy/#monitoraccesspolicyspecscopeclustersrulesindexresourcesnamespacesfilters","title":"MonitorAccessPolicy.spec.scope.clusters.rules[index].resources.namespaces.filters","text":"<p><sup><sup>\u21a9 Parent</sup></sup></p> Name Type Description Required allowed []string            Allowed namespace names or patterns false denied []string            Denied namespace names or patterns false"},{"location":"references/crds/monitoraccesspolicy/#monitoraccesspolicyspecscopeclustersrulesindexresourcesnodes","title":"MonitorAccessPolicy.spec.scope.clusters.rules[index].resources.nodes","text":"<p><sup><sup>\u21a9 Parent</sup></sup></p> Name Type Description Required filters object false visibility enum            Node visibility level Enum: all, none, filtered Default: all false"},{"location":"references/crds/monitoraccesspolicy/#monitoraccesspolicyspecscopeclustersrulesindexresourcesnodesfilters","title":"MonitorAccessPolicy.spec.scope.clusters.rules[index].resources.nodes.filters","text":"<p><sup><sup>\u21a9 Parent</sup></sup></p> Name Type Description Required hideByLabels map[string]string            Hide nodes with specific labels false hideMasters boolean            Hide master/control plane nodes Default: false false labelSelector map[string]string            Label selector for nodes false"},{"location":"references/crds/monitoraccesspolicy/#monitoraccesspolicyspecscopeclustersrulesindexresourcesoperators","title":"MonitorAccessPolicy.spec.scope.clusters.rules[index].resources.operators","text":"<p><sup><sup>\u21a9 Parent</sup></sup></p> Name Type Description Required filters object false visibility enum            Operator visibility level Enum: all, none, filtered Default: all false"},{"location":"references/crds/monitoraccesspolicy/#monitoraccesspolicyspecscopeclustersrulesindexresourcesoperatorsfilters","title":"MonitorAccessPolicy.spec.scope.clusters.rules[index].resources.operators.filters","text":"<p><sup><sup>\u21a9 Parent</sup></sup></p> Name Type Description Required allowedNames []string            Specific operator names to show false allowedNamespaces []string            Namespaces where operators are visible false deniedNames []string            Specific operator names to hide false deniedNamespaces []string            Namespaces where operators are hidden false"},{"location":"references/crds/monitoraccesspolicy/#monitoraccesspolicyspecscopeclustersrulesindexresourcespods","title":"MonitorAccessPolicy.spec.scope.clusters.rules[index].resources.pods","text":"<p><sup><sup>\u21a9 Parent</sup></sup></p> Name Type Description Required filters object false visibility enum            Pod visibility level Enum: all, none, filtered Default: all false"},{"location":"references/crds/monitoraccesspolicy/#monitoraccesspolicyspecscopeclustersrulesindexresourcespodsfilters","title":"MonitorAccessPolicy.spec.scope.clusters.rules[index].resources.pods.filters","text":"<p><sup><sup>\u21a9 Parent</sup></sup></p> Name Type Description Required allowedNamespaces []string            Namespaces where pods are visible false"},{"location":"references/crds/monitoraccesspolicy/#monitoraccesspolicyspeclifecycle","title":"MonitorAccessPolicy.spec.lifecycle","text":"<p><sup><sup>\u21a9 Parent</sup></sup></p> Name Type Description Required validity object false"},{"location":"references/crds/monitoraccesspolicy/#monitoraccesspolicyspeclifecyclevalidity","title":"MonitorAccessPolicy.spec.lifecycle.validity","text":"<p><sup><sup>\u21a9 Parent</sup></sup></p> Name Type Description Required notAfter string            Policy expires after this time Format: date-time false notBefore string            Policy is not valid before this time Format: date-time false"},{"location":"references/crds/monitoraccesspolicy/#monitoraccesspolicyspecoperations","title":"MonitorAccessPolicy.spec.operations","text":"<p><sup><sup>\u21a9 Parent</sup></sup></p> Name Type Description Required audit object false"},{"location":"references/crds/monitoraccesspolicy/#monitoraccesspolicyspecoperationsaudit","title":"MonitorAccessPolicy.spec.operations.audit","text":"<p><sup><sup>\u21a9 Parent</sup></sup></p> Name Type Description Required logAccess boolean            Log all access attempts using this policy Default: false false requireReason boolean            Require reason for access Default: false false"},{"location":"references/crds/monitoraccesspolicy/#monitoraccesspolicystatus","title":"MonitorAccessPolicy.status","text":"<p><sup><sup>\u21a9 Parent</sup></sup></p> Name Type Description Required affectedGroups integer false affectedServiceAccounts integer false affectedUsers integer false compiledAt string Format: date-time false conditions []object false evaluationCount integer Default: 0 false hash string false lastEvaluated string Format: date-time false message string false state enum Enum: Active, Inactive, Error, Pending, Expired Default: Pending false"},{"location":"references/crds/monitoraccesspolicy/#monitoraccesspolicystatusconditionsindex","title":"MonitorAccessPolicy.status.conditions[index]","text":"<p><sup><sup>\u21a9 Parent</sup></sup></p> Name Type Description Required lastTransitionTime string Format: date-time false message string false reason string false status string false type string false"},{"location":"references/crds/registryconnection/","title":"API Reference","text":"<p>Packages:</p> <ul> <li>clusterpulse.io/v1alpha1</li> </ul>"},{"location":"references/crds/registryconnection/#clusterpulseiov1alpha1","title":"clusterpulse.io/v1alpha1","text":"<p>Resource Types:</p> <ul> <li>RegistryConnection</li> </ul>"},{"location":"references/crds/registryconnection/#registryconnection","title":"RegistryConnection","text":"<p><sup><sup>\u21a9 Parent</sup></sup></p> Name Type Description Required apiVersion string clusterpulse.io/v1alpha1 true kind string RegistryConnection true metadata object Refer to the Kubernetes API documentation for the fields of the `metadata` field. true spec object false status object false"},{"location":"references/crds/registryconnection/#registryconnectionspec","title":"RegistryConnection.spec","text":"<p><sup><sup>\u21a9 Parent</sup></sup></p> Name Type Description Required endpoint string            Registry endpoint URL true credentialsRef object            Reference to secret containing credentials false displayName string            Human-friendly name for the registry false healthCheckPaths []string            Additional paths to check for health Default: [/v2/] false insecure boolean            Allow insecure HTTP connections Default: false false labels map[string]string            Labels for registry categorization false monitoring object false skipTLSVerify boolean            Skip TLS certificate verification Default: false false type string            Optional type identifier for the registry (informational only) false"},{"location":"references/crds/registryconnection/#registryconnectionspeccredentialsref","title":"RegistryConnection.spec.credentialsRef","text":"<p><sup><sup>\u21a9 Parent</sup></sup></p> <p>Reference to secret containing credentials</p> Name Type Description Required name string            Name of the secret true namespace string            Namespace of the secret false"},{"location":"references/crds/registryconnection/#registryconnectionspecmonitoring","title":"RegistryConnection.spec.monitoring","text":"<p><sup><sup>\u21a9 Parent</sup></sup></p> Name Type Description Required checkCatalog boolean            Enable catalog endpoint checking Default: false false interval integer            Check interval in seconds Default: 60 Minimum: 30 false maxCatalogEntries integer            Maximum catalog entries to fetch Default: 100 Minimum: 1 Maximum: 1000 false timeout integer            Request timeout in seconds Default: 10 Minimum: 5 false"},{"location":"references/crds/registryconnection/#registryconnectionstatus","title":"RegistryConnection.status","text":"<p><sup><sup>\u21a9 Parent</sup></sup></p> Name Type Description Required available boolean            Whether registry is reachable false features map[string]boolean            Detected registry features false health string            Health status (healthy, degraded, unhealthy, unknown) false lastCheckTime string            Last health check timestamp Format: date-time false message string            Status message false phase string            Current phase (Connecting, Connected, Error, Unknown) false repositoryCount integer            Number of repositories (if catalog enabled) false responseTime integer            Response time in milliseconds false version string            Registry version false"},{"location":"tests/api/","title":"ClusterPulse API Test Guide","text":""},{"location":"tests/api/#overview","title":"Overview","text":"<p>This test suite covers the ClusterPulse API with a focus on the RBAC engine (our most security-critical component) and API endpoints. Tests use <code>pytest</code> with <code>fakeredis</code> for isolated, fast execution.</p>"},{"location":"tests/api/#quick-start","title":"Quick Start","text":"<pre><code># Run all tests\npytest\n\n# Run with coverage\npytest --cov=clusterpulse --cov-report=html\n\n# Run specific test categories\npytest -m unit           # Unit tests only\npytest -m integration    # Integration tests only\npytest -m rbac          # RBAC-specific tests\n\n# Run a specific test file\npytest tests/unit/core/test_rbac_engine.py\n\n# Run with verbose output\npytest -v\n\n# Run tests matching a pattern\npytest -k \"test_filter\"\n</code></pre>"},{"location":"tests/api/#test-structure","title":"Test Structure","text":"<pre><code>tests/\n\u251c\u2500\u2500 conftest.py                          # Shared fixtures and configuration\n\u251c\u2500\u2500 unit/                                # Fast, isolated unit tests\n\u2502   \u251c\u2500\u2500 core/\n\u2502   \u2502   \u2514\u2500\u2500 test_rbac_engine.py         # RBAC engine (security critical!)\n\u2502   \u2514\u2500\u2500 repositories/\n\u2502       \u2514\u2500\u2500 test_cluster_repository.py  # Redis data access layer\n\u2514\u2500\u2500 integration/                         # Tests with multiple components\n    \u2514\u2500\u2500 api/\n        \u251c\u2500\u2500 test_auth_routes.py         # Authentication/authorization flows\n        \u2514\u2500\u2500 test_cluster_routes.py      # Cluster API endpoints\n</code></pre>"},{"location":"tests/api/#key-testing-patterns","title":"Key Testing Patterns","text":""},{"location":"tests/api/#1-fixture-based-test-data","title":"1. Fixture-Based Test Data","text":"<p>We use fixtures in <code>conftest.py</code> to create consistent test data:</p> <pre><code>def test_example(authenticated_client, basic_dev_policy, sample_cluster_metrics):\n    # Fixtures provide pre-configured test data\n    # No manual setup needed\n    pass\n</code></pre> <p>Available Fixtures:</p> <ul> <li>Users: <code>dev_user</code>, <code>admin_user</code>, <code>readonly_user</code>, <code>no_access_user</code></li> <li>Policies: <code>basic_dev_policy</code>, <code>admin_policy</code>, <code>readonly_policy</code>, <code>namespace_filtered_policy</code></li> <li>Data: <code>sample_cluster_spec</code>, <code>sample_cluster_metrics</code>, <code>sample_nodes</code>, <code>sample_operators</code></li> <li>Clients: <code>test_client</code>, <code>authenticated_client</code>, <code>admin_client</code></li> <li>Infrastructure: <code>fake_redis</code>, <code>rbac_engine</code></li> </ul>"},{"location":"tests/api/#2-fakeredis-for-isolation","title":"2. FakeRedis for Isolation","text":"<p>All tests use <code>fakeredis</code> instead of a real Redis instance:</p> <pre><code>def test_something(fake_redis):\n    # fake_redis behaves like real Redis but is in-memory\n    fake_redis.set(\"key\", \"value\")\n    assert fake_redis.get(\"key\") == \"value\"\n</code></pre> <p>Benefits:</p> <ul> <li>No external dependencies</li> <li>Fast execution (in-memory)</li> <li>Isolated - tests don't interfere with each other</li> <li>Deterministic - no timing issues</li> </ul>"},{"location":"tests/api/#3-policy-based-authorization-testing","title":"3. Policy-Based Authorization Testing","text":"<p>The RBAC engine is complex, so we test it thoroughly:</p> <pre><code>def test_authorize_with_policy(rbac_engine, fake_redis, basic_dev_policy):\n    # 1. Store policy in fake Redis\n    populate_redis_with_policies([basic_dev_policy])\n\n    # 2. Create authorization request\n    principal = Principal(username=\"john.doe\", groups=[\"developers\"])\n    resource = Resource(type=ResourceType.CLUSTER, name=\"dev-cluster-1\")\n    request = Request(principal=principal, action=Action.VIEW, resource=resource)\n\n    # 3. Test authorization\n    decision = rbac_engine.authorize(request)\n\n    assert decision.allowed\n    assert Action.VIEW in decision.permissions\n</code></pre>"},{"location":"tests/api/#4-mocking-external-dependencies","title":"4. Mocking External Dependencies","text":"<p>We mock Kubernetes API calls and group resolution:</p> <pre><code>def test_with_mock_groups(authenticated_client):\n    def mock_resolve_groups(username, email=None):\n        return [\"developers\", \"platform-team\"]\n\n    import clusterpulse.api.dependencies.auth as auth_module\n    auth_module.resolve_groups_realtime = mock_resolve_groups\n\n    # Now requests will use mocked group data\n    response = authenticated_client.get(\"/api/v1/auth/me\")\n</code></pre>"},{"location":"tests/api/#critical-test-areas","title":"Critical Test Areas","text":""},{"location":"tests/api/#rbac-engine-test_rbac_enginepy","title":"RBAC Engine (<code>test_rbac_engine.py</code>)","text":"<p>Why it matters: This is our security boundary. A bug here could expose unauthorized data.</p> <p>What we test:</p> <ul> <li>Policy matching and evaluation</li> <li>Permission calculation</li> <li>Resource filtering (namespaces, nodes, operators)</li> <li>Deny overrides Allow (security critical)</li> <li>Time-bound policies</li> <li>Disabled policies are ignored</li> <li>Cache behavior</li> <li>Anonymous access</li> </ul> <p>Example test: <pre><code>def test_authorize_with_deny_policy(rbac_engine, fake_redis):\n    \"\"\"Ensure Deny policies override Allow policies.\"\"\"\n    # Setup Allow + Deny policies (Deny has higher priority)\n    # ...\n    decision = rbac_engine.authorize(request)\n    assert decision.denied  # Deny must win!\n</code></pre></p>"},{"location":"tests/api/#cluster-repository-test_cluster_repositorypy","title":"Cluster Repository (<code>test_cluster_repository.py</code>)","text":"<p>Why it matters: All cluster data flows through this layer.</p> <p>What we test:</p> <ul> <li>CRUD operations on cluster data</li> <li>Node management</li> <li>Metrics retrieval</li> <li>Alert and event handling</li> <li>Error handling (Redis failures)</li> <li>Health checks</li> </ul>"},{"location":"tests/api/#auth-routes-test_auth_routespy","title":"Auth Routes (<code>test_auth_routes.py</code>)","text":"<p>Why it matters: Authentication is the entry point for all API access.</p> <p>What we test:</p> <ul> <li>Authentication status</li> <li>User information with groups</li> <li>Permission calculation</li> <li>Policy retrieval</li> <li>Cache clearing</li> <li>Logout flow</li> <li>Group resolution (real-time from K8s)</li> </ul>"},{"location":"tests/api/#cluster-routes-test_cluster_routespy","title":"Cluster Routes (<code>test_cluster_routes.py</code>)","text":"<p>Why it matters: Main API surface - this is what users interact with.</p> <p>What we test:</p> <ul> <li>Listing clusters with RBAC filtering</li> <li>Getting cluster details</li> <li>Node listing and filtering</li> <li>Namespace access control</li> <li>Operator visibility</li> <li>Metrics with permission checks</li> <li>Query parameter filtering</li> </ul>"},{"location":"tests/api/#writing-new-tests","title":"Writing New Tests","text":""},{"location":"tests/api/#unit-test-template","title":"Unit Test Template","text":"<pre><code>@pytest.mark.unit\nclass TestNewFeature:\n    \"\"\"Test description.\"\"\"\n\n    def test_basic_functionality(self, fake_redis):\n        \"\"\"Test the happy path.\"\"\"\n        # Arrange\n        # ... setup test data\n\n        # Act\n        result = function_under_test()\n\n        # Assert\n        assert result == expected\n\n    def test_error_handling(self, fake_redis):\n        \"\"\"Test error conditions.\"\"\"\n        # Test what happens when things go wrong\n        pass\n</code></pre>"},{"location":"tests/api/#integration-test-template","title":"Integration Test Template","text":"<pre><code>@pytest.mark.integration\nclass TestNewEndpoint:\n    \"\"\"Test API endpoint with full stack.\"\"\"\n\n    def test_endpoint_success(\n        self,\n        authenticated_client,\n        fake_redis,\n        populate_redis_with_policies,\n        basic_dev_policy\n    ):\n        \"\"\"Test successful request.\"\"\"\n        # Setup policies and data\n        populate_redis_with_policies([basic_dev_policy])\n\n        # Mock group resolution\n        def mock_resolve_groups(username, email=None):\n            return [\"developers\"]\n\n        import clusterpulse.api.dependencies.auth as auth_module\n        auth_module.resolve_groups_realtime = mock_resolve_groups\n\n        # Make request\n        response = authenticated_client.get(\"/api/v1/your/endpoint\")\n\n        # Assert\n        assert response.status_code == 200\n        data = response.json()\n        assert \"expected_field\" in data\n\n    def test_endpoint_no_permission(self, test_client, fake_redis):\n        \"\"\"Test authorization failure.\"\"\"\n        response = test_client.get(\"/api/v1/your/endpoint\")\n        assert response.status_code == 403\n</code></pre>"},{"location":"tests/api/#test-data-management","title":"Test Data Management","text":""},{"location":"tests/api/#populating-redis","title":"Populating Redis","text":"<p>Use helper fixtures to populate Redis with test data:</p> <pre><code>def test_with_cluster_data(\n    fake_redis,\n    populate_redis_with_cluster,\n    sample_cluster_spec,\n    sample_cluster_metrics\n):\n    # Populate Redis with a complete cluster\n    populate_redis_with_cluster(\n        \"test-cluster\",\n        sample_cluster_spec,\n        sample_cluster_status,\n        sample_cluster_metrics,\n        nodes=sample_nodes,\n        namespaces=sample_namespaces\n    )\n\n    # Now Redis has complete cluster data\n    assert fake_redis.exists(\"cluster:test-cluster:spec\")\n</code></pre>"},{"location":"tests/api/#populating-policies","title":"Populating Policies","text":"<pre><code>def test_with_policies(fake_redis, populate_redis_with_policies, basic_dev_policy):\n    populate_redis_with_policies([basic_dev_policy])\n\n    # Policy is now indexed and ready\n    # You can make authorization decisions\n</code></pre>"},{"location":"tests/api/#common-testing-scenarios","title":"Common Testing Scenarios","text":""},{"location":"tests/api/#testing-namespace-filtering","title":"Testing Namespace Filtering","text":"<pre><code>def test_namespace_filtering(authenticated_client, fake_redis, namespace_filtered_policy):\n    \"\"\"User should only see pods in their allowed namespaces.\"\"\"\n    # 1. Setup policy with namespace restrictions\n    populate_redis_with_policies([namespace_filtered_policy])\n\n    # 2. Create pods in various namespaces\n    pods = [\n        {\"name\": \"pod-1\", \"namespace\": \"team-a-prod\"},   # Allowed\n        {\"name\": \"pod-2\", \"namespace\": \"team-b-prod\"},   # Not allowed\n    ]\n\n    # 3. Make request\n    response = authenticated_client.get(\"/api/v1/clusters/test/pods\")\n\n    # 4. Verify filtering\n    data = response.json()\n    assert len(data) == 1\n    assert data[0][\"namespace\"] == \"team-a-prod\"\n</code></pre>"},{"location":"tests/api/#testing-node-filtering","title":"Testing Node Filtering","text":"<pre><code>def test_node_filtering(authenticated_client, fake_redis):\n    \"\"\"User should only see allowed nodes.\"\"\"\n    # Setup policy that restricts node visibility\n    node_filter_policy = {\n        \"policy_name\": \"node-filter\",\n        # ... policy with node_filter\n    }\n    populate_redis_with_policies([node_filter_policy])\n\n    response = authenticated_client.get(\"/api/v1/clusters/test/nodes\")\n    data = response.json()\n\n    # Should only see filtered nodes\n    assert all(node[\"name\"] in [\"worker-1\", \"worker-2\"] for node in data)\n</code></pre>"},{"location":"tests/api/#testing-permission-levels","title":"Testing Permission Levels","text":"<pre><code>def test_view_metrics_permission(authenticated_client, fake_redis):\n    \"\"\"User with viewMetrics permission can see metrics.\"\"\"\n    policy_with_metrics = {\n        # ... policy with viewMetrics: true\n    }\n\n    response = authenticated_client.get(\"/api/v1/clusters/test/metrics\")\n    assert response.status_code == 200\n    assert \"cpu_usage_percent\" in response.json()\n\ndef test_no_metrics_permission(authenticated_client, fake_redis):\n    \"\"\"User without viewMetrics permission cannot see metrics.\"\"\"\n    policy_without_metrics = {\n        # ... policy with viewMetrics: false\n    }\n\n    response = authenticated_client.get(\"/api/v1/clusters/test/metrics\")\n    assert response.status_code == 403\n</code></pre>"},{"location":"tests/api/#debugging-tests","title":"Debugging Tests","text":""},{"location":"tests/api/#running-a-single-test","title":"Running a Single Test","text":"<pre><code># Run one specific test\npytest tests/unit/core/test_rbac_engine.py::TestRBACEngine::test_authorize_no_policies -v\n\n# Run with print statements visible\npytest tests/unit/core/test_rbac_engine.py::TestRBACEngine::test_authorize_no_policies -v -s\n</code></pre>"},{"location":"tests/api/#inspecting-failures","title":"Inspecting Failures","text":"<pre><code># Show local variables on failure\npytest --showlocals\n\n# Enter debugger on failure\npytest --pdb\n\n# Show full diff on assertion failures\npytest -vv\n</code></pre>"},{"location":"tests/api/#common-issues","title":"Common Issues","text":"<p>Issue: \"No module named 'clusterpulse'\" <pre><code># Solution: Install in development mode\npip install -e .\n</code></pre></p> <p>Issue: Redis client not mocked properly <pre><code># Make sure to use the fake_redis fixture\ndef test_something(fake_redis):  # \u2190 Include this fixture\n    # Test code here\n</code></pre></p> <p>Issue: Group resolution failing <pre><code># Always mock group resolution in integration tests\ndef mock_resolve_groups(username, email=None):\n    return [\"developers\"]\n\nimport clusterpulse.api.dependencies.auth as auth_module\nauth_module.resolve_groups_realtime = mock_resolve_groups\n</code></pre></p>"},{"location":"tests/api/#test-markers","title":"Test Markers","text":"<p>We use pytest markers to categorize tests:</p> <pre><code>@pytest.mark.unit           # Fast, isolated unit tests\n@pytest.mark.integration    # Integration tests with multiple components\n@pytest.mark.rbac          # RBAC-specific tests\n@pytest.mark.redis         # Tests that depend on Redis behavior\n@pytest.mark.slow          # Long-running tests\n</code></pre> <p>Run tests by marker: <pre><code>pytest -m \"unit and not slow\"\npytest -m \"integration or rbac\"\n</code></pre></p>"},{"location":"tests/api/#coverage-goals","title":"Coverage Goals","text":"<p>Current coverage focuses on:</p> <ul> <li>\u2705 RBAC engine (security critical)</li> <li>\u2705 Repository layer (data access)</li> <li>\u2705 Main API endpoints</li> <li>\u2705 Authentication flows</li> <li>\u2705 Middleware configs</li> </ul> <p>Next priorities:</p> <ul> <li>\u26a0\ufe0f Health endpoints</li> <li>\u26a0\ufe0f Public API routes</li> <li>\u26a0\ufe0f Metrics calculator</li> <li>\u26a0\ufe0f Registry routes</li> <li>\u26a0\ufe0f Error scenarios</li> </ul>"},{"location":"tests/api/#best-practices","title":"Best Practices","text":"<ol> <li>Use descriptive test names: <code>test_authorize_with_deny_policy</code> not <code>test_1</code></li> <li>One assertion per test (usually): Makes failures easier to debug</li> <li>Use fixtures over setup/teardown: More flexible and readable</li> <li>Test error paths: Don't just test happy paths</li> <li>Keep tests independent: Tests should not depend on each other</li> <li>Mock external dependencies: Don't make real API calls or connect to real Redis</li> <li>Use meaningful test data: <code>\"dev-cluster-1\"</code> is better than <code>\"cluster1\"</code></li> </ol>"},{"location":"tests/api/#contributing-tests","title":"Contributing Tests","text":"<p>When adding new features:</p> <ol> <li>Write tests first (TDD when possible)</li> <li>Add fixtures for reusable test data</li> <li>Use appropriate markers (<code>@pytest.mark.unit</code>, etc.)</li> <li>Document complex test scenarios with comments</li> <li>Run the full suite before submitting PR</li> </ol>"},{"location":"tests/api/#resources","title":"Resources","text":"<ul> <li>pytest documentation</li> <li>fakeredis documentation</li> <li>FastAPI testing guide</li> </ul>"},{"location":"tutorials/","title":"Tutorials","text":"<p>This section contains step-by-step tutorials for learning ClusterPulse concepts and workflows.</p>"},{"location":"tutorials/#available-tutorials","title":"Available Tutorials","text":"Tutorial Description Duration RBAC Basics Learn the fundamentals of ClusterPulse role-based access control 20 min"},{"location":"tutorials/#prerequisites","title":"Prerequisites","text":"<p>Before starting these tutorials, ensure you have:</p> <ul> <li>A running ClusterPulse installation</li> <li><code>oc</code> access to the cluster where ClusterPulse is deployed</li> <li>At least one monitored cluster configured</li> <li>Administrative access to create <code>MonitorAccessPolicy</code> resources</li> </ul>"},{"location":"tutorials/#learning-path","title":"Learning Path","text":"<pre><code>flowchart LR\n    A[RBAC Basics] --&gt; B[Create Read-Only Policy]\n    B --&gt; C[Filter by Namespace]\n    C --&gt; D[Advanced Policy Patterns]</code></pre>"},{"location":"tutorials/#recommended-order","title":"Recommended Order","text":"<ol> <li>RBAC Basics - Understand the core concepts before creating policies</li> <li>Create Read-Only Policy - Apply your knowledge with a simple policy</li> <li>Filter by Namespace - Learn fine-grained access control</li> </ol>"},{"location":"tutorials/#tutorial-format","title":"Tutorial Format","text":"<p>Each tutorial follows a consistent structure:</p> <ul> <li>Objectives - What you will learn</li> <li>Prerequisites - What you need before starting</li> <li>Steps - Numbered instructions with code examples</li> <li>Verification - How to confirm each step succeeded</li> <li>Summary - Key takeaways</li> </ul>"},{"location":"tutorials/#getting-help","title":"Getting Help","text":"<p>If you encounter issues while following these tutorials:</p> <ol> <li>Check the troubleshooting section at the end of each tutorial</li> <li>Review the policy controller logs: <code>oc logs -n clusterpulse deployment/policy-controller</code></li> <li>Verify your policy syntax against the RBAC Model reference</li> </ol>"},{"location":"tutorials/rbac-basics/","title":"RBAC Basics Tutorial","text":"<p>This tutorial introduces the fundamentals of ClusterPulse role-based access control (RBAC). You will learn how policies work, create your first policy, and verify it takes effect.</p>"},{"location":"tutorials/rbac-basics/#objectives","title":"Objectives","text":"<p>By the end of this tutorial, you will:</p> <ul> <li>Understand the ClusterPulse RBAC model</li> <li>Create a basic <code>MonitorAccessPolicy</code></li> <li>Verify policy application through the API</li> <li>Debug common policy issues</li> </ul>"},{"location":"tutorials/rbac-basics/#prerequisites","title":"Prerequisites","text":"<ul> <li>ClusterPulse deployed and accessible</li> <li><code>oc</code> configured with cluster access</li> <li>At least one cluster being monitored by ClusterPulse</li> <li>A test user or group to apply policies to</li> </ul>"},{"location":"tutorials/rbac-basics/#step-1-understand-the-policy-structure","title":"Step 1: Understand the Policy Structure","text":"<p>A <code>MonitorAccessPolicy</code> consists of five sections:</p> <pre><code>flowchart TB\n    subgraph Policy\n        A[identity] --&gt; B[Who does this apply to?]\n        C[access] --&gt; D[Allow or Deny?]\n        E[scope] --&gt; F[Which clusters and resources?]\n        G[lifecycle] --&gt; H[When is this valid?]\n        I[operations] --&gt; J[Audit settings]\n    end</code></pre> Section Purpose <code>identity</code> Defines subjects (users, groups, service accounts) and priority <code>access</code> Sets the effect (Allow/Deny) and enabled state <code>scope</code> Specifies cluster rules, permissions, and resource filters <code>lifecycle</code> Optional validity period (notBefore, notAfter) <code>operations</code> Optional audit configuration"},{"location":"tutorials/rbac-basics/#step-2-view-current-policies","title":"Step 2: View Current Policies","text":"<p>Check existing policies in your cluster:</p> <pre><code>oc get monitoraccesspolicies -n clusterpulse\n</code></pre> <p>Expected output:</p> <pre><code>NAME                  STATE    AGE\ndefault-admin         Active   5d\nexample-readonly      Active   2d\n</code></pre> <p>View details of a policy:</p> <pre><code>oc get monitoraccesspolicy default-admin -n clusterpulse -o yaml\n</code></pre>"},{"location":"tutorials/rbac-basics/#step-3-create-your-first-policy","title":"Step 3: Create Your First Policy","text":"<p>Create a file named <code>tutorial-policy.yaml</code>:</p> <pre><code>apiVersion: clusterpulse.io/v1alpha1\nkind: MonitorAccessPolicy\nmetadata:\n  name: tutorial-viewers\n  namespace: clusterpulse\nspec:\n  identity:\n    priority: 200\n    subjects:\n      groups:\n        - tutorial-group\n\n  access:\n    effect: Allow\n    enabled: true\n\n  scope:\n    clusters:\n      default: all\n      rules:\n        - selector: {}\n          permissions:\n            view: true\n            viewMetrics: true\n</code></pre> <p>Apply the policy:</p> <pre><code>oc apply -f tutorial-policy.yaml\n</code></pre>"},{"location":"tutorials/rbac-basics/#step-4-verify-policy-compilation","title":"Step 4: Verify Policy Compilation","text":"<p>The policy controller compiles policies into optimized structures stored in Redis. Check the status:</p> <pre><code>oc get monitoraccesspolicy tutorial-viewers -n clusterpulse -o jsonpath='{.status}'\n</code></pre> <p>Expected output:</p> <pre><code>{\n  \"state\": \"Active\",\n  \"message\": \"Policy is active\",\n  \"compiledAt\": \"2024-01-15T10:30:00Z\",\n  \"affectedGroups\": 1,\n  \"hash\": \"a1b2c3d4e5f6\"\n}\n</code></pre> <p>If the state is <code>Error</code>, check the policy controller logs:</p> <pre><code>oc logs -n clusterpulse deployment/policy-controller | grep tutorial-viewers\n</code></pre>"},{"location":"tutorials/rbac-basics/#step-5-test-policy-via-api","title":"Step 5: Test Policy via API","text":""},{"location":"tutorials/rbac-basics/#check-authentication-status","title":"Check Authentication Status","text":"<pre><code>curl -s https://clusterpulse.example.com/api/v1/auth/status | jq\n</code></pre>"},{"location":"tutorials/rbac-basics/#view-applied-policies","title":"View Applied Policies","text":"<pre><code>curl -s https://clusterpulse.example.com/api/v1/auth/policies | jq\n</code></pre> <p>This returns all policies that apply to the current user:</p> <pre><code>{\n  \"user\": {\n    \"username\": \"testuser\",\n    \"groups\": [\"tutorial-group\"]\n  },\n  \"total_policies\": 1,\n  \"policies\": [\n    {\n      \"source\": \"group:tutorial-group\",\n      \"policy\": {\n        \"policy_name\": \"tutorial-viewers\",\n        \"effect\": \"Allow\",\n        \"enabled\": true\n      },\n      \"priority\": 200\n    }\n  ]\n}\n</code></pre>"},{"location":"tutorials/rbac-basics/#view-effective-permissions","title":"View Effective Permissions","text":"<pre><code>curl -s https://clusterpulse.example.com/api/v1/auth/permissions | jq\n</code></pre>"},{"location":"tutorials/rbac-basics/#step-6-modify-the-policy","title":"Step 6: Modify the Policy","text":"<p>Update the policy to restrict access to specific clusters. Edit <code>tutorial-policy.yaml</code>:</p> <pre><code>apiVersion: clusterpulse.io/v1alpha1\nkind: MonitorAccessPolicy\nmetadata:\n  name: tutorial-viewers\n  namespace: clusterpulse\nspec:\n  identity:\n    priority: 200\n    subjects:\n      groups:\n        - tutorial-group\n\n  access:\n    effect: Allow\n    enabled: true\n\n  scope:\n    clusters:\n      default: none  # Changed from 'all'\n      rules:\n        - selector:\n            environment: development\n          permissions:\n            view: true\n            viewMetrics: true\n</code></pre> <p>Apply the updated policy:</p> <pre><code>oc apply -f tutorial-policy.yaml\n</code></pre> <p>The change takes effect immediately. Users in <code>tutorial-group</code> now only see clusters with the label <code>environment: development</code>.</p>"},{"location":"tutorials/rbac-basics/#step-7-add-resource-filtering","title":"Step 7: Add Resource Filtering","text":"<p>Further restrict the policy to specific namespaces:</p> <pre><code>apiVersion: clusterpulse.io/v1alpha1\nkind: MonitorAccessPolicy\nmetadata:\n  name: tutorial-viewers\n  namespace: clusterpulse\nspec:\n  identity:\n    priority: 200\n    subjects:\n      groups:\n        - tutorial-group\n\n  access:\n    effect: Allow\n    enabled: true\n\n  scope:\n    clusters:\n      default: none\n      rules:\n        - selector:\n            environment: development\n          permissions:\n            view: true\n            viewMetrics: true\n          resources:\n            namespaces:\n              visibility: filtered\n              filters:\n                allowed:\n                  - \"tutorial-*\"\n                  - default\n</code></pre> <p>Apply and verify:</p> <pre><code>oc apply -f tutorial-policy.yaml\n\n# Check the namespace list for a development cluster\ncurl -s https://clusterpulse.example.com/api/v1/clusters/dev-cluster/namespaces | jq\n</code></pre> <p>Only namespaces matching <code>tutorial-*</code> or <code>default</code> should be returned.</p>"},{"location":"tutorials/rbac-basics/#step-8-clean-up","title":"Step 8: Clean Up","text":"<p>Remove the tutorial policy:</p> <pre><code>oc delete monitoraccesspolicy tutorial-viewers -n clusterpulse\n</code></pre>"},{"location":"tutorials/rbac-basics/#key-concepts-summary","title":"Key Concepts Summary","text":""},{"location":"tutorials/rbac-basics/#policy-priority","title":"Policy Priority","text":"<ul> <li>Lower numbers = higher priority</li> <li>Range: 0-999</li> <li>First matching Allow or Deny wins</li> </ul>"},{"location":"tutorials/rbac-basics/#effect-types","title":"Effect Types","text":"Effect Behavior <code>Allow</code> Permits access if policy matches <code>Deny</code> Blocks access if policy matches"},{"location":"tutorials/rbac-basics/#visibility-levels","title":"Visibility Levels","text":"Level Description <code>all</code> No restrictions <code>none</code> Complete restriction <code>filtered</code> Apply filter rules"},{"location":"tutorials/rbac-basics/#subject-types","title":"Subject Types","text":"Type Example Users <code>alice@example.com</code> Groups <code>platform-team</code> Service Accounts <code>name: monitoring-sa, namespace: monitoring</code>"},{"location":"tutorials/rbac-basics/#troubleshooting","title":"Troubleshooting","text":""},{"location":"tutorials/rbac-basics/#policy-not-taking-effect","title":"Policy Not Taking Effect","text":"<ol> <li>Verify the policy state is <code>Active</code></li> <li>Confirm the user's groups match the policy subjects</li> <li>Check for higher-priority policies that might override</li> </ol>"},{"location":"tutorials/rbac-basics/#access-unexpectedly-denied","title":"Access Unexpectedly Denied","text":"<ol> <li>Look for <code>Deny</code> policies with higher priority</li> <li>Verify the cluster labels match the selector</li> <li>Check if resource filters are too restrictive</li> </ol>"},{"location":"tutorials/rbac-basics/#policy-stuck-in-error-state","title":"Policy Stuck in Error State","text":"<ol> <li>Review the policy controller logs</li> <li>Validate YAML syntax</li> <li>Check for invalid field values (e.g., negative priority)</li> </ol>"},{"location":"tutorials/rbac-basics/#next-steps","title":"Next Steps","text":"<ul> <li>Create Read-Only Policy - Detailed guide on read-only access</li> <li>Filter by Namespace - Advanced namespace filtering</li> <li>Policy Evaluation - Understand the evaluation algorithm</li> </ul>"}]}